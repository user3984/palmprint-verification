Traceback (most recent call last):
  File "train.py", line 137, in <module>
    logits = model(image)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "train.py", line 64, in forward
    feat = self.net(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/palmprint/mobilevit.py", line 406, in forward
    x = self.layers(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/palmprint/modules.py", line 175, in forward
    out = _inner_forward(x)
  File "/root/palmprint/modules.py", line 168, in _inner_forward
    return x + self.conv(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/palmprint/modules.py", line 88, in forward
    x = self.norm(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 23.69 GiB total capacity; 10.73 GiB already allocated; 206.75 MiB free; 10.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Loss: 38.67250061035156
Loss: 38.356502532958984
Loss: 38.67365646362305
Loss: 38.530303955078125
Loss: 38.46663284301758
Loss: 38.408851623535156
Loss: 38.48426818847656
Loss: 38.45661163330078
Loss: 38.545021057128906
Loss: 38.415443420410156
Loss: 38.20274353027344
Loss: 38.421226501464844
Loss: 38.13290023803711
Loss: 38.26337432861328
Loss: 38.21148681640625
Loss: 38.28659439086914
Loss: 38.00215530395508
Loss: 38.34486770629883
Loss: 38.36551284790039
Loss: 37.97450637817383
Loss: 37.983154296875
Loss: 38.14872360229492
Loss: 37.92761993408203
Loss: 38.247928619384766
Loss: 37.913883209228516
Loss: 37.78530502319336
Loss: 37.8546257019043
Loss: 38.01606750488281
Loss: 37.99205780029297
Loss: 37.80290222167969
Loss: 37.77046203613281
Loss: 37.866722106933594
Loss: 37.886051177978516
Loss: 37.975555419921875
Loss: 37.881195068359375
Loss: 38.019081115722656
Loss: 38.11696243286133
Loss: 37.618675231933594
Loss: 37.54374694824219
Loss: 37.927608489990234
Loss: 37.84977340698242
Loss: 37.621273040771484
Loss: 37.5703239440918
Loss: 37.58723831176758
Loss: 37.59208297729492
Loss: 37.628173828125
Loss: 37.66864013671875
Loss: 37.6487922668457
Loss: 37.71736526489258
Loss: 37.6575813293457
Loss: 37.479305267333984
Loss: 37.60429763793945
Loss: 37.468406677246094
Loss: 37.616722106933594
Loss: 37.41994094848633
Loss: 37.637779235839844
Loss: 37.48813247680664
Loss: 37.39809799194336
Loss: 37.29340362548828
Loss: 37.62034225463867
Loss: 37.78573226928711
Loss: 37.23834991455078
Loss: 37.540008544921875
Loss: 37.530059814453125
Loss: 37.500736236572266
Loss: 37.54283142089844
Loss: 37.491302490234375
Loss: 37.172359466552734
Loss: 37.62147903442383
Loss: 37.395355224609375
Loss: 37.218360900878906
Loss: 37.3547477722168
Loss: 37.21265411376953
Loss: 37.31733703613281
Loss: 37.44969177246094
Loss: 37.605186462402344
Loss: 37.24806594848633
Loss: 37.34326171875
Loss: 37.29130554199219
Loss: 37.332237243652344
Loss: 37.27742385864258
Loss: 37.35972213745117
Loss: 37.17924118041992
Loss: 37.38786315917969
Loss: 37.34117889404297
Loss: 37.485836029052734
Loss: 37.29104995727539
Loss: 37.113121032714844
Loss: 37.46441650390625
Loss: 37.286537170410156
[Train] Epoch 1, accuracy 0.005208333333333333
[Eval] Epoch 1, loss 5.876036, accuracy 0.010417
Model saved as x_small_model_weights_best.pth
Loss: 37.35017776489258
Loss: 37.477474212646484
Loss: 37.41604995727539
Loss: 37.23250198364258
Loss: 37.286903381347656
Loss: 36.84225845336914
Loss: 36.81880569458008
Loss: 37.08038330078125
Loss: 37.5377082824707
Loss: 37.32878112792969
Loss: 37.115169525146484
Loss: 37.33811569213867
Loss: 37.13845443725586
Loss: 37.100399017333984
Loss: 36.87818908691406
Loss: 37.17524337768555
Loss: 37.39552307128906
Loss: 37.14836883544922
Loss: 37.02992248535156
Loss: 37.239707946777344
Loss: 37.045528411865234
Loss: 37.033199310302734
Loss: 37.03542709350586
Loss: 36.952266693115234
Loss: 36.891082763671875
Loss: 36.79170608520508
Loss: 37.32855987548828
Loss: 36.826873779296875
Loss: 36.73556900024414
Loss: 37.05763244628906
Loss: 37.05418014526367
Loss: 36.97303771972656
Loss: 36.8447151184082
Loss: 36.77771759033203
Loss: 37.06733703613281
Loss: 37.08460235595703
Loss: 36.870033264160156
Loss: 37.050716400146484
Loss: 36.59841537475586
Loss: 36.83442306518555
Loss: 36.68029022216797
Loss: 36.50431823730469
Loss: 36.63423156738281
Loss: 36.355247497558594
Loss: 36.8116569519043
Loss: 36.820068359375
Loss: 36.761592864990234
Loss: 36.463661193847656
Loss: 36.657989501953125
Loss: 36.57078170776367
Loss: 36.798736572265625
Loss: 36.54153823852539
Loss: 36.570960998535156
Loss: 36.455482482910156
Loss: 36.186744689941406
Loss: 36.284610748291016
Loss: 36.2298698425293
Loss: 36.38746643066406
Loss: 36.223670959472656
Loss: 36.2450065612793
Loss: 36.41508102416992
Loss: 36.294681549072266
Loss: 36.15208053588867
Loss: 36.33313751220703
Loss: 36.232364654541016
Loss: 36.11765670776367
Loss: 36.20133590698242
Loss: 36.10253143310547
Loss: 35.655029296875
Loss: 36.192081451416016
Loss: 35.8608512878418
Loss: 35.78810119628906
Loss: 35.86741256713867
Loss: 36.248741149902344
Loss: 35.095603942871094
Loss: 35.91973114013672
Loss: 35.688968658447266
Loss: 35.53904724121094
Loss: 35.68336486816406
Loss: 35.65975570678711
Loss: 35.78196716308594
Loss: 35.41816711425781
Loss: 35.28693389892578
Loss: 35.2678108215332
Loss: 35.05021667480469
Loss: 34.936336517333984
Loss: 35.72407531738281
Loss: 34.86992645263672
Loss: 35.060638427734375
Loss: 35.51153564453125
[Train] Epoch 2, accuracy 0.06875
[Eval] Epoch 2, loss 5.803942, accuracy 0.214236
Model saved as x_small_model_weights_best.pth
Loss: 34.900718688964844
Loss: 34.878849029541016
Loss: 34.4509391784668
Loss: 34.707088470458984
Loss: 35.291229248046875
Loss: 34.44294738769531
Loss: 34.84096908569336
Loss: 34.22772216796875
Loss: 34.60194778442383
Loss: 34.06775665283203
Loss: 34.290401458740234
Loss: 34.30055236816406
Loss: 34.81850051879883
Loss: 34.95781326293945
Loss: 34.62800979614258
Loss: 34.3430290222168
Loss: 34.759159088134766
Loss: 34.2588005065918
Loss: 34.20887756347656
Loss: 33.81315231323242
Loss: 34.05653762817383
Loss: 34.625587463378906
Loss: 34.26887893676758
Loss: 34.395755767822266
Loss: 34.01862716674805
Loss: 33.75743103027344
Loss: 34.058937072753906
Loss: 33.74137878417969
Loss: 34.0699577331543
Loss: 34.3004264831543
Loss: 33.8869514465332
Loss: 33.64959716796875
Loss: 33.76677322387695
Loss: 33.39603805541992
Loss: 33.433841705322266
Loss: 33.45255661010742
Loss: 33.882320404052734
Loss: 33.461463928222656
Loss: 32.85776901245117
Loss: 33.91212844848633
Loss: 33.360801696777344
Loss: 32.510501861572266
Loss: 33.11204147338867
Loss: 32.9229850769043
Loss: 33.848350524902344
Loss: 33.048797607421875
Loss: 32.106021881103516
Loss: 32.14768600463867
Loss: 32.39591979980469
Loss: 32.15676498413086
Loss: 32.20883560180664
Loss: 32.903594970703125
Loss: 31.943012237548828
Loss: 32.043663024902344
Loss: 31.88656234741211
Loss: 32.76869583129883
Loss: 31.892467498779297
Loss: 32.239768981933594
Loss: 32.199283599853516
Loss: 31.465208053588867
Loss: 31.41124725341797
Loss: 30.961658477783203
Loss: 31.902864456176758
Loss: 30.989124298095703
Loss: 32.16194534301758
Loss: 31.405349731445312
Loss: 30.626989364624023
Loss: 31.442045211791992
Loss: 31.475801467895508
Loss: 31.843172073364258
Loss: 30.80240821838379
Loss: 29.910104751586914
Loss: 31.273365020751953
Loss: 31.673503875732422
Loss: 30.563085556030273
Loss: 29.73073959350586
Loss: 30.335859298706055
Loss: 30.525161743164062
Loss: 30.8482608795166
Loss: 30.874832153320312
Loss: 29.448728561401367
Loss: 30.246427536010742
Loss: 30.702838897705078
Loss: 31.676223754882812
Loss: 29.050321578979492
Loss: 30.356903076171875
Loss: 29.69037437438965
Loss: 29.317302703857422
Loss: 28.798751831054688
Loss: 29.159282684326172
[Train] Epoch 3, accuracy 0.43914930555555554
[Eval] Epoch 3, loss 5.608713, accuracy 0.698611
Model saved as x_small_model_weights_best.pth
Loss: 28.22940444946289
Loss: 28.25094223022461
Loss: 27.237438201904297
Loss: 28.318599700927734
Loss: 27.33799934387207
Loss: 28.0448055267334
Loss: 26.849876403808594
Loss: 28.010183334350586
Loss: 27.327497482299805
Loss: 27.2631778717041
Loss: 27.136581420898438
Loss: 26.742706298828125
Loss: 26.832096099853516
Loss: 27.679946899414062
Loss: 27.585128784179688
Loss: 28.563552856445312
Loss: 26.700546264648438
Loss: 25.30597496032715
Loss: 27.991369247436523
Loss: 26.870988845825195
Loss: 26.685611724853516
Loss: 26.775554656982422
Loss: 26.679426193237305
Loss: 26.34212875366211
Loss: 26.03987693786621
Loss: 26.48940086364746
Loss: 26.059001922607422
Loss: 27.37540054321289
Loss: 27.041698455810547
Loss: 24.895751953125
Loss: 25.832170486450195
Loss: 25.64514923095703
Loss: 25.925251007080078
Loss: 25.227930068969727
Loss: 25.550003051757812
Loss: 24.952425003051758
Loss: 25.215787887573242
Loss: 25.280521392822266
Loss: 25.336706161499023
Loss: 26.09229850769043
Loss: 25.739622116088867
Loss: 24.6313533782959
Loss: 24.895235061645508
Loss: 25.614187240600586
Loss: 25.63861656188965
Loss: 23.890722274780273
Loss: 25.31715965270996
Loss: 24.168556213378906
Loss: 25.12621307373047
Loss: 24.125595092773438
Loss: 25.149044036865234
Loss: 24.2587947845459
Loss: 25.94437026977539
Loss: 23.624624252319336
Loss: 24.75698471069336
Loss: 22.78652000427246
Loss: 23.132892608642578
Loss: 24.85237693786621
Loss: 23.10755157470703
Loss: 23.43613052368164
Loss: 22.48546600341797
Loss: 22.84181785583496
Loss: 21.5218563079834
Loss: 24.144500732421875
Loss: 22.19995880126953
Loss: 22.415929794311523
Loss: 23.651798248291016
Loss: 21.5382022857666
Loss: 22.233983993530273
Loss: 23.3064022064209
Loss: 22.316274642944336
Loss: 21.428302764892578
Loss: 22.091583251953125
Loss: 21.908266067504883
Loss: 20.878433227539062
Loss: 22.17633628845215
Loss: 22.024389266967773
Loss: 20.60219955444336
Loss: 21.178218841552734
Loss: 21.873550415039062
Loss: 21.903072357177734
Loss: 21.882293701171875
Loss: 19.940465927124023
Loss: 21.49644660949707
Loss: 21.254783630371094
Loss: 19.821157455444336
Loss: 20.433330535888672
Loss: 21.081310272216797
Loss: 20.732585906982422
Loss: 20.116111755371094
[Train] Epoch 4, accuracy 0.8196180555555556
[Eval] Epoch 4, loss 5.443337, accuracy 0.906250
Model saved as x_small_model_weights_best.pth
Loss: 18.598581314086914
Loss: 19.33525848388672
Loss: 18.39008140563965
Loss: 19.066682815551758
Loss: 18.53518295288086
Loss: 19.105653762817383
Loss: 18.05083465576172
Loss: 19.19239616394043
Loss: 19.099960327148438
Loss: 19.39668846130371
Loss: 19.569869995117188
Loss: 19.523408889770508
Loss: 19.596731185913086
Loss: 18.518701553344727
Loss: 19.901716232299805
Loss: 20.601228713989258
Loss: 18.307937622070312
Loss: 18.84917449951172
Loss: 17.599760055541992
Loss: 16.86589813232422
Loss: 18.633716583251953
Loss: 19.26476287841797
Loss: 16.638273239135742
Loss: 19.906572341918945
Loss: 17.31022834777832
Loss: 19.216644287109375
Loss: 17.286781311035156
Loss: 17.11263084411621
Loss: 18.25997543334961
Loss: 17.02764892578125
Loss: 16.29175567626953
Loss: 17.430362701416016
Loss: 16.649402618408203
Loss: 16.663774490356445
Loss: 18.363479614257812
Loss: 17.60851287841797
Loss: 17.431947708129883
Loss: 18.709716796875
Loss: 17.102041244506836
Loss: 17.378767013549805
Loss: 17.98663902282715
Loss: 17.75592613220215
Loss: 15.9236421585083
Loss: 17.360464096069336
Loss: 16.396018981933594
Loss: 17.747028350830078
Loss: 18.103355407714844
Loss: 17.883575439453125
Loss: 16.469274520874023
Loss: 16.020183563232422
Loss: 17.29164695739746
Loss: 16.61634635925293
Loss: 18.32918357849121
Loss: 16.211389541625977
Loss: 17.929067611694336
Loss: 16.34425926208496
Loss: 15.22454833984375
Loss: 16.81060028076172
Loss: 15.335453987121582
Loss: 14.277557373046875
Loss: 16.241886138916016
Loss: 15.367403030395508
Loss: 15.954336166381836
Loss: 16.283672332763672
Loss: 15.28567886352539
Loss: 15.278698921203613
Loss: 15.287298202514648
Loss: 16.09258460998535
Loss: 15.22481632232666
Loss: 15.00366497039795
Loss: 16.125181198120117
Loss: 16.812379837036133
Loss: 13.88002872467041
Loss: 13.504581451416016
Loss: 15.2125825881958
Loss: 16.215707778930664
Loss: 13.809795379638672
Loss: 15.530261039733887
Loss: 15.377677917480469
Loss: 15.049046516418457
Loss: 13.987933158874512
Loss: 13.66224193572998
Loss: 14.755613327026367
Loss: 14.229195594787598
Loss: 14.064214706420898
Loss: 14.593721389770508
Loss: 14.943105697631836
Loss: 13.9536714553833
Loss: 14.694437980651855
Loss: 14.470513343811035
[Train] Epoch 5, accuracy 0.9461805555555556
[Eval] Epoch 5, loss 5.368594, accuracy 0.962153
Model saved as x_small_model_weights_best.pth
Loss: 13.104174613952637
Loss: 13.709881782531738
Loss: 12.62887191772461
Loss: 13.045008659362793
Loss: 12.763614654541016
Loss: 11.743335723876953
Loss: 13.765486717224121
Loss: 13.904386520385742
Loss: 11.52779483795166
Loss: 12.985021591186523
Loss: 14.011336326599121
Loss: 13.08991527557373
Loss: 11.166810035705566
Loss: 14.173879623413086
Loss: 12.223546981811523
Loss: 11.799678802490234
Loss: 11.89696216583252
Loss: 11.802629470825195
Loss: 11.610503196716309
Loss: 12.857697486877441
Loss: 13.177824974060059
Loss: 11.438746452331543
Loss: 12.543424606323242
Loss: 13.307538986206055
Loss: 11.55640697479248
Loss: 11.34207534790039
Loss: 11.534648895263672
Loss: 11.993029594421387
Loss: 13.19804573059082
Loss: 10.84643840789795
Loss: 10.818833351135254
Loss: 11.884533882141113
Loss: 11.1069974899292
Loss: 11.22650146484375
Loss: 12.02759075164795
Loss: 10.388025283813477
Loss: 12.863668441772461
Loss: 12.098959922790527
Loss: 11.919840812683105
Loss: 12.603684425354004
Loss: 13.222638130187988
Loss: 12.902708053588867
Loss: 12.212750434875488
Loss: 11.871519088745117
Loss: 11.151802062988281
Loss: 11.036709785461426
Loss: 11.074773788452148
Loss: 10.82528018951416
Loss: 10.549744606018066
Loss: 11.955912590026855
Loss: 12.298101425170898
Loss: 11.338308334350586
Loss: 10.564873695373535
Loss: 11.222596168518066
Loss: 11.962435722351074
Loss: 10.6016263961792
Loss: 10.821447372436523
Loss: 11.303704261779785
Loss: 9.533571243286133
Loss: 12.018535614013672
Loss: 9.923632621765137
Loss: 11.384618759155273
Loss: 10.397477149963379
Loss: 10.213303565979004
Loss: 10.495814323425293
Loss: 9.827689170837402
Loss: 10.439072608947754
Loss: 9.583770751953125
Loss: 11.932747840881348
Loss: 9.730502128601074
Loss: 10.665590286254883
Loss: 11.678913116455078
Loss: 11.205023765563965
Loss: 11.352283477783203
Loss: 10.546416282653809
Loss: 9.600861549377441
Loss: 10.338883399963379
Loss: 10.256196975708008
Loss: 9.214021682739258
Loss: 9.328505516052246
Loss: 10.408079147338867
Loss: 9.84093952178955
Loss: 10.423666000366211
Loss: 11.70488452911377
Loss: 9.364777565002441
Loss: 10.136552810668945
Loss: 11.005187034606934
Loss: 9.374894142150879
Loss: 9.335481643676758
Loss: 9.99456787109375
[Train] Epoch 6, accuracy 0.9821180555555555
[Eval] Epoch 6, loss 5.305110, accuracy 0.984375
Model saved as x_small_model_weights_best.pth
Loss: 10.091965675354004
Loss: 8.268489837646484
Loss: 9.979305267333984
Loss: 8.292064666748047
Loss: 8.498953819274902
Loss: 9.381492614746094
Loss: 8.467833518981934
Loss: 9.069311141967773
Loss: 8.096877098083496
Loss: 7.834379196166992
Loss: 7.753535270690918
Loss: 8.529472351074219
Loss: 9.945328712463379
Loss: 7.578972816467285
Loss: 9.253747940063477
Loss: 8.127440452575684
Loss: 7.903661727905273
Loss: 8.946442604064941
Loss: 9.332317352294922
Loss: 9.401447296142578
Loss: 8.221870422363281
Loss: 8.779989242553711
Loss: 7.846768379211426
Loss: 8.486611366271973
Loss: 8.380562782287598
Loss: 8.802227020263672
Loss: 7.822472095489502
Loss: 8.401581764221191
Loss: 9.490506172180176
Loss: 7.4042158126831055
Loss: 7.1611433029174805
Loss: 7.863752841949463
Loss: 7.154718399047852
Loss: 8.08639907836914
Loss: 8.372742652893066
Loss: 7.340272426605225
Loss: 8.124650001525879
Loss: 9.724215507507324
Loss: 8.912666320800781
Loss: 8.730231285095215
Loss: 7.417911052703857
Loss: 7.445340156555176
Loss: 8.438432693481445
Loss: 7.159224987030029
Loss: 6.7664337158203125
Loss: 7.564877510070801
Loss: 7.968743324279785
Loss: 8.738515853881836
Loss: 7.871461868286133
Loss: 7.935536861419678
Loss: 7.990633964538574
Loss: 7.770530700683594
Loss: 7.933479309082031
Loss: 8.332195281982422
Loss: 8.288905143737793
Loss: 8.066266059875488
Loss: 8.197613716125488
Loss: 8.807929992675781
Loss: 8.337796211242676
Loss: 7.2207489013671875
Loss: 6.553673267364502
Loss: 8.12399959564209
Loss: 8.075181007385254
Loss: 7.925809383392334
Loss: 7.0285139083862305
Loss: 8.437575340270996
Loss: 7.011259078979492
Loss: 7.0179524421691895
Loss: 7.509261608123779
Loss: 6.551412582397461
Loss: 6.185546875
Loss: 6.855049133300781
Loss: 7.390746593475342
Loss: 8.134008407592773
Loss: 7.481264114379883
Loss: 7.324270725250244
Loss: 8.010127067565918
Loss: 6.519769668579102
Loss: 6.866995334625244
Loss: 7.096629619598389
Loss: 6.769603729248047
Loss: 6.76732063293457
Loss: 6.682042121887207
Loss: 6.699459075927734
Loss: 7.227128028869629
Loss: 7.069983959197998
Loss: 6.573668956756592
Loss: 5.102609634399414
Loss: 6.905945301055908
Loss: 7.275474548339844
[Train] Epoch 7, accuracy 0.9915798611111111
[Eval] Epoch 7, loss 5.264501, accuracy 0.988542
Model saved as x_small_model_weights_best.pth
Loss: 5.419250965118408
Loss: 5.450744152069092
Loss: 5.381697654724121
Loss: 5.679535865783691
Loss: 5.899223804473877
Loss: 5.416933059692383
Loss: 6.097203731536865
Loss: 6.252854347229004
Loss: 5.736676216125488
Loss: 6.6493821144104
Loss: 5.547275543212891
Loss: 4.853179931640625
Loss: 6.431906700134277
Loss: 4.382440090179443
Loss: 5.188080310821533
Loss: 5.716681003570557
Loss: 5.347831726074219
Loss: 7.476061820983887
Loss: 5.1937150955200195
Loss: 4.80327844619751
Loss: 6.903871059417725
Loss: 5.86955451965332
Loss: 6.29988956451416
Loss: 5.016744613647461
Loss: 5.740971565246582
Loss: 6.015498638153076
Loss: 5.2784810066223145
Loss: 6.566844940185547
Loss: 4.876415729522705
Loss: 6.556424617767334
Loss: 5.810954570770264
Loss: 5.9670729637146
Loss: 6.123140335083008
Loss: 6.7697625160217285
Loss: 6.557225227355957
Loss: 5.037286758422852
Loss: 5.415442943572998
Loss: 6.2780280113220215
Loss: 6.63349723815918
Loss: 6.127992153167725
Loss: 5.373697757720947
Loss: 6.108367443084717
Loss: 6.331247806549072
Loss: 4.406662940979004
Loss: 5.845346927642822
Loss: 5.274571418762207
Loss: 6.382859230041504
Loss: 6.67260217666626
Loss: 4.964848518371582
Loss: 5.257450580596924
Loss: 6.144603729248047
Loss: 5.4287028312683105
Loss: 5.164095401763916
Loss: 4.750546455383301
Loss: 5.949770927429199
Loss: 4.653304576873779
Loss: 5.157543182373047
Loss: 5.479144096374512
Loss: 6.322917461395264
Loss: 5.391595840454102
Loss: 5.688858509063721
Loss: 5.148004531860352
Loss: 4.86052131652832
Loss: 5.0907883644104
Loss: 4.91864013671875
Loss: 3.6104307174682617
Loss: 5.584339141845703
Loss: 4.070428371429443
Loss: 5.664275169372559
Loss: 5.935665130615234
Loss: 5.17404317855835
Loss: 5.094504356384277
Loss: 5.5661773681640625
Loss: 5.09468936920166
Loss: 3.8420727252960205
Loss: 5.055787563323975
Loss: 5.702670574188232
Loss: 5.984696388244629
Loss: 5.968102931976318
Loss: 5.84384298324585
Loss: 5.627214431762695
Loss: 4.690812587738037
Loss: 4.728321075439453
Loss: 5.357566833496094
Loss: 5.827279090881348
Loss: 5.487942695617676
Loss: 5.338686943054199
Loss: 5.5310869216918945
Loss: 6.192721843719482
Loss: 5.793302059173584
[Train] Epoch 8, accuracy 0.9957465277777777
[Eval] Epoch 8, loss 5.258157, accuracy 0.992361
Model saved as x_small_model_weights_best.pth
Loss: 4.670442581176758
Loss: 4.517942428588867
Loss: 4.150970458984375
Loss: 3.806717872619629
Loss: 5.397951126098633
Loss: 4.962748050689697
Loss: 4.835320472717285
Loss: 5.498427867889404
Loss: 5.277378559112549
Loss: 3.7525410652160645
Loss: 3.8371150493621826
Loss: 4.554261684417725
Loss: 5.79272985458374
Loss: 4.8596391677856445
Loss: 3.6753318309783936
Loss: 4.81502103805542
Loss: 4.446287631988525
Loss: 4.092308521270752
Loss: 5.057518005371094
Loss: 4.145215034484863
Loss: 5.022094249725342
Loss: 5.2162089347839355
Loss: 4.346288204193115
Loss: 4.247927665710449
Loss: 4.308968544006348
Loss: 4.333193302154541
Loss: 3.528414011001587
Loss: 4.49780797958374
Loss: 4.175380706787109
Loss: 4.257051944732666
Loss: 3.8200974464416504
Loss: 3.5296237468719482
Loss: 4.602878570556641
Loss: 4.190159320831299
Loss: 4.137807369232178
Loss: 4.727234363555908
Loss: 4.419094085693359
Loss: 4.348332405090332
Loss: 4.44792366027832
Loss: 3.7135353088378906
Loss: 4.019384860992432
Loss: 3.3629069328308105
Loss: 4.173538684844971
Loss: 4.018275260925293
Loss: 3.938718795776367
Loss: 4.986915588378906
Loss: 3.7445807456970215
Loss: 4.17075252532959
Loss: 4.3618011474609375
Loss: 3.6957271099090576
Loss: 2.849606990814209
Loss: 4.73546838760376
Loss: 5.173094749450684
Loss: 3.6341333389282227
Loss: 4.751087665557861
Loss: 3.812299966812134
Loss: 4.413740634918213
Loss: 4.359376430511475
Loss: 4.414535045623779
Loss: 4.226101875305176
Loss: 4.220569133758545
Loss: 3.816533088684082
Loss: 4.1535797119140625
Loss: 4.598863124847412
Loss: 3.196024179458618
Loss: 3.727328300476074
Loss: 3.476656675338745
Loss: 3.6429061889648438
Loss: 3.964840888977051
Loss: 4.5777130126953125
Loss: 3.6414339542388916
Loss: 3.8927431106567383
Loss: 4.560947418212891
Loss: 4.465573787689209
Loss: 3.629319667816162
Loss: 3.4418506622314453
Loss: 3.5698046684265137
Loss: 3.4203755855560303
Loss: 3.4053401947021484
Loss: 4.7238287925720215
Loss: 3.753749370574951
Loss: 3.767986297607422
Loss: 3.983123302459717
Loss: 3.481739044189453
Loss: 3.4974899291992188
Loss: 4.128518104553223
Loss: 3.847480297088623
Loss: 3.8623664379119873
Loss: 4.02783203125
Loss: 3.858781337738037
[Train] Epoch 9, accuracy 0.9979166666666667
[Eval] Epoch 9, loss 5.236985, accuracy 0.994444
Model saved as x_small_model_weights_best.pth
Loss: 3.744384527206421
Loss: 3.3132448196411133
Loss: 4.162570953369141
Loss: 2.940922737121582
Loss: 3.6227874755859375
Loss: 4.144805431365967
Loss: 3.5748727321624756
Loss: 3.7469565868377686
Loss: 3.017620801925659
Loss: 2.9442014694213867
Loss: 3.443474531173706
Loss: 4.036028861999512
Loss: 3.2592740058898926
Loss: 2.456010580062866
Loss: 3.108168601989746
Loss: 3.0598089694976807
Loss: 3.2547881603240967
Loss: 3.594867706298828
Loss: 2.5738422870635986
Loss: 3.5518269538879395
Loss: 3.674333333969116
Loss: 2.772461414337158
Loss: 3.039525032043457
Loss: 2.768301486968994
Loss: 3.627825975418091
Loss: 2.4018125534057617
Loss: 2.8834328651428223
Loss: 3.306777000427246
Loss: 3.0863261222839355
Loss: 3.563354253768921
Loss: 2.4961419105529785
Loss: 2.231440782546997
Loss: 3.1285247802734375
Loss: 3.567969560623169
Loss: 2.699950933456421
Loss: 3.377241611480713
Loss: 2.3830630779266357
Loss: 2.9940743446350098
Loss: 2.558502435684204
Loss: 2.690274238586426
Loss: 3.0640814304351807
Loss: 2.91837477684021
Loss: 3.662343978881836
Loss: 2.5820765495300293
Loss: 2.837966203689575
Loss: 3.193995714187622
Loss: 2.6037778854370117
Loss: 3.1004011631011963
Loss: 2.7520315647125244
Loss: 3.31219220161438
Loss: 3.6427457332611084
Loss: 3.2841169834136963
Loss: 2.246695041656494
Loss: 3.2386958599090576
Loss: 3.1473515033721924
Loss: 3.0234994888305664
Loss: 2.5818121433258057
Loss: 2.4459128379821777
Loss: 3.240391731262207
Loss: 2.685112953186035
Loss: 2.693880319595337
Loss: 3.480316638946533
Loss: 2.76629638671875
Loss: 2.7176411151885986
Loss: 3.1816608905792236
Loss: 3.0759711265563965
Loss: 2.9894301891326904
Loss: 2.9032347202301025
Loss: 2.5895285606384277
Loss: 2.8799688816070557
Loss: 2.2728536128997803
Loss: 3.1475961208343506
Loss: 3.2932443618774414
Loss: 3.6332497596740723
Loss: 3.0636966228485107
Loss: 2.684879779815674
Loss: 2.549326181411743
Loss: 3.3724489212036133
Loss: 3.298999547958374
Loss: 4.0088605880737305
Loss: 2.7735118865966797
Loss: 2.448080539703369
Loss: 2.125579595565796
Loss: 2.198941469192505
Loss: 2.9076833724975586
Loss: 2.9636287689208984
Loss: 3.48987078666687
Loss: 3.0693306922912598
Loss: 2.8856945037841797
Loss: 3.020131826400757
[Train] Epoch 10, accuracy 0.9984375
[Eval] Epoch 10, loss 5.219676, accuracy 0.995833
Model saved as x_small_model_weights_best.pth
Loss: 2.148714780807495
Loss: 2.615732431411743
Loss: 2.663403034210205
Loss: 2.9470582008361816
Loss: 2.0753417015075684
Loss: 2.0436689853668213
Loss: 2.9655508995056152
Loss: 3.064518928527832
Loss: 2.3705153465270996
Loss: 2.7268455028533936
Loss: 2.7045228481292725
Loss: 2.542161464691162
Loss: 2.363917350769043
Loss: 2.270237684249878
Loss: 2.0986812114715576
Loss: 2.298664093017578
Loss: 2.2578163146972656
Loss: 2.373098611831665
Loss: 2.4586050510406494
Loss: 2.067094564437866
Loss: 2.815809726715088
Loss: 2.0598998069763184
Loss: 2.443420886993408
Loss: 3.1330366134643555
Loss: 1.8191527128219604
Loss: 2.6197474002838135
Loss: 1.877906084060669
Loss: 2.893052577972412
Loss: 2.0139074325561523
Loss: 2.622490882873535
Loss: 2.161349058151245
Loss: 2.292741537094116
Loss: 3.1259093284606934
Loss: 2.311018228530884
Loss: 2.7199621200561523
Loss: 2.7022597789764404
Loss: 1.5918183326721191
Loss: 1.5844115018844604
Loss: 2.7912731170654297
Loss: 2.554964542388916
Loss: 1.9975777864456177
Loss: 2.8538055419921875
Loss: 2.497547149658203
Loss: 1.913787841796875
Loss: 2.9573605060577393
Loss: 2.1804354190826416
Loss: 2.681871175765991
Loss: 2.5749621391296387
Loss: 2.223055601119995
Loss: 2.869534492492676
Loss: 2.567150354385376
Loss: 2.000373601913452
Loss: 2.092944860458374
Loss: 2.884263515472412
Loss: 2.226022481918335
Loss: 2.797502040863037
Loss: 3.2971692085266113
Loss: 2.153226375579834
Loss: 2.659842014312744
Loss: 2.3886852264404297
Loss: 3.0854218006134033
Loss: 3.070662260055542
Loss: 2.654222249984741
Loss: 2.396824359893799
Loss: 1.9386574029922485
Loss: 2.852635145187378
Loss: 1.9285705089569092
Loss: 2.542313814163208
Loss: 2.2188010215759277
Loss: 2.558976888656616
Loss: 2.5969250202178955
Loss: 2.321815013885498
Loss: 2.4568405151367188
Loss: 2.403303384780884
Loss: 2.125361442565918
Loss: 2.0038557052612305
Loss: 1.8370378017425537
Loss: 1.6131771802902222
Loss: 2.7215681076049805
Loss: 2.280430316925049
Loss: 3.190148115158081
Loss: 2.8914809226989746
Loss: 2.678035259246826
Loss: 2.53307843208313
Loss: 2.2766270637512207
Loss: 2.1749320030212402
Loss: 1.5825775861740112
Loss: 1.5773974657058716
Loss: 2.408531904220581
Loss: 2.208831310272217
[Train] Epoch 11, accuracy 0.9991319444444444
[Eval] Epoch 11, loss 5.213024, accuracy 0.997222
Model saved as x_small_model_weights_best.pth
Loss: 2.3035147190093994
Loss: 2.144540309906006
Loss: 1.9752106666564941
Loss: 2.2773525714874268
Loss: 1.841059684753418
Loss: 1.6728870868682861
Loss: 2.1030914783477783
Loss: 1.8898138999938965
Loss: 1.9280859231948853
Loss: 2.0924036502838135
Loss: 1.9331910610198975
Loss: 2.319488286972046
Loss: 1.5603522062301636
Loss: 1.13673996925354
Loss: 2.4214975833892822
Loss: 1.7881739139556885
Loss: 2.004565477371216
Loss: 1.7218717336654663
Loss: 1.3276457786560059
Loss: 2.1000232696533203
Loss: 2.427666425704956
Loss: 1.4515092372894287
Loss: 2.4089934825897217
Loss: 1.384896159172058
Loss: 1.4408388137817383
Loss: 1.8249081373214722
Loss: 1.7222667932510376
Loss: 1.7995446920394897
Loss: 1.6623072624206543
Loss: 1.455655574798584
Loss: 2.065220594406128
Loss: 2.1005265712738037
Loss: 2.0081963539123535
Loss: 1.998003602027893
Loss: 1.4599319696426392
Loss: 2.0651204586029053
Loss: 1.9738370180130005
Loss: 2.0091373920440674
Loss: 1.5662055015563965
Loss: 2.5271823406219482
Loss: 1.063612699508667
Loss: 1.7269675731658936
Loss: 1.8922652006149292
Loss: 2.043703556060791
Loss: 1.9380449056625366
Loss: 0.9222795963287354
Loss: 2.0252954959869385
Loss: 1.9900028705596924
Loss: 1.4605494737625122
Loss: 2.078988790512085
Loss: 1.7121254205703735
Loss: 1.7245765924453735
Loss: 2.164670705795288
Loss: 1.6719359159469604
Loss: 2.3371098041534424
Loss: 2.2223665714263916
Loss: 1.890248417854309
Loss: 2.1100668907165527
Loss: 1.0685627460479736
Loss: 1.578763723373413
Loss: 1.321668028831482
Loss: 1.5123755931854248
Loss: 1.7699785232543945
Loss: 1.828364372253418
Loss: 1.8367830514907837
Loss: 1.8151825666427612
Loss: 2.09397292137146
Loss: 2.869199275970459
Loss: 1.8475943803787231
Loss: 1.685081958770752
Loss: 2.1958746910095215
Loss: 1.7219146490097046
Loss: 1.7160630226135254
Loss: 1.2405873537063599
Loss: 1.6063454151153564
Loss: 1.3668053150177002
Loss: 1.7134209871292114
Loss: 1.7171646356582642
Loss: 1.8513803482055664
Loss: 1.6037797927856445
Loss: 1.4530779123306274
Loss: 1.7657411098480225
Loss: 1.031783938407898
Loss: 1.2081667184829712
Loss: 1.7505500316619873
Loss: 1.3009146451950073
Loss: 1.4393343925476074
Loss: 1.2177072763442993
Loss: 2.103634834289551
Loss: 1.910938024520874
[Train] Epoch 12, accuracy 0.9994791666666667
[Eval] Epoch 12, loss 5.183407, accuracy 0.997917
Model saved as x_small_model_weights_best.pth
Loss: 1.2513070106506348
Loss: 1.0911134481430054
Loss: 1.3319635391235352
Loss: 1.8578077554702759
Loss: 1.2923738956451416
Loss: 1.3058204650878906
Loss: 1.6133180856704712
Loss: 0.8959441184997559
Loss: 1.203736424446106
Loss: 1.640792965888977
Loss: 1.4656304121017456
Loss: 1.525421380996704
Loss: 1.3197723627090454
Loss: 1.410046935081482
Loss: 1.6203325986862183
Loss: 1.1713517904281616
Loss: 2.1400585174560547
Loss: 1.2769814729690552
Loss: 1.1508126258850098
Loss: 1.2208694219589233
Loss: 1.2264045476913452
Loss: 1.124090552330017
Loss: 1.2852873802185059
Loss: 1.2633850574493408
Loss: 1.4410362243652344
Loss: 1.901059865951538
Loss: 1.5077664852142334
Loss: 1.6517417430877686
Loss: 1.4828166961669922
Loss: 1.6135129928588867
Loss: 1.3561128377914429
Loss: 1.721588373184204
Loss: 1.7113717794418335
Loss: 1.395546317100525
Loss: 1.7798584699630737
Loss: 1.473131775856018
Loss: 1.5836414098739624
Loss: 1.8987743854522705
Loss: 1.0042974948883057
Loss: 1.0896977186203003
Loss: 1.0859063863754272
Loss: 1.4430351257324219
Loss: 1.263196587562561
Loss: 1.221200942993164
Loss: 1.0381970405578613
Loss: 2.0652496814727783
Loss: 1.6883740425109863
Loss: 1.5881624221801758
Loss: 1.6701877117156982
Loss: 1.5485812425613403
Loss: 1.4758555889129639
Loss: 1.3811951875686646
Loss: 1.001073956489563
Loss: 1.354038953781128
Loss: 1.8973733186721802
Loss: 1.1170445680618286
Loss: 2.0806117057800293
Loss: 1.036299705505371
Loss: 1.7644048929214478
Loss: 0.8964893817901611
Loss: 1.4773237705230713
Loss: 1.4302607774734497
Loss: 1.4889371395111084
Loss: 1.831946611404419
Loss: 1.2873539924621582
Loss: 1.1785402297973633
Loss: 1.181154489517212
Loss: 1.3448866605758667
Loss: 0.9332116842269897
Loss: 1.3042030334472656
Loss: 0.9252675771713257
Loss: 1.3403570652008057
Loss: 1.9184147119522095
Loss: 1.9172322750091553
Loss: 0.9544965028762817
Loss: 1.4778108596801758
Loss: 1.2629060745239258
Loss: 1.3854565620422363
Loss: 1.2756091356277466
Loss: 0.9839437007904053
Loss: 1.28175950050354
Loss: 2.1298391819000244
Loss: 1.6983458995819092
Loss: 1.6481364965438843
Loss: 1.7165049314498901
Loss: 1.244184136390686
Loss: 1.3625036478042603
Loss: 1.5299257040023804
Loss: 1.520452618598938
Loss: 1.751427173614502
[Train] Epoch 13, accuracy 0.9996527777777777
[Eval] Epoch 13, loss 5.181294, accuracy 0.998264
Model saved as x_small_model_weights_best.pth
Loss: 1.1517043113708496
Loss: 1.8624505996704102
Loss: 1.001879096031189
Loss: 1.0945255756378174
Loss: 1.4461053609848022
Loss: 1.0447596311569214
Loss: 0.6903979778289795
Loss: 1.1158734560012817
Loss: 1.0286964178085327
Loss: 0.9496495723724365
Loss: 0.9246911406517029
Loss: 1.29121732711792
Loss: 1.3533751964569092
Loss: 0.8132163286209106
Loss: 1.2812273502349854
Loss: 1.0217523574829102
Loss: 0.7638934254646301
Loss: 1.0804681777954102
Loss: 0.9124848246574402
Loss: 1.0075864791870117
Loss: 0.9518959522247314
Loss: 0.9963148236274719
Loss: 1.1598626375198364
Loss: 1.106436014175415
Loss: 1.1084916591644287
Loss: 1.2556041479110718
Loss: 0.9299244284629822
Loss: 1.0984162092208862
Loss: 1.165748119354248
Loss: 0.7183203101158142
Loss: 1.0631799697875977
Loss: 1.320560336112976
Loss: 1.0595377683639526
Loss: 0.8727098107337952
Loss: 0.9886963367462158
Loss: 0.7461730241775513
Loss: 1.2812275886535645
Loss: 0.8188090920448303
Loss: 0.9983948469161987
Loss: 1.39940345287323
Loss: 0.8407487273216248
Loss: 1.3815394639968872
Loss: 1.4831210374832153
Loss: 0.935762345790863
Loss: 1.2327231168746948
Loss: 0.5411469340324402
Loss: 0.9527809619903564
Loss: 1.8944871425628662
Loss: 1.3084176778793335
Loss: 1.072056531906128
Loss: 1.0775216817855835
Loss: 0.9685394763946533
Loss: 1.2476261854171753
Loss: 1.0067249536514282
Loss: 0.987051248550415
Loss: 1.6239880323410034
Loss: 0.853827178478241
Loss: 1.3411260843276978
Loss: 1.200361728668213
Loss: 1.0270252227783203
Loss: 0.8324149250984192
Loss: 1.2286733388900757
Loss: 0.9559440016746521
Loss: 1.1659412384033203
Loss: 1.2525088787078857
Loss: 0.9873538613319397
Loss: 1.1958622932434082
Loss: 1.4511841535568237
Loss: 1.2143363952636719
Loss: 1.2444627285003662
Loss: 0.918287992477417
Loss: 0.60971999168396
Loss: 0.7978350520133972
Loss: 1.3576302528381348
Loss: 1.1255838871002197
Loss: 1.6587226390838623
Loss: 1.065427541732788
Loss: 0.6964033842086792
Loss: 0.8433805704116821
Loss: 1.1868922710418701
Loss: 1.12218177318573
Loss: 1.3771775960922241
Loss: 0.7345145344734192
Loss: 1.2921696901321411
Loss: 1.5469714403152466
Loss: 0.844210684299469
Loss: 1.0160577297210693
Loss: 1.5015190839767456
Loss: 1.2226221561431885
Loss: 1.194853663444519
[Train] Epoch 14, accuracy 0.9997395833333333
[Eval] Epoch 14, loss 5.181589, accuracy 0.997917
Loss: 0.6008842587471008
Loss: 1.1874117851257324
Loss: 1.5913952589035034
Loss: 0.7546157240867615
Loss: 1.0223180055618286
Loss: 0.7110037207603455
Loss: 0.9932182431221008
Loss: 0.5881286263465881
Loss: 0.8494760990142822
Loss: 0.7328258752822876
Loss: 1.1564816236495972
Loss: 0.8854562044143677
Loss: 0.766753077507019
Loss: 0.9984291791915894
Loss: 0.915776789188385
Loss: 0.7652180790901184
Loss: 0.8145458698272705
Loss: 0.817401111125946
Loss: 0.9520896077156067
Loss: 0.6909231543540955
Loss: 0.8506379127502441
Loss: 0.8867312669754028
Loss: 0.9119566082954407
Loss: 0.6308949589729309
Loss: 0.99430912733078
Loss: 0.9555255174636841
Loss: 1.2392756938934326
Loss: 0.6560330986976624
Loss: 0.9915919899940491
Loss: 0.7398687601089478
Loss: 1.0485320091247559
Loss: 0.32460716366767883
Loss: 0.8090776205062866
Loss: 0.8034860491752625
Loss: 0.8283801674842834
Loss: 0.8812327980995178
Loss: 0.5611808896064758
Loss: 1.1836298704147339
Loss: 1.4157629013061523
Loss: 0.9753206968307495
Loss: 1.1355023384094238
Loss: 0.6672981977462769
Loss: 0.5519037246704102
Loss: 1.1176766157150269
Loss: 0.7642115354537964
Loss: 0.7427738308906555
Loss: 1.149354338645935
Loss: 0.9004589915275574
Loss: 0.6877006888389587
Loss: 0.797865629196167
Loss: 0.7895053625106812
Loss: 0.9977090954780579
Loss: 1.0593475103378296
Loss: 0.9050118923187256
Loss: 1.1491668224334717
Loss: 0.6886652708053589
Loss: 0.6206629872322083
Loss: 0.9442553520202637
Loss: 1.318215250968933
Loss: 0.7167474031448364
Loss: 1.0065749883651733
Loss: 1.0468721389770508
Loss: 0.7288491129875183
Loss: 0.8452250957489014
Loss: 0.7941275238990784
Loss: 0.9600875973701477
Loss: 1.2128127813339233
Loss: 1.0081905126571655
Loss: 1.0745608806610107
Loss: 0.7264202833175659
Loss: 1.5030909776687622
Loss: 0.5144869685173035
Loss: 0.8362376689910889
Loss: 1.1283842325210571
Loss: 0.8395669460296631
Loss: 0.707482099533081
Loss: 1.4240168333053589
Loss: 0.7595750689506531
Loss: 1.194456934928894
Loss: 1.4686888456344604
Loss: 0.37297728657722473
Loss: 0.821479856967926
Loss: 1.2083587646484375
Loss: 1.121711254119873
Loss: 1.0672038793563843
Loss: 1.1172045469284058
Loss: 1.024704933166504
Loss: 1.0475456714630127
Loss: 0.8380976915359497
Loss: 1.0927314758300781
[Train] Epoch 15, accuracy 0.9997395833333333
[Eval] Epoch 15, loss 5.184365, accuracy 0.997917
Loss: 0.9249789118766785
Loss: 1.1210497617721558
Loss: 0.8978443145751953
Loss: 1.172282338142395
Loss: 0.7963718771934509
Loss: 0.5636637210845947
Loss: 0.6285931468009949
Loss: 1.168713927268982
Loss: 0.7851227521896362
Loss: 1.0617560148239136
Loss: 0.5864236950874329
Loss: 0.7692722082138062
Loss: 0.5565143823623657
Loss: 0.6964842081069946
Loss: 1.1501224040985107
Loss: 0.35884928703308105
Loss: 0.9872851371765137
Loss: 0.6257489919662476
Loss: 1.0125011205673218
Loss: 1.1371618509292603
Loss: 0.899834394454956
Loss: 0.8620410561561584
Loss: 0.7464004158973694
Loss: 0.5845667719841003
Loss: 1.02117121219635
Loss: 0.5010924339294434
Loss: 0.8163720369338989
Loss: 0.6815233826637268
Loss: 1.0062825679779053
Loss: 0.41350945830345154
Loss: 0.7330297827720642
Loss: 0.4882828891277313
Loss: 0.860377848148346
Loss: 0.531141459941864
Loss: 0.8877246379852295
Loss: 0.8740319609642029
Loss: 0.8106017708778381
Loss: 0.8290749788284302
Loss: 1.1108680963516235
Loss: 0.818868100643158
Loss: 0.9214239716529846
Loss: 0.8256709575653076
Loss: 0.7633384466171265
Loss: 0.5502349138259888
Loss: 1.0671191215515137
Loss: 1.004045844078064
Loss: 0.9194978475570679
Loss: 0.579683780670166
Loss: 0.6357005834579468
Loss: 1.2372153997421265
Loss: 1.0444023609161377
Loss: 0.6374408006668091
Loss: 1.1028207540512085
Loss: 1.0692239999771118
Loss: 0.7872816324234009
Loss: 1.095460057258606
Loss: 1.311238408088684
Loss: 1.2761279344558716
Loss: 0.3408544063568115
Loss: 0.9991822838783264
Loss: 0.6124594807624817
Loss: 0.5215454697608948
Loss: 0.6339543461799622
Loss: 0.9006346464157104
Loss: 0.6480849981307983
Loss: 0.8249009251594543
Loss: 1.1230366230010986
Loss: 0.8948614597320557
Loss: 1.2471064329147339
Loss: 0.933566153049469
Loss: 0.6201463341712952
Loss: 0.6810746788978577
Loss: 0.7181508541107178
Loss: 1.2070192098617554
Loss: 0.7178603410720825
Loss: 1.0461838245391846
Loss: 0.45682868361473083
Loss: 0.2528468370437622
Loss: 0.655466616153717
Loss: 1.041656732559204
Loss: 0.8099303841590881
Loss: 0.6793175935745239
Loss: 0.7738742828369141
Loss: 0.8996371626853943
Loss: 1.0592174530029297
Loss: 0.5398536324501038
Loss: 1.2319271564483643
Loss: 0.8686856031417847
Loss: 0.7327278852462769
Loss: 0.969385027885437
[Train] Epoch 16, accuracy 0.9997395833333333
[Eval] Epoch 16, loss 5.178588, accuracy 0.998264
Model saved as x_small_model_weights_best.pth
Loss: 1.326066017150879
Loss: 0.564714789390564
Loss: 0.70447838306427
Loss: 0.8894968032836914
Loss: 0.8448448181152344
Loss: 0.6659095883369446
Loss: 0.5814546346664429
Loss: 0.6695396304130554
Loss: 0.7881022691726685
Loss: 0.6835246086120605
Loss: 0.8332101106643677
Loss: 0.821419894695282
Loss: 0.3882913589477539
Loss: 0.6537662148475647
Loss: 0.5147730708122253
Loss: 0.5922585129737854
Loss: 0.750460147857666
Loss: 0.4917207956314087
Loss: 0.5203626155853271
Loss: 0.6195052266120911
Loss: 1.1707580089569092
Loss: 0.48463496565818787
Loss: 0.6034246683120728
Loss: 0.5262585282325745
Loss: 0.6019616723060608
Loss: 0.6695461273193359
Loss: 0.4936586320400238
Loss: 0.45059335231781006
Loss: 0.6373628377914429
Loss: 0.5543844103813171
Loss: 0.7848568558692932
Loss: 0.7558730244636536
Loss: 0.9320884943008423
Loss: 0.8468714952468872
Loss: 0.8910212516784668
Loss: 0.93118816614151
Loss: 0.38770878314971924
Loss: 0.8194742798805237
Loss: 0.554505467414856
Loss: 0.7762109637260437
Loss: 0.7252436876296997
Loss: 1.1847974061965942
Loss: 0.7501566410064697
Loss: 0.40577054023742676
Loss: 0.48341670632362366
Loss: 1.0306588411331177
Loss: 0.5188080668449402
Loss: 0.9679208397865295
Loss: 0.6449697613716125
Loss: 0.7939814329147339
Loss: 1.0188438892364502
Loss: 0.42150115966796875
Loss: 0.6157242655754089
Loss: 0.7640591859817505
Loss: 1.1405426263809204
Loss: 0.6634105443954468
Loss: 0.8505009412765503
Loss: 0.38640591502189636
Loss: 0.8445582389831543
Loss: 0.6789454221725464
Loss: 0.42521998286247253
Loss: 0.5871265530586243
Loss: 0.9969059824943542
Loss: 0.7943553328514099
Loss: 0.8743719458580017
Loss: 0.5883759260177612
Loss: 0.5893841981887817
Loss: 0.73635333776474
Loss: 1.1298553943634033
Loss: 0.5708550810813904
Loss: 0.7670851349830627
Loss: 0.26686227321624756
Loss: 0.8474584221839905
Loss: 0.778745710849762
Loss: 0.7136649489402771
Loss: 0.8852826356887817
Loss: 0.646996259689331
Loss: 1.0042792558670044
Loss: 0.7565130591392517
Loss: 0.9529378414154053
Loss: 0.5622335076332092
Loss: 0.43219849467277527
Loss: 0.708295464515686
Loss: 0.5443723797798157
Loss: 0.8212360739707947
Loss: 0.49485862255096436
Loss: 0.3031251132488251
Loss: 0.6036834716796875
Loss: 0.6941186785697937
Loss: 0.6186126470565796
[Train] Epoch 17, accuracy 0.9998263888888889
[Eval] Epoch 17, loss 5.173287, accuracy 0.997917
Loss: 0.3995451331138611
Loss: 0.49316272139549255
Loss: 0.7803958058357239
Loss: 1.0238797664642334
Loss: 0.6339898109436035
Loss: 0.437902569770813
Loss: 0.7519496083259583
Loss: 0.5021783113479614
Loss: 0.7131476998329163
Loss: 0.4261993169784546
Loss: 0.9601885080337524
Loss: 0.610014021396637
Loss: 0.36901023983955383
Loss: 0.6672478318214417
Loss: 0.6589111089706421
Loss: 0.6400548219680786
Loss: 0.3182903230190277
Loss: 0.6570038795471191
Loss: 0.7761949300765991
Loss: 0.6141204833984375
Loss: 0.47210565209388733
Loss: 0.6691094040870667
Loss: 0.4901423454284668
Loss: 0.7540881037712097
Loss: 1.0766345262527466
Loss: 0.491174578666687
Loss: 0.6439495086669922
Loss: 1.0890156030654907
Loss: 0.8684509992599487
Loss: 0.5765968561172485
Loss: 0.6072394251823425
Loss: 0.8042387366294861
Loss: 0.7223609685897827
Loss: 0.7110869884490967
Loss: 0.6658653616905212
Loss: 0.5529444217681885
Loss: 0.6766147613525391
Loss: 0.8079227209091187
Loss: 0.5954499244689941
Loss: 0.5065556168556213
Loss: 0.7534319162368774
Loss: 0.6647054553031921
Loss: 0.38164302706718445
Loss: 0.8162479400634766
Loss: 0.475538969039917
Loss: 0.5522312521934509
Loss: 0.4617879092693329
Loss: 0.6612834930419922
Loss: 0.5506043434143066
Loss: 0.4761015474796295
Loss: 0.8812040090560913
Loss: 0.6858786940574646
Loss: 0.4771061837673187
Loss: 0.7270234227180481
Loss: 0.4194667339324951
Loss: 0.7015861868858337
Loss: 0.5875760316848755
Loss: 1.045271873474121
Loss: 0.6648728251457214
Loss: 0.5910112857818604
Loss: 0.4736177623271942
Loss: 0.6456396579742432
Loss: 0.6793615818023682
Loss: 0.5091575980186462
Loss: 0.5495067238807678
Loss: 0.46507012844085693
Loss: 0.8328527212142944
Loss: 0.37495651841163635
Loss: 0.29673606157302856
Loss: 0.2149948924779892
Loss: 0.34803447127342224
Loss: 0.49585771560668945
Loss: 1.0707472562789917
Loss: 0.7387317419052124
Loss: 0.5370302796363831
Loss: 0.4348730146884918
Loss: 0.6814561486244202
Loss: 1.0000666379928589
Loss: 0.6525821685791016
Loss: 0.5835744142532349
Loss: 0.7717044353485107
Loss: 0.43602827191352844
Loss: 0.5860416889190674
Loss: 0.5565419793128967
Loss: 0.3828994631767273
Loss: 0.42310047149658203
Loss: 0.469165176153183
Loss: 0.47604846954345703
Loss: 0.5767816305160522
Loss: 0.5749592781066895
[Train] Epoch 18, accuracy 0.9998263888888889
[Eval] Epoch 18, loss 5.167019, accuracy 0.997917
Loss: 0.8846385478973389
Loss: 0.5448841452598572
Loss: 0.3702097237110138
Loss: 0.6593860387802124
Loss: 0.48967263102531433
Loss: 0.5648819208145142
Loss: 0.5299346446990967
Loss: 0.5468795299530029
Loss: 0.30805516242980957
Loss: 0.6137562990188599
Loss: 0.43669235706329346
Loss: 0.6242437362670898
Loss: 0.910650908946991
Loss: 0.6647045016288757
Loss: 0.3522350788116455
Loss: 0.39682018756866455
Loss: 0.49178966879844666
Loss: 0.5226186513900757
Loss: 1.0898962020874023
Loss: 0.5956178903579712
Loss: 0.28445956110954285
Loss: 0.7916784286499023
Loss: 0.39967894554138184
Loss: 1.0383282899856567
Loss: 0.48645177483558655
Loss: 0.7158619165420532
Loss: 0.800051212310791
Loss: 0.37380215525627136
Loss: 0.8515475392341614
Loss: 0.6789256930351257
Loss: 0.5740829706192017
Loss: 0.4591541588306427
Loss: 0.1933680921792984
Loss: 0.6902557015419006
Loss: 0.8632873296737671
Loss: 0.2586365044116974
Loss: 0.6563316583633423
Loss: 0.5435189008712769
Loss: 0.32153311371803284
Loss: 0.7383357286453247
Loss: 0.3448220193386078
Loss: 0.6490449905395508
Loss: 0.4102352559566498
Loss: 0.2958778738975525
Loss: 0.33140361309051514
Loss: 0.42257264256477356
Loss: 0.550108790397644
Loss: 0.33821722865104675
Loss: 0.3641761541366577
Loss: 0.46955910325050354
Loss: 0.37942805886268616
Loss: 0.5560732483863831
Loss: 0.4412773549556732
Loss: 0.629804253578186
Loss: 0.2134947031736374
Loss: 0.3820919394493103
Loss: 0.4568119943141937
Loss: 0.3871878385543823
Loss: 0.9300251007080078
Loss: 0.415318101644516
Loss: 0.5285643935203552
Loss: 0.33451467752456665
Loss: 0.2946130037307739
Loss: 0.356942355632782
Loss: 0.4681824743747711
Loss: 0.3581134080886841
Loss: 0.3644777834415436
Loss: 0.5261073708534241
Loss: 0.5625761151313782
Loss: 0.6364285945892334
Loss: 0.6391833424568176
Loss: 0.5882469415664673
Loss: 0.6369950175285339
Loss: 0.33535468578338623
Loss: 0.46789100766181946
Loss: 0.47671225666999817
Loss: 0.7236490845680237
Loss: 0.5287944078445435
Loss: 0.9828782081604004
Loss: 0.5573634505271912
Loss: 0.42001137137413025
Loss: 0.5714021921157837
Loss: 0.39093780517578125
Loss: 0.3467971682548523
Loss: 0.5835070610046387
Loss: 0.3893415927886963
Loss: 0.6132693290710449
Loss: 0.5170266628265381
Loss: 0.154925137758255
Loss: 0.8098608255386353
[Train] Epoch 19, accuracy 0.9999131944444445
[Eval] Epoch 19, loss 5.164552, accuracy 0.998264
Model saved as x_small_model_weights_best.pth
Loss: 0.22713793814182281
Loss: 0.32507914304733276
Loss: 0.4126741886138916
Loss: 0.32913386821746826
Loss: 0.316156268119812
Loss: 0.6818727850914001
Loss: 0.8803329467773438
Loss: 0.29335418343544006
Loss: 0.44809257984161377
Loss: 0.7644513249397278
Loss: 0.5156197547912598
Loss: 0.3443840444087982
Loss: 0.43074458837509155
Loss: 0.4743534326553345
Loss: 0.3975200653076172
Loss: 0.9277676343917847
Loss: 0.5378883481025696
Loss: 0.2633054554462433
Loss: 0.5134169459342957
Loss: 0.5535963773727417
Loss: 0.7257713675498962
Loss: 0.17110849916934967
Loss: 0.4636305570602417
Loss: 0.569851815700531
Loss: 0.458447128534317
Loss: 0.341659814119339
Loss: 0.37611064314842224
Loss: 0.39226630330085754
Loss: 0.7372949123382568
Loss: 0.42101699113845825
Loss: 0.47791507840156555
Loss: 0.3679448068141937
Loss: 0.34249794483184814
Loss: 0.44689640402793884
Loss: 0.42345261573791504
Loss: 0.4673555791378021
Loss: 0.44079458713531494
Loss: 0.49601083993911743
Loss: 0.425175279378891
Loss: 0.41012245416641235
Loss: 0.4554825723171234
Loss: 0.39384689927101135
Loss: 0.4047108590602875
Loss: 0.5350217223167419
Loss: 0.2625678479671478
Loss: 0.38547635078430176
Loss: 0.5916659832000732
Loss: 0.7778701186180115
Loss: 0.426636666059494
Loss: 0.3551005721092224
Loss: 0.35011062026023865
Loss: 0.27589911222457886
Loss: 0.3009410500526428
Loss: 0.5034209489822388
Loss: 0.22205662727355957
Loss: 0.5892062783241272
Loss: 0.6217869520187378
Loss: 0.37255680561065674
Loss: 0.4286656081676483
Loss: 0.5381960272789001
Loss: 0.46085697412490845
Loss: 0.15324893593788147
Loss: 0.5420141816139221
Loss: 0.5435675382614136
Loss: 0.2880336046218872
Loss: 0.3466106951236725
Loss: 0.37537816166877747
Loss: 0.580311119556427
Loss: 0.3340738117694855
Loss: 0.48613905906677246
Loss: 0.27386462688446045
Loss: 0.25975826382637024
Loss: 0.6317150592803955
Loss: 0.4005475342273712
Loss: 0.3124052584171295
Loss: 0.4379178583621979
Loss: 0.4267934262752533
Loss: 0.5116683840751648
Loss: 0.3113183081150055
Loss: 0.473128080368042
Loss: 0.4635305106639862
Loss: 0.4863436222076416
Loss: 0.27214479446411133
Loss: 0.5885199308395386
Loss: 0.4763944149017334
Loss: 0.4361736476421356
Loss: 0.48825159668922424
Loss: 0.38830187916755676
Loss: 0.39807844161987305
Loss: 0.6698573231697083
[Train] Epoch 20, accuracy 0.9998263888888889
[Eval] Epoch 20, loss 5.166486, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.47655731439590454
Loss: 0.4067496955394745
Loss: 0.5508939623832703
Loss: 0.21281468868255615
Loss: 0.6732446551322937
Loss: 0.22445864975452423
Loss: 0.2789764702320099
Loss: 0.359761118888855
Loss: 0.1332942247390747
Loss: 0.4183518886566162
Loss: 0.32243677973747253
Loss: 0.4051823616027832
Loss: 0.43291398882865906
Loss: 0.3330720365047455
Loss: 0.512310266494751
Loss: 0.22467638552188873
Loss: 0.4383736550807953
Loss: 0.28082430362701416
Loss: 0.4517582058906555
Loss: 0.3069697916507721
Loss: 0.3557308614253998
Loss: 0.3666345477104187
Loss: 0.5356450080871582
Loss: 0.4647257924079895
Loss: 0.2547696828842163
Loss: 0.48715996742248535
Loss: 0.1320715993642807
Loss: 0.39306744933128357
Loss: 0.680250883102417
Loss: 0.16369128227233887
Loss: 0.48138657212257385
Loss: 0.4192039966583252
Loss: 0.5119338631629944
Loss: 0.12622731924057007
Loss: 0.33761733770370483
Loss: 0.32670366764068604
Loss: 0.41439875960350037
Loss: 0.36876189708709717
Loss: 0.25335970520973206
Loss: 0.6075628995895386
Loss: 0.1865173578262329
Loss: 0.39195516705513
Loss: 0.3723932206630707
Loss: 0.21278557181358337
Loss: 0.22537486255168915
Loss: 0.2319236695766449
Loss: 0.5117051005363464
Loss: 0.40657293796539307
Loss: 0.2529710531234741
Loss: 0.34260985255241394
Loss: 0.30329540371894836
Loss: 0.4418071508407593
Loss: 0.29040446877479553
Loss: 0.16850101947784424
Loss: 0.592083752155304
Loss: 0.252573162317276
Loss: 0.6702577471733093
Loss: 0.373595267534256
Loss: 0.28902122378349304
Loss: 0.1953052431344986
Loss: 0.24285390973091125
Loss: 0.5269899964332581
Loss: 0.7033727765083313
Loss: 0.39878013730049133
Loss: 0.45699506998062134
Loss: 0.09887269884347916
Loss: 0.4295850694179535
Loss: 0.4391404688358307
Loss: 0.2836976647377014
Loss: 0.4443797469139099
Loss: 0.24124540388584137
Loss: 0.5702917575836182
Loss: 0.5069079995155334
Loss: 0.2529292702674866
Loss: 0.4049418866634369
Loss: 0.3956276774406433
Loss: 0.3319600522518158
Loss: 0.28328239917755127
Loss: 0.2621617615222931
Loss: 0.3465840816497803
Loss: 0.3771078586578369
Loss: 0.2186557948589325
Loss: 0.16690999269485474
Loss: 0.243700310587883
Loss: 0.17826059460639954
Loss: 0.4852060377597809
Loss: 0.15468211472034454
Loss: 0.4169793725013733
Loss: 0.4754458963871002
Loss: 0.3142976462841034
[Train] Epoch 21, accuracy 0.9998263888888889
[Eval] Epoch 21, loss 5.155007, accuracy 0.998264
Loss: 0.5793523788452148
Loss: 0.17689527571201324
Loss: 0.2878348231315613
Loss: 0.5098040699958801
Loss: 0.5088421702384949
Loss: 0.376229465007782
Loss: 0.21284368634223938
Loss: 0.5943616032600403
Loss: 0.31832587718963623
Loss: 0.3497786521911621
Loss: 0.17506037652492523
Loss: 0.28313955664634705
Loss: 0.4695262610912323
Loss: 0.26859089732170105
Loss: 0.33314117789268494
Loss: 0.10116439312696457
Loss: 0.1888134926557541
Loss: 0.2636183798313141
Loss: 0.4116381108760834
Loss: 0.3029085397720337
Loss: 0.2460671365261078
Loss: 0.13241197168827057
Loss: 0.2788996994495392
Loss: 0.25741735100746155
Loss: 0.3784264028072357
Loss: 0.4705759286880493
Loss: 0.2734561264514923
Loss: 0.2463858276605606
Loss: 0.1850433349609375
Loss: 0.31099769473075867
Loss: 0.25606346130371094
Loss: 0.1837800145149231
Loss: 0.5127100348472595
Loss: 0.36919206380844116
Loss: 0.463593989610672
Loss: 0.3839796781539917
Loss: 0.43067729473114014
Loss: 0.26180994510650635
Loss: 0.2537103593349457
Loss: 0.3089561462402344
Loss: 0.3731044828891754
Loss: 0.32261091470718384
Loss: 0.34631362557411194
Loss: 0.08333713561296463
Loss: 0.4215083718299866
Loss: 0.8212435245513916
Loss: 0.31864845752716064
Loss: 0.36750170588493347
Loss: 0.3155880868434906
Loss: 0.3372202515602112
Loss: 0.19317050278186798
Loss: 0.3289831578731537
Loss: 0.26770108938217163
Loss: 0.5400639772415161
Loss: 0.315230131149292
Loss: 0.4738590717315674
Loss: 0.4091510772705078
Loss: 0.38262125849723816
Loss: 0.2487073689699173
Loss: 0.4017797112464905
Loss: 0.31310558319091797
Loss: 0.43123918771743774
Loss: 0.6140049695968628
Loss: 0.2797885239124298
Loss: 0.40152597427368164
Loss: 0.42919155955314636
Loss: 0.42855706810951233
Loss: 0.19081604480743408
Loss: 0.3297674357891083
Loss: 0.7499746084213257
Loss: 0.5422597527503967
Loss: 0.10180573910474777
Loss: 0.21458634734153748
Loss: 0.30776068568229675
Loss: 0.4346126914024353
Loss: 0.5574125051498413
Loss: 0.6738510727882385
Loss: 0.27316349744796753
Loss: 0.22773656249046326
Loss: 0.22730472683906555
Loss: 0.4125744104385376
Loss: 0.3164636194705963
Loss: 0.5011090636253357
Loss: 0.34666186571121216
Loss: 0.24831219017505646
Loss: 0.2332412153482437
Loss: 0.3030756413936615
Loss: 0.44150421023368835
Loss: 0.29049935936927795
Loss: 0.0901370421051979
[Train] Epoch 22, accuracy 0.9998263888888889
[Eval] Epoch 22, loss 5.157435, accuracy 0.998264
Loss: 0.22086970508098602
Loss: 0.13089397549629211
Loss: 0.2990855276584625
Loss: 0.09587209671735764
Loss: 0.6315575838088989
Loss: 0.40368229150772095
Loss: 0.3270428478717804
Loss: 0.37645065784454346
Loss: 0.26892563700675964
Loss: 0.2438870519399643
Loss: 0.3013092875480652
Loss: 0.39510077238082886
Loss: 0.16484472155570984
Loss: 0.1611652672290802
Loss: 0.17339390516281128
Loss: 0.21277928352355957
Loss: 0.3127653896808624
Loss: 0.279067724943161
Loss: 0.45706942677497864
Loss: 0.3645794987678528
Loss: 0.3184042274951935
Loss: 0.1691853404045105
Loss: 0.34545448422431946
Loss: 0.2981378138065338
Loss: 0.2144928276538849
Loss: 0.44386112689971924
Loss: 0.6084294319152832
Loss: 0.41675934195518494
Loss: 0.14505837857723236
Loss: 0.19215761125087738
Loss: 0.6491633057594299
Loss: 0.374723881483078
Loss: 0.27049800753593445
Loss: 0.2904338240623474
Loss: 0.27389687299728394
Loss: 0.30787625908851624
Loss: 0.4805326759815216
Loss: 0.2474556416273117
Loss: 0.2995293438434601
Loss: 0.2976623773574829
Loss: 0.21684576570987701
Loss: 0.24810218811035156
Loss: 0.31017976999282837
Loss: 0.3033985197544098
Loss: 0.24919269979000092
Loss: 0.42472949624061584
Loss: 0.2980262041091919
Loss: 0.20687799155712128
Loss: 0.5408909320831299
Loss: 0.1737840622663498
Loss: 0.2709551453590393
Loss: 0.13691848516464233
Loss: 0.1640113741159439
Loss: 0.3323933184146881
Loss: 0.3526526093482971
Loss: 0.08363864570856094
Loss: 0.5420351028442383
Loss: 0.29629191756248474
Loss: 0.30360132455825806
Loss: 0.2804616391658783
Loss: 0.40372252464294434
Loss: 0.24017515778541565
Loss: 0.18614040315151215
Loss: 0.1154462993144989
Loss: 0.16432303190231323
Loss: 0.3342648446559906
Loss: 0.2534034252166748
Loss: 0.3761891722679138
Loss: 0.28214818239212036
Loss: 0.3111502528190613
Loss: 0.2837532162666321
Loss: 0.17707319557666779
Loss: 0.2008242905139923
Loss: 0.19634032249450684
Loss: 0.2925795912742615
Loss: 0.3626900315284729
Loss: 0.2970142066478729
Loss: 0.3770913779735565
Loss: 0.3115880787372589
Loss: 0.3987140655517578
Loss: 0.25046244263648987
Loss: 0.38792017102241516
Loss: 0.3323580026626587
Loss: 0.6093506217002869
Loss: 0.3103198707103729
Loss: 0.2974575161933899
Loss: 0.5555742979049683
Loss: 0.05978565290570259
Loss: 0.7274959683418274
Loss: 0.24725906550884247
[Train] Epoch 23, accuracy 0.9998263888888889
[Eval] Epoch 23, loss 5.164366, accuracy 0.997917
Loss: 0.633071780204773
Loss: 0.28292378783226013
Loss: 0.2157583236694336
Loss: 0.3440641164779663
Loss: 0.376171350479126
Loss: 0.15836812555789948
Loss: 0.6447818875312805
Loss: 0.24281452596187592
Loss: 0.2721181809902191
Loss: 0.43844419717788696
Loss: 0.30592960119247437
Loss: 0.191823348402977
Loss: 0.23118585348129272
Loss: 0.34653791785240173
Loss: 0.15190178155899048
Loss: 0.07991436123847961
Loss: 0.45559608936309814
Loss: 0.5746544599533081
Loss: 0.4245792627334595
Loss: 0.2049354463815689
Loss: 0.5498948097229004
Loss: 0.6111816763877869
Loss: 0.0802844986319542
Loss: 0.42088526487350464
Loss: 0.33081352710723877
Loss: 0.2880673110485077
Loss: 0.37929773330688477
Loss: 0.38767334818840027
Loss: 0.3734866678714752
Loss: 0.4715530574321747
Loss: 0.2939216196537018
Loss: 0.2624902129173279
Loss: 0.1654176115989685
Loss: 0.597815215587616
Loss: 0.1394425630569458
Loss: 0.31238386034965515
Loss: 0.2283744066953659
Loss: 0.24406924843788147
Loss: 0.1789684295654297
Loss: 0.22854244709014893
Loss: 0.31536710262298584
Loss: 0.18314896523952484
Loss: 0.16385722160339355
Loss: 0.31994423270225525
Loss: 0.49492713809013367
Loss: 0.5204198956489563
Loss: 0.2252543717622757
Loss: 0.4673612415790558
Loss: 0.24985338747501373
Loss: 0.30801159143447876
Loss: 0.3979223370552063
Loss: 0.16701817512512207
Loss: 0.20624397695064545
Loss: 0.6631959676742554
Loss: 0.27475008368492126
Loss: 0.29438337683677673
Loss: 0.16023093461990356
Loss: 0.3350684344768524
Loss: 0.15154579281806946
Loss: 0.4266680181026459
Loss: 0.09206004440784454
Loss: 0.21733078360557556
Loss: 0.332541286945343
Loss: 0.17906565964221954
Loss: 0.4532187879085541
Loss: 0.48911166191101074
Loss: 0.19679442048072815
Loss: 0.1853334903717041
Loss: 0.13759301602840424
Loss: 0.1949031800031662
Loss: 0.3702128231525421
Loss: 0.15389837324619293
Loss: 0.21212433278560638
Loss: 0.5396087765693665
Loss: 0.21041983366012573
Loss: 0.24376802146434784
Loss: 0.17922942340373993
Loss: 0.2287140041589737
Loss: 0.3009319007396698
Loss: 0.2958514094352722
Loss: 0.5506624579429626
Loss: 0.37720850110054016
Loss: 0.39171475172042847
Loss: 0.296190083026886
Loss: 0.268518328666687
Loss: 0.4248226583003998
Loss: 0.16001106798648834
Loss: 0.23685218393802643
Loss: 0.26087772846221924
Loss: 0.22133411467075348
[Train] Epoch 24, accuracy 0.9999131944444445
[Eval] Epoch 24, loss 5.147876, accuracy 0.998264
Loss: 0.07740989327430725
Loss: 0.30506080389022827
Loss: 0.1222793459892273
Loss: 0.11517923325300217
Loss: 0.326160728931427
Loss: 0.20113256573677063
Loss: 0.2600667476654053
Loss: 0.18961964547634125
Loss: 0.1625445932149887
Loss: 0.3558633029460907
Loss: 0.3946395516395569
Loss: 0.36737391352653503
Loss: 0.24093300104141235
Loss: 0.07556049525737762
Loss: 0.32659921050071716
Loss: 0.2879627048969269
Loss: 0.30965349078178406
Loss: 0.19145366549491882
Loss: 0.16312940418720245
Loss: 0.2856847941875458
Loss: 0.5416199564933777
Loss: 0.21799957752227783
Loss: 0.07638543844223022
Loss: 0.15384770929813385
Loss: 0.20756137371063232
Loss: 0.24424153566360474
Loss: 0.36861586570739746
Loss: 0.181389719247818
Loss: 0.10639704763889313
Loss: 0.4369690418243408
Loss: 0.5299879312515259
Loss: 0.15436235070228577
Loss: 0.12455540895462036
Loss: 0.2822868824005127
Loss: 0.290865957736969
Loss: 0.17545738816261292
Loss: 0.270497590303421
Loss: 0.3306276500225067
Loss: 0.14820188283920288
Loss: 0.21132192015647888
Loss: 0.15919572114944458
Loss: 0.26275765895843506
Loss: 0.3049149215221405
Loss: 0.3664666712284088
Loss: 0.26352211833000183
Loss: 0.21417401731014252
Loss: 0.1052701473236084
Loss: 0.4337436258792877
Loss: 0.24168746173381805
Loss: 0.40519431233406067
Loss: 0.15124523639678955
Loss: 0.2848186790943146
Loss: 0.24722617864608765
Loss: 0.07079361379146576
Loss: 0.506560742855072
Loss: 0.2750519812107086
Loss: 0.3124110996723175
Loss: 0.22244097292423248
Loss: 0.15399788320064545
Loss: 0.27209895849227905
Loss: 0.0781976506114006
Loss: 0.37843480706214905
Loss: 0.3658517897129059
Loss: 0.44532591104507446
Loss: 0.11698030680418015
Loss: 0.19864247739315033
Loss: 0.38359224796295166
Loss: 0.2124803066253662
Loss: 0.3136523365974426
Loss: 0.400362491607666
Loss: 0.20633690059185028
Loss: 0.09212519228458405
Loss: 0.509651780128479
Loss: 0.3737961947917938
Loss: 0.14125142991542816
Loss: 0.1221042200922966
Loss: 0.20810042321681976
Loss: 0.2782130539417267
Loss: 0.2989009916782379
Loss: 0.2909841239452362
Loss: 0.19201268255710602
Loss: 0.4333953559398651
Loss: 0.21346266567707062
Loss: 0.310543030500412
Loss: 0.11637496948242188
Loss: 0.295593798160553
Loss: 0.13034363090991974
Loss: 0.42649874091148376
Loss: 0.1013079285621643
Loss: 0.34314289689064026
[Train] Epoch 25, accuracy 0.9999131944444445
[Eval] Epoch 25, loss 5.152754, accuracy 0.998264
Loss: 0.13364657759666443
Loss: 0.22112196683883667
Loss: 0.3458598256111145
Loss: 0.16478218138217926
Loss: 0.2644958794116974
Loss: 0.11407102644443512
Loss: 0.284192830324173
Loss: 0.15443333983421326
Loss: 0.42991214990615845
Loss: 0.24717877805233002
Loss: 0.10509327799081802
Loss: 0.14169809222221375
Loss: 0.11566440761089325
Loss: 0.15957076847553253
Loss: 0.38006627559661865
Loss: 0.21104229986667633
Loss: 0.2815684974193573
Loss: 0.22958895564079285
Loss: 0.08544319868087769
Loss: 0.23686085641384125
Loss: 0.3177642226219177
Loss: 0.28380098938941956
Loss: 0.35214346647262573
Loss: 0.13672108948230743
Loss: 0.17313475906848907
Loss: 0.2935156524181366
Loss: 0.12142821401357651
Loss: 0.695951521396637
Loss: 0.1045142412185669
Loss: 0.17388516664505005
Loss: 0.3736423850059509
Loss: 0.10070061683654785
Loss: 0.1524285227060318
Loss: 0.2846544086933136
Loss: 0.4926954507827759
Loss: 0.43474292755126953
Loss: 0.13184386491775513
Loss: 0.15445955097675323
Loss: 0.1759290248155594
Loss: 0.2295539826154709
Loss: 0.3184222877025604
Loss: 0.22971196472644806
Loss: 0.3908972144126892
Loss: 0.21733170747756958
Loss: 0.33180564641952515
Loss: 0.20519396662712097
Loss: 0.1664068102836609
Loss: 0.17361319065093994
Loss: 0.20806461572647095
Loss: 0.07844933122396469
Loss: 0.31086891889572144
Loss: 0.1394026279449463
Loss: 0.4249931275844574
Loss: 0.1865757405757904
Loss: 0.16767649352550507
Loss: 0.1702827364206314
Loss: 0.13327816128730774
Loss: 0.20758174359798431
Loss: 0.21538645029067993
Loss: 0.2258581519126892
Loss: 0.08607914298772812
Loss: 0.22861316800117493
Loss: 0.32793551683425903
Loss: 0.1381358653306961
Loss: 0.06376919895410538
Loss: 0.3648957312107086
Loss: 0.15601611137390137
Loss: 0.06680572032928467
Loss: 0.0769258663058281
Loss: 0.34845277667045593
Loss: 0.31441205739974976
Loss: 0.19275936484336853
Loss: 0.3255775570869446
Loss: 0.2206541895866394
Loss: 0.06654392182826996
Loss: 0.1018962636590004
Loss: 0.3053797781467438
Loss: 0.1937102973461151
Loss: 0.17627225816249847
Loss: 0.03466832637786865
Loss: 0.14536337554454803
Loss: 0.2592203617095947
Loss: 0.13269978761672974
Loss: 0.2372165024280548
Loss: 0.15886320173740387
Loss: 0.06517146527767181
Loss: 0.19957521557807922
Loss: 0.46917450428009033
Loss: 0.2078646570444107
Loss: 0.05775248259305954
[Train] Epoch 26, accuracy 0.9998263888888889
[Eval] Epoch 26, loss 5.144404, accuracy 0.998264
Loss: 0.348631888628006
Loss: 0.060497429221868515
Loss: 0.19217349588871002
Loss: 0.12496088445186615
Loss: 0.24194510281085968
Loss: 0.18727245926856995
Loss: 0.16090130805969238
Loss: 0.1024121344089508
Loss: 0.14126665890216827
Loss: 0.3909447491168976
Loss: 0.08024926483631134
Loss: 0.05857079476118088
Loss: 0.1484173685312271
Loss: 0.09350403398275375
Loss: 0.13162606954574585
Loss: 0.13794226944446564
Loss: 0.3424793481826782
Loss: 0.26454728841781616
Loss: 0.29037001729011536
Loss: 0.10177136957645416
Loss: 0.2044331282377243
Loss: 0.24275189638137817
Loss: 0.22432199120521545
Loss: 0.07804366946220398
Loss: 0.20238137245178223
Loss: 0.07990719377994537
Loss: 0.12780706584453583
Loss: 0.10567385703325272
Loss: 0.1501297801733017
Loss: 0.2520589530467987
Loss: 0.262714147567749
Loss: 0.03378378599882126
Loss: 0.1683947890996933
Loss: 0.4671560823917389
Loss: 0.46010857820510864
Loss: 0.17008574306964874
Loss: 0.23300966620445251
Loss: 0.18644988536834717
Loss: 0.08940250426530838
Loss: 0.16943663358688354
Loss: 0.3138270974159241
Loss: 0.08578085899353027
Loss: 0.027327055111527443
Loss: 0.025402378290891647
Loss: 0.1375506967306137
Loss: 0.1541345715522766
Loss: 0.19337455928325653
Loss: 0.14046941697597504
Loss: 0.04935005307197571
Loss: 0.18801482021808624
Loss: 0.18917658925056458
Loss: 0.1832362413406372
Loss: 0.18529845774173737
Loss: 0.2707558572292328
Loss: 0.11945708841085434
Loss: 0.09383291006088257
Loss: 0.2315748929977417
Loss: 0.16737638413906097
Loss: 0.24368272721767426
Loss: 0.13354307413101196
Loss: 0.1367461383342743
Loss: 0.21343310177326202
Loss: 0.10756812989711761
Loss: 0.41271135210990906
Loss: 0.24154160916805267
Loss: 0.20258067548274994
Loss: 0.07127028703689575
Loss: 0.06538476049900055
Loss: 0.2585561275482178
Loss: 0.2651340365409851
Loss: 0.2758215665817261
Loss: 0.11654558032751083
Loss: 0.08584253489971161
Loss: 0.23618030548095703
Loss: 0.32784709334373474
Loss: 0.08046863973140717
Loss: 0.03193441033363342
Loss: 0.10693461447954178
Loss: 0.1578148901462555
Loss: 0.056267235428094864
Loss: 0.12101121246814728
Loss: 0.33817794919013977
Loss: 0.24219433963298798
Loss: 0.28502988815307617
Loss: 0.05577252805233002
Loss: 0.24981296062469482
Loss: 0.03080020472407341
Loss: 0.11612126231193542
Loss: 0.05531268194317818
Loss: 0.11620981246232986
[Train] Epoch 27, accuracy 0.9998263888888889
[Eval] Epoch 27, loss 5.140996, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.13216327130794525
Loss: 0.17835314571857452
Loss: 0.32174235582351685
Loss: 0.38140952587127686
Loss: 0.11761778593063354
Loss: 0.4449903070926666
Loss: 0.10671597719192505
Loss: 0.25758492946624756
Loss: 0.16858504712581635
Loss: 0.15690134465694427
Loss: 0.12002253532409668
Loss: 0.10648835450410843
Loss: 0.16304007172584534
Loss: 0.16455969214439392
Loss: 0.28221526741981506
Loss: 0.14355191588401794
Loss: 0.0824541226029396
Loss: 0.18556630611419678
Loss: 0.16505612432956696
Loss: 0.07760147750377655
Loss: 0.10415862500667572
Loss: 0.06268686056137085
Loss: 0.1005028784275055
Loss: 0.1419636607170105
Loss: 0.22569964826107025
Loss: 0.06624314188957214
Loss: 0.11760455369949341
Loss: 0.1592378467321396
Loss: 0.037612367421388626
Loss: 0.0638241320848465
Loss: 0.1741122156381607
Loss: 0.22910290956497192
Loss: 0.051223721355199814
Loss: 0.14091365039348602
Loss: 0.12376830726861954
Loss: 0.22060395777225494
Loss: 0.049263615161180496
Loss: 0.1552250236272812
Loss: 0.10828538239002228
Loss: 0.16173356771469116
Loss: 0.09588305652141571
Loss: 0.38760730624198914
Loss: 0.1164935976266861
Loss: 0.2761598825454712
Loss: 0.11424732208251953
Loss: 0.04990732669830322
Loss: 0.2744024991989136
Loss: 0.1891688108444214
Loss: 0.11334984749555588
Loss: 0.42537921667099
Loss: 0.10808228701353073
Loss: 0.024988168850541115
Loss: 0.21991291642189026
Loss: 0.25165802240371704
Loss: 0.21511298418045044
Loss: 0.2640424370765686
Loss: 0.11066922545433044
Loss: 0.02248288132250309
Loss: 0.14993123710155487
Loss: 0.2968103289604187
Loss: 0.12039641290903091
Loss: 0.1636672466993332
Loss: 0.0361715629696846
Loss: 0.344259649515152
Loss: 0.0694313794374466
Loss: 0.22126439213752747
Loss: 0.09135230630636215
Loss: 0.08371276408433914
Loss: 0.1628388911485672
Loss: 0.19398954510688782
Loss: 0.2641984522342682
Loss: 0.1898323893547058
Loss: 0.031212929636240005
Loss: 0.20078496634960175
Loss: 0.056342434138059616
Loss: 0.2023908644914627
Loss: 0.13561758399009705
Loss: 0.0833686888217926
Loss: 0.1694703847169876
Loss: 0.16052798926830292
Loss: 0.275635302066803
Loss: 0.24537967145442963
Loss: 0.1089685708284378
Loss: 0.11276378482580185
Loss: 0.22933098673820496
Loss: 0.2613578140735626
Loss: 0.15232859551906586
Loss: 0.3630220592021942
Loss: 0.17792770266532898
Loss: 0.1821950227022171
[Train] Epoch 28, accuracy 1.0
[Eval] Epoch 28, loss 5.143016, accuracy 0.998264
Loss: 0.14454065263271332
Loss: 0.2825271189212799
Loss: 0.303566038608551
Loss: 0.1998802274465561
Loss: 0.36409953236579895
Loss: 0.10487426817417145
Loss: 0.19482086598873138
Loss: 0.14298726618289948
Loss: 0.24347154796123505
Loss: 0.341444194316864
Loss: 0.28148770332336426
Loss: 0.14336372911930084
Loss: 0.3843606114387512
Loss: 0.03697981312870979
Loss: 0.12452077120542526
Loss: 0.21286562085151672
Loss: 0.054654933512210846
Loss: 0.20581954717636108
Loss: 0.03175845742225647
Loss: 0.05914023891091347
Loss: 0.18082357943058014
Loss: 0.17134162783622742
Loss: 0.12512089312076569
Loss: 0.2499009519815445
Loss: 0.09884469211101532
Loss: 0.09882519394159317
Loss: 0.3307574987411499
Loss: 0.1925620138645172
Loss: 0.08893454074859619
Loss: 0.23031923174858093
Loss: 0.08110029250383377
Loss: 0.0692344456911087
Loss: 0.19011667370796204
Loss: 0.10786071419715881
Loss: 0.05585762858390808
Loss: 0.11877395212650299
Loss: 0.10196134448051453
Loss: 0.04939720034599304
Loss: 0.10830862820148468
Loss: 0.15387564897537231
Loss: 0.029879285022616386
Loss: 0.124033622443676
Loss: 0.2314416766166687
Loss: 0.05809082090854645
Loss: 0.22274650633335114
Loss: 0.23525862395763397
Loss: 0.21781033277511597
Loss: 0.07292322814464569
Loss: 0.09100601077079773
Loss: 0.07584726065397263
Loss: 0.21321499347686768
Loss: 0.0590561144053936
Loss: 0.11420171707868576
Loss: 0.13979128003120422
Loss: 0.07167600840330124
Loss: 0.2254026234149933
Loss: 0.17369344830513
Loss: 0.21442387998104095
Loss: 0.030083095654845238
Loss: 0.11723510175943375
Loss: 0.1834436058998108
Loss: 0.19868765771389008
Loss: 0.2173471748828888
Loss: 0.1422961950302124
Loss: 0.033552221953868866
Loss: 0.10108504444360733
Loss: 0.1648045778274536
Loss: 0.16923895478248596
Loss: 0.1969018280506134
Loss: 0.029547864571213722
Loss: 0.24119064211845398
Loss: 0.2474958747625351
Loss: 0.14298060536384583
Loss: 0.13429957628250122
Loss: 0.2000841349363327
Loss: 0.21895566582679749
Loss: 0.13481295108795166
Loss: 0.24095675349235535
Loss: 0.12677359580993652
Loss: 0.23046155273914337
Loss: 0.1510506123304367
Loss: 0.0565122626721859
Loss: 0.1480606496334076
Loss: 0.20461370050907135
Loss: 0.1442732810974121
Loss: 0.10024365037679672
Loss: 0.3400346040725708
Loss: 0.524111270904541
Loss: 0.11153519153594971
Loss: 0.13784928619861603
[Train] Epoch 29, accuracy 0.9999131944444445
[Eval] Epoch 29, loss 5.141828, accuracy 0.997917
Loss: 0.2238140106201172
Loss: 0.08451321721076965
Loss: 0.1281503289937973
Loss: 0.10139150172472
Loss: 0.2133457511663437
Loss: 0.08236607909202576
Loss: 0.15278320014476776
Loss: 0.16993600130081177
Loss: 0.08259934931993484
Loss: 0.10994784533977509
Loss: 0.06878945231437683
Loss: 0.12325601279735565
Loss: 0.2510908544063568
Loss: 0.12555721402168274
Loss: 0.13715088367462158
Loss: 0.08429960161447525
Loss: 0.11348607391119003
Loss: 0.22624824941158295
Loss: 0.11206185817718506
Loss: 0.24524587392807007
Loss: 0.1734425574541092
Loss: 0.3535691201686859
Loss: 0.03747299313545227
Loss: 0.20795443654060364
Loss: 0.01050659827888012
Loss: 0.18373903632164001
Loss: 0.1263873130083084
Loss: 0.17099629342556
Loss: 0.1670973300933838
Loss: 0.1689763069152832
Loss: 0.19228723645210266
Loss: 0.10529831796884537
Loss: 0.14361892640590668
Loss: 0.2418186366558075
Loss: 0.11245313286781311
Loss: 0.12891383469104767
Loss: 0.18956275284290314
Loss: 0.03204309940338135
Loss: 0.019171947613358498
Loss: 0.23022590577602386
Loss: 0.09702203422784805
Loss: 0.23431316018104553
Loss: 0.277995228767395
Loss: 0.17009925842285156
Loss: 0.3466874957084656
Loss: 0.31873390078544617
Loss: 0.12487290799617767
Loss: 0.06398364156484604
Loss: 0.17741326987743378
Loss: 0.052079107612371445
Loss: 0.22136205434799194
Loss: 0.12462938576936722
Loss: 0.2112765610218048
Loss: 0.05893876776099205
Loss: 0.29618266224861145
Loss: 0.07507452368736267
Loss: 0.11477705836296082
Loss: 0.2294512242078781
Loss: 0.08720896393060684
Loss: 0.11750222742557526
Loss: 0.1890249252319336
Loss: 0.18890410661697388
Loss: 0.1912538707256317
Loss: 0.08269737660884857
Loss: 0.14649911224842072
Loss: 0.40704014897346497
Loss: 0.03330986201763153
Loss: 0.11528170108795166
Loss: 0.12187065929174423
Loss: 0.13830816745758057
Loss: 0.09384843707084656
Loss: 0.16785500943660736
Loss: 0.1505582630634308
Loss: 0.06484994292259216
Loss: 0.20003481209278107
Loss: 0.20290103554725647
Loss: 0.18330205976963043
Loss: 0.09641864895820618
Loss: 0.21752241253852844
Loss: 0.21006198227405548
Loss: 0.03866281360387802
Loss: 0.10863683372735977
Loss: 0.08332472294569016
Loss: 0.1300695687532425
Loss: 0.24872104823589325
Loss: 0.08035871386528015
Loss: 0.2566443085670471
Loss: 0.14625421166419983
Loss: 0.07037720084190369
Loss: 0.20031407475471497
[Train] Epoch 30, accuracy 0.9999131944444445
[Eval] Epoch 30, loss 5.140317, accuracy 0.997917
Loss: 0.33665895462036133
Loss: 0.12197449803352356
Loss: 0.10614459961652756
Loss: 0.05837700143456459
Loss: 0.10158389806747437
Loss: 0.18895623087882996
Loss: 0.16864068806171417
Loss: 0.08067288249731064
Loss: 0.09619005769491196
Loss: 0.03566670045256615
Loss: 0.15214702486991882
Loss: 0.11043719202280045
Loss: 0.14225409924983978
Loss: 0.1846114993095398
Loss: 0.1527501791715622
Loss: 0.12869790196418762
Loss: 0.09614504128694534
Loss: 0.17782138288021088
Loss: 0.04521044343709946
Loss: 0.1546207070350647
Loss: 0.03608319163322449
Loss: 0.08784447610378265
Loss: 0.1007758229970932
Loss: 0.22059406340122223
Loss: 0.189565509557724
Loss: 0.09928973019123077
Loss: 0.0694015845656395
Loss: 0.10140255093574524
Loss: 0.0945473164319992
Loss: 0.10723818838596344
Loss: 0.024934398010373116
Loss: 0.3282364308834076
Loss: 0.05849545821547508
Loss: 0.2521304786205292
Loss: 0.16516320407390594
Loss: 0.02145323157310486
Loss: 0.1457449197769165
Loss: 0.3215276002883911
Loss: 0.11050842702388763
Loss: 0.16603712737560272
Loss: 0.26007598638534546
Loss: 0.1879553198814392
Loss: 0.15416225790977478
Loss: 0.05985642969608307
Loss: 0.2521745264530182
Loss: 0.25029486417770386
Loss: 0.0776868388056755
Loss: 0.1381085067987442
Loss: 0.1869455724954605
Loss: 0.011096222326159477
Loss: 0.09997730702161789
Loss: 0.18029353022575378
Loss: 0.15307177603244781
Loss: 0.3128356635570526
Loss: 0.08921860158443451
Loss: 0.235847607254982
Loss: 0.09226295351982117
Loss: 0.08230317384004593
Loss: 0.20183467864990234
Loss: 0.08413916826248169
Loss: 0.07219716906547546
Loss: 0.1511089950799942
Loss: 0.17862647771835327
Loss: 0.0970531702041626
Loss: 0.08057566732168198
Loss: 0.09626703709363937
Loss: 0.10493988543748856
Loss: 0.04107343778014183
Loss: 0.10765417665243149
Loss: 0.15308508276939392
Loss: 0.1840590238571167
Loss: 0.07728660106658936
Loss: 0.13838019967079163
Loss: 0.022897226735949516
Loss: 0.047092255204916
Loss: 0.024108368903398514
Loss: 0.06713481992483139
Loss: 0.03153686225414276
Loss: 0.3736569285392761
Loss: 0.07792817801237106
Loss: 0.16764195263385773
Loss: 0.013392344117164612
Loss: 0.18038935959339142
Loss: 0.08516664803028107
Loss: 0.1398223489522934
Loss: 0.0531228706240654
Loss: 0.08912468701601028
Loss: 0.0800151377916336
Loss: 0.2101602554321289
Loss: 0.10749826580286026
[Train] Epoch 31, accuracy 0.9999131944444445
[Eval] Epoch 31, loss 5.136192, accuracy 0.998264
Loss: 0.041713815182447433
Loss: 0.048481956124305725
Loss: 0.11955180019140244
Loss: 0.11219771206378937
Loss: 0.06104027107357979
Loss: 0.08465791493654251
Loss: 0.05222643166780472
Loss: 0.07847536355257034
Loss: 0.06196606531739235
Loss: 0.1579243689775467
Loss: 0.07747434824705124
Loss: 0.055190559476614
Loss: 0.41903212666511536
Loss: 0.047868553549051285
Loss: 0.08354299515485764
Loss: 0.17428569495677948
Loss: 0.10824001580476761
Loss: 0.019923558458685875
Loss: 0.07369611412286758
Loss: 0.04241098091006279
Loss: 0.1789608597755432
Loss: 0.06725442409515381
Loss: 0.0399438701570034
Loss: 0.11185919493436813
Loss: 0.0849979817867279
Loss: 0.1079603061079979
Loss: 0.13148121535778046
Loss: 0.13732832670211792
Loss: 0.08602912724018097
Loss: 0.2971804738044739
Loss: 0.18774385750293732
Loss: 0.0754915326833725
Loss: 0.030441612005233765
Loss: 0.04488953575491905
Loss: 0.13078933954238892
Loss: 0.0248256865888834
Loss: 0.11697626113891602
Loss: 0.12346572428941727
Loss: 0.11659648269414902
Loss: 0.14558367431163788
Loss: 0.1038440465927124
Loss: 0.027387119829654694
Loss: 0.15567278861999512
Loss: 0.12763606011867523
Loss: 0.1293075680732727
Loss: 0.2093951553106308
Loss: 0.0177928414195776
Loss: 0.1356092095375061
Loss: 0.2653764486312866
Loss: 0.1838277280330658
Loss: 0.06104645878076553
Loss: 0.20168614387512207
Loss: 0.07074321806430817
Loss: 0.02916429005563259
Loss: 0.046691954135894775
Loss: 0.1632186621427536
Loss: 0.21205446124076843
Loss: 0.02009434439241886
Loss: 0.019192956387996674
Loss: 0.013451728038489819
Loss: 0.07268131524324417
Loss: 0.03824956342577934
Loss: 0.10646878182888031
Loss: 0.032069478183984756
Loss: 0.09085748344659805
Loss: 0.067274309694767
Loss: 0.03473399952054024
Loss: 0.11206641048192978
Loss: 0.08057229220867157
Loss: 0.056418079882860184
Loss: 0.16411560773849487
Loss: 0.11302167177200317
Loss: 0.13211475312709808
Loss: 0.16591012477874756
Loss: 0.013537938706576824
Loss: 0.208724245429039
Loss: 0.12042815238237381
Loss: 0.11010539531707764
Loss: 0.08509670197963715
Loss: 0.10464725643396378
Loss: 0.02717626839876175
Loss: 0.036887239664793015
Loss: 0.059152185916900635
Loss: 0.1935683786869049
Loss: 0.07852451503276825
Loss: 0.13058656454086304
Loss: 0.09396097809076309
Loss: 0.10021064430475235
Loss: 0.03968244045972824
Loss: 0.22303073108196259
[Train] Epoch 32, accuracy 0.9999131944444445
[Eval] Epoch 32, loss 5.127891, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.2314625233411789
Loss: 0.03350064530968666
Loss: 0.1207108348608017
Loss: 0.030057530850172043
Loss: 0.18948085606098175
Loss: 0.008169527165591717
Loss: 0.028626663610339165
Loss: 0.106442391872406
Loss: 0.15581341087818146
Loss: 0.1579350382089615
Loss: 0.027788875624537468
Loss: 0.0623217411339283
Loss: 0.08244577050209045
Loss: 0.051807701587677
Loss: 0.10824909061193466
Loss: 0.14886541664600372
Loss: 0.15863044559955597
Loss: 0.3572506606578827
Loss: 0.11968715488910675
Loss: 0.020241254940629005
Loss: 0.16138671338558197
Loss: 0.04897688329219818
Loss: 0.06756754964590073
Loss: 0.12906686961650848
Loss: 0.1184956282377243
Loss: 0.036543529480695724
Loss: 0.18907208740711212
Loss: 0.22891175746917725
Loss: 0.019363822415471077
Loss: 0.0416489839553833
Loss: 0.05960867181420326
Loss: 0.19431307911872864
Loss: 0.04188325256109238
Loss: 0.03520562872290611
Loss: 0.02742394432425499
Loss: 0.12961316108703613
Loss: 0.12759289145469666
Loss: 0.08882679045200348
Loss: 0.18481087684631348
Loss: 0.06586075574159622
Loss: 0.09503497928380966
Loss: 0.22298775613307953
Loss: 0.2625560462474823
Loss: 0.03187376260757446
Loss: 0.08168022334575653
Loss: 0.07918635755777359
Loss: 0.05063195526599884
Loss: 0.07000739127397537
Loss: 0.052427150309085846
Loss: 0.018474480137228966
Loss: 0.06147284433245659
Loss: 0.07343383133411407
Loss: 0.1203007772564888
Loss: 0.013538245111703873
Loss: 0.11924014240503311
Loss: 0.12577247619628906
Loss: 0.05104395002126694
Loss: 0.04517528414726257
Loss: 0.10093893855810165
Loss: 0.12087466567754745
Loss: 0.08002505451440811
Loss: 0.0649319738149643
Loss: 0.04406886547803879
Loss: 0.14800670742988586
Loss: 0.015705179423093796
Loss: 0.015066483058035374
Loss: 0.08549102395772934
Loss: 0.009181613102555275
Loss: 0.10702802985906601
Loss: 0.05664181709289551
Loss: 0.0862271785736084
Loss: 0.2023598700761795
Loss: 0.01932343654334545
Loss: 0.16033925116062164
Loss: 0.08540091663599014
Loss: 0.16996242105960846
Loss: 0.21952591836452484
Loss: 0.01704050786793232
Loss: 0.01550706010311842
Loss: 0.04395827651023865
Loss: 0.18887975811958313
Loss: 0.14697949588298798
Loss: 0.07601957768201828
Loss: 0.18103332817554474
Loss: 0.16555404663085938
Loss: 0.07363177835941315
Loss: 0.12741374969482422
Loss: 0.07925689965486526
Loss: 0.027715256437659264
Loss: 0.02086525224149227
[Train] Epoch 33, accuracy 0.9999131944444445
[Eval] Epoch 33, loss 5.130890, accuracy 0.998264
Loss: 0.21415288746356964
Loss: 0.007829630747437477
Loss: 0.05579547584056854
Loss: 0.012062469497323036
Loss: 0.04407048597931862
Loss: 0.23633447289466858
Loss: 0.03173036873340607
Loss: 0.21367298066616058
Loss: 0.04215039312839508
Loss: 0.05549772456288338
Loss: 0.23403076827526093
Loss: 0.18114638328552246
Loss: 0.0862870141863823
Loss: 0.12939193844795227
Loss: 0.09255722165107727
Loss: 0.036697302013635635
Loss: 0.09292986243963242
Loss: 0.033784009516239166
Loss: 0.13685427606105804
Loss: 0.009669213555753231
Loss: 0.0922248512506485
Loss: 0.26290348172187805
Loss: 0.0574234202504158
Loss: 0.18682298064231873
Loss: 0.05051693320274353
Loss: 0.06144900992512703
Loss: 0.22584356367588043
Loss: 0.19526271522045135
Loss: 0.011932477355003357
Loss: 0.10151337832212448
Loss: 0.10818014293909073
Loss: 0.024495523422956467
Loss: 0.04531269147992134
Loss: 0.04570303112268448
Loss: 0.10465733706951141
Loss: 0.17049533128738403
Loss: 0.22913797199726105
Loss: 0.04352515563368797
Loss: 0.07516921311616898
Loss: 0.021526044234633446
Loss: 0.09886123239994049
Loss: 0.206258162856102
Loss: 0.1412624716758728
Loss: 0.031199147924780846
Loss: 0.12155711650848389
Loss: 0.09015563875436783
Loss: 0.10201381146907806
Loss: 0.07052154093980789
Loss: 0.04521860182285309
Loss: 0.03888968750834465
Loss: 0.06900250166654587
Loss: 0.08882211148738861
Loss: 0.03976541385054588
Loss: 0.029366975650191307
Loss: 0.1188967376947403
Loss: 0.11702070385217667
Loss: 0.03863823413848877
Loss: 0.2062852531671524
Loss: 0.10877282172441483
Loss: 0.06173308193683624
Loss: 0.030458873137831688
Loss: 0.010473629459738731
Loss: 0.12002970278263092
Loss: 0.058967769145965576
Loss: 0.08239398896694183
Loss: 0.04648078605532646
Loss: 0.039356984198093414
Loss: 0.08564430475234985
Loss: 0.1183638870716095
Loss: 0.13028216361999512
Loss: 0.09748807549476624
Loss: 0.11908037215471268
Loss: 0.09267033636569977
Loss: 0.10104606300592422
Loss: 0.029986176639795303
Loss: 0.019983544945716858
Loss: 0.09577752649784088
Loss: 0.06629312038421631
Loss: 0.12372458726167679
Loss: 0.15149125456809998
Loss: 0.1225188598036766
Loss: 0.03235836699604988
Loss: 0.03970586135983467
Loss: 0.16594766080379486
Loss: 0.09592804312705994
Loss: 0.03913981467485428
Loss: 0.09906091541051865
Loss: 0.3187756836414337
Loss: 0.03229696676135063
Loss: 0.09065781533718109
[Train] Epoch 34, accuracy 1.0
[Eval] Epoch 34, loss 5.141550, accuracy 0.998611
Loss: 0.018876053392887115
Loss: 0.017925100401043892
Loss: 0.21112172305583954
Loss: 0.023955192416906357
Loss: 0.06878545880317688
Loss: 0.13461342453956604
Loss: 0.04946346580982208
Loss: 0.10620598495006561
Loss: 0.11200354993343353
Loss: 0.12785430252552032
Loss: 0.14221863448619843
Loss: 0.04437742754817009
Loss: 0.01634722761809826
Loss: 0.06510821729898453
Loss: 0.035186413675546646
Loss: 0.060748279094696045
Loss: 0.1366676390171051
Loss: 0.10514180362224579
Loss: 0.011671112850308418
Loss: 0.03188866004347801
Loss: 0.08489803969860077
Loss: 0.06926680356264114
Loss: 0.1636287420988083
Loss: 0.09478636831045151
Loss: 0.13839083909988403
Loss: 0.019281750544905663
Loss: 0.17132392525672913
Loss: 0.0780511200428009
Loss: 0.12896175682544708
Loss: 0.04565455764532089
Loss: 0.00410526292398572
Loss: 0.10089975595474243
Loss: 0.0203761737793684
Loss: 0.06658501923084259
Loss: 0.20827414095401764
Loss: 0.039909157902002335
Loss: 0.07342203706502914
Loss: 0.12157581001520157
Loss: 0.06914600729942322
Loss: 0.22658559679985046
Loss: 0.3007536828517914
Loss: 0.08580855280160904
Loss: 0.08423871546983719
Loss: 0.07013150304555893
Loss: 0.15754088759422302
Loss: 0.026259727776050568
Loss: 0.10114888101816177
Loss: 0.035671938210725784
Loss: 0.17810851335525513
Loss: 0.3191656470298767
Loss: 0.10638061910867691
Loss: 0.10097372531890869
Loss: 0.014428825117647648
Loss: 0.17707079648971558
Loss: 0.06398554891347885
Loss: 0.08480393886566162
Loss: 0.10729158669710159
Loss: 0.15438733994960785
Loss: 0.008295235224068165
Loss: 0.04795317351818085
Loss: 0.051518432796001434
Loss: 0.037958137691020966
Loss: 0.15740253031253815
Loss: 0.10497371107339859
Loss: 0.04597488418221474
Loss: 0.038582172244787216
Loss: 0.047438789159059525
Loss: 0.03914496675133705
Loss: 0.10089010745286942
Loss: 0.005099736154079437
Loss: 0.08766477555036545
Loss: 0.11199267953634262
Loss: 0.06565535068511963
Loss: 0.16772884130477905
Loss: 0.05909081548452377
Loss: 0.1337200254201889
Loss: 0.06418965011835098
Loss: 0.027442913502454758
Loss: 0.1528748720884323
Loss: 0.1369248628616333
Loss: 0.14456325769424438
Loss: 0.08023000508546829
Loss: 0.06048084422945976
Loss: 0.013652571476995945
Loss: 0.166991725564003
Loss: 0.01983226090669632
Loss: 0.2179822474718094
Loss: 0.1735294759273529
Loss: 0.1383146345615387
Loss: 0.017694957554340363
[Train] Epoch 35, accuracy 0.9999131944444445
[Eval] Epoch 35, loss 5.128476, accuracy 0.998264
Loss: 0.047509778290987015
Loss: 0.025099467486143112
Loss: 0.08195939660072327
Loss: 0.08545581996440887
Loss: 0.012857599183917046
Loss: 0.06721547245979309
Loss: 0.07544621080160141
Loss: 0.04586780071258545
Loss: 0.07602210342884064
Loss: 0.024239785969257355
Loss: 0.045823317021131516
Loss: 0.011359584517776966
Loss: 0.10256155580282211
Loss: 0.020875200629234314
Loss: 0.11659033596515656
Loss: 0.172407329082489
Loss: 0.20220237970352173
Loss: 0.025334984064102173
Loss: 0.06305903941392899
Loss: 0.01018126867711544
Loss: 0.18807072937488556
Loss: 0.006808902602642775
Loss: 0.04119099676609039
Loss: 0.06099684536457062
Loss: 0.02341669611632824
Loss: 0.180711567401886
Loss: 0.01643998548388481
Loss: 0.021020641550421715
Loss: 0.03663722053170204
Loss: 0.2050616592168808
Loss: 0.04041241854429245
Loss: 0.0319490022957325
Loss: 0.07264996320009232
Loss: 0.02292419970035553
Loss: 0.1240333691239357
Loss: 0.09372025728225708
Loss: 0.10339584946632385
Loss: 0.08363189548254013
Loss: 0.0182520542293787
Loss: 0.13321611285209656
Loss: 0.06887983530759811
Loss: 0.014423826709389687
Loss: 0.16292530298233032
Loss: 0.028316687792539597
Loss: 0.12247869372367859
Loss: 0.10622797906398773
Loss: 0.09231401234865189
Loss: 0.23610331118106842
Loss: 0.00944290030747652
Loss: 0.07829582691192627
Loss: 0.13162489235401154
Loss: 0.06475048512220383
Loss: 0.05513758584856987
Loss: 0.17739109694957733
Loss: 0.08668970316648483
Loss: 0.01554503757506609
Loss: 0.04407987743616104
Loss: 0.042826663702726364
Loss: 0.07255975157022476
Loss: 0.07727359235286713
Loss: 0.024554023519158363
Loss: 0.04796036332845688
Loss: 0.20697976648807526
Loss: 0.052515167742967606
Loss: 0.10714422166347504
Loss: 0.03627358376979828
Loss: 0.21970702707767487
Loss: 0.07515747100114822
Loss: 0.09818217903375626
Loss: 0.049509935081005096
Loss: 0.06213543936610222
Loss: 0.07842879742383957
Loss: 0.09248539060354233
Loss: 0.17705745995044708
Loss: 0.008818437345325947
Loss: 0.07702463865280151
Loss: 0.22486235201358795
Loss: 0.020286519080400467
Loss: 0.027642052620649338
Loss: 0.08008643239736557
Loss: 0.06480857729911804
Loss: 0.06133856996893883
Loss: 0.003117592306807637
Loss: 0.04712459444999695
Loss: 0.05147838592529297
Loss: 0.009245838969945908
Loss: 0.17531439661979675
Loss: 0.01638949289917946
Loss: 0.06926371902227402
Loss: 0.037798017263412476
[Train] Epoch 36, accuracy 1.0
[Eval] Epoch 36, loss 5.125825, accuracy 0.997917
Loss: 0.08346008509397507
Loss: 0.04847012460231781
Loss: 0.03613532334566116
Loss: 0.0035920776426792145
Loss: 0.009568467736244202
Loss: 0.0688670352101326
Loss: 0.09679809957742691
Loss: 0.00920881237834692
Loss: 0.045508768409490585
Loss: 0.11847080290317535
Loss: 0.0849834606051445
Loss: 0.13371436297893524
Loss: 0.15529589354991913
Loss: 0.041231606155633926
Loss: 0.07923449575901031
Loss: 0.008878401480615139
Loss: 0.06225752457976341
Loss: 0.050235047936439514
Loss: 0.011126496829092503
Loss: 0.005593074019998312
Loss: 0.04590025916695595
Loss: 0.0358768031001091
Loss: 0.022234836593270302
Loss: 0.03339255601167679
Loss: 0.07415670901536942
Loss: 0.009883406572043896
Loss: 0.07867854088544846
Loss: 0.19864167273044586
Loss: 0.06849893927574158
Loss: 0.03360235318541527
Loss: 0.022446036338806152
Loss: 0.055178917944431305
Loss: 0.056865353137254715
Loss: 0.1803998500108719
Loss: 0.010098690167069435
Loss: 0.025473367422819138
Loss: 0.16821648180484772
Loss: 0.012294604443013668
Loss: 0.009956899099051952
Loss: 0.027839085087180138
Loss: 0.014239265583455563
Loss: 0.11408531665802002
Loss: 0.048256050795316696
Loss: 0.03306293860077858
Loss: 0.06742238253355026
Loss: 0.008763008750975132
Loss: 0.04990647733211517
Loss: 0.0628196969628334
Loss: 0.012645761482417583
Loss: 0.027372099459171295
Loss: 0.1700349599123001
Loss: 0.05784205347299576
Loss: 0.09748304635286331
Loss: 0.0779658779501915
Loss: 0.016382453963160515
Loss: 0.025967897847294807
Loss: 0.03502697870135307
Loss: 0.02703189104795456
Loss: 0.0441836416721344
Loss: 0.08422313630580902
Loss: 0.018491055816411972
Loss: 0.03272676840424538
Loss: 0.07358957827091217
Loss: 0.05347627028822899
Loss: 0.009774846956133842
Loss: 0.036260850727558136
Loss: 0.055673036724328995
Loss: 0.006229780148714781
Loss: 0.0704583004117012
Loss: 0.07169177383184433
Loss: 0.08315344899892807
Loss: 0.051241807639598846
Loss: 0.03604937717318535
Loss: 0.09220661967992783
Loss: 0.1427210420370102
Loss: 0.058971162885427475
Loss: 0.032936956733465195
Loss: 0.18287813663482666
Loss: 0.047121867537498474
Loss: 0.012171901762485504
Loss: 0.038700658828020096
Loss: 0.08188054710626602
Loss: 0.014640877954661846
Loss: 0.060728829354047775
Loss: 0.10295441001653671
Loss: 0.04438687860965729
Loss: 0.013998191803693771
Loss: 0.044243477284908295
Loss: 0.05218536779284477
Loss: 0.07132072001695633
[Train] Epoch 37, accuracy 1.0
[Eval] Epoch 37, loss 5.119364, accuracy 0.998264
Loss: 0.05478507652878761
Loss: 0.042717643082141876
Loss: 0.051056016236543655
Loss: 0.006673954892903566
Loss: 0.02279275469481945
Loss: 0.03738200291991234
Loss: 0.09116247296333313
Loss: 0.05925450474023819
Loss: 0.05477171391248703
Loss: 0.023577166721224785
Loss: 0.11379977315664291
Loss: 0.0707329511642456
Loss: 0.013169783167541027
Loss: 0.1103319451212883
Loss: 0.036059826612472534
Loss: 0.0016096850158646703
Loss: 0.08227961510419846
Loss: 0.010841562412679195
Loss: 0.022667258977890015
Loss: 0.0060409377329051495
Loss: 0.0622473880648613
Loss: 0.07206570357084274
Loss: 0.08782593160867691
Loss: 0.07411231845617294
Loss: 0.013433105312287807
Loss: 0.12998484075069427
Loss: 0.14388065040111542
Loss: 0.16638575494289398
Loss: 0.0818786546587944
Loss: 0.009826608002185822
Loss: 0.14647021889686584
Loss: 0.05572468414902687
Loss: 0.07900353521108627
Loss: 0.030643559992313385
Loss: 0.02014823630452156
Loss: 0.0350751094520092
Loss: 0.15107594430446625
Loss: 0.007503115106374025
Loss: 0.007147484924644232
Loss: 0.057571522891521454
Loss: 0.06900288164615631
Loss: 0.1563153862953186
Loss: 0.027606628835201263
Loss: 0.14940306544303894
Loss: 0.028474081307649612
Loss: 0.12882842123508453
Loss: 0.14326907694339752
Loss: 0.023884031921625137
Loss: 0.09635366499423981
Loss: 0.03024912439286709
Loss: 0.06314093619585037
Loss: 0.1408337503671646
Loss: 0.019248731434345245
Loss: 0.12255841493606567
Loss: 0.00214612134732306
Loss: 0.03969497233629227
Loss: 0.041975975036621094
Loss: 0.11563550680875778
Loss: 0.03492126613855362
Loss: 0.27907562255859375
Loss: 0.07297290861606598
Loss: 0.0849059596657753
Loss: 0.07430719584226608
Loss: 0.08586648851633072
Loss: 0.09657195210456848
Loss: 0.05138741061091423
Loss: 0.03844471275806427
Loss: 0.05469723045825958
Loss: 0.04228115826845169
Loss: 0.02824847213923931
Loss: 0.11128633469343185
Loss: 0.01902962476015091
Loss: 0.04658149182796478
Loss: 0.23260101675987244
Loss: 0.014748858287930489
Loss: 0.06807033717632294
Loss: 0.08106769621372223
Loss: 0.02680368162691593
Loss: 0.03404315188527107
Loss: 0.06627649068832397
Loss: 0.12232862412929535
Loss: 0.0737762525677681
Loss: 0.049283500760793686
Loss: 0.0072129773907363415
Loss: 0.08259019255638123
Loss: 0.04721863940358162
Loss: 0.16113068163394928
Loss: 0.08804146200418472
Loss: 0.20328165590763092
Loss: 0.053042929619550705
[Train] Epoch 38, accuracy 1.0
[Eval] Epoch 38, loss 5.133984, accuracy 0.998264
Loss: 0.08885984122753143
Loss: 0.06444846838712692
Loss: 0.031680840998888016
Loss: 0.016435516998171806
Loss: 0.017094023525714874
Loss: 0.06464836001396179
Loss: 0.11051180958747864
Loss: 0.06700699776411057
Loss: 0.006708457134664059
Loss: 0.05426346883177757
Loss: 0.1187843456864357
Loss: 0.08498956263065338
Loss: 0.1669704169034958
Loss: 0.048784758895635605
Loss: 0.07178864628076553
Loss: 0.03511922061443329
Loss: 0.12462588399648666
Loss: 0.05585762858390808
Loss: 0.12460668385028839
Loss: 0.1974327117204666
Loss: 0.003959176130592823
Loss: 0.06996574997901917
Loss: 0.07062949985265732
Loss: 0.09776773303747177
Loss: 0.05588154494762421
Loss: 0.07801243662834167
Loss: 0.0312577486038208
Loss: 0.01511793676763773
Loss: 0.10440120846033096
Loss: 0.04334569349884987
Loss: 0.07323123514652252
Loss: 0.047975413501262665
Loss: 0.10089906305074692
Loss: 0.05390116944909096
Loss: 0.25264492630958557
Loss: 0.006945779547095299
Loss: 0.06456859409809113
Loss: 0.0344596728682518
Loss: 0.07989145815372467
Loss: 0.20114536583423615
Loss: 0.02517814002931118
Loss: 0.1399378925561905
Loss: 0.13375017046928406
Loss: 0.01557956077158451
Loss: 0.08727122098207474
Loss: 0.07803370803594589
Loss: 0.00559797091409564
Loss: 0.07096150517463684
Loss: 0.04182266816496849
Loss: 0.08428547531366348
Loss: 0.008255638182163239
Loss: 0.016600828617811203
Loss: 0.17552606761455536
Loss: 0.001039138762280345
Loss: 0.05260593444108963
Loss: 0.005296013783663511
Loss: 0.053074631839990616
Loss: 0.03873062506318092
Loss: 0.0552859902381897
Loss: 0.008576053194701672
Loss: 0.04006147012114525
Loss: 0.04562622681260109
Loss: 0.03529031574726105
Loss: 0.012613408267498016
Loss: 0.03055587224662304
Loss: 0.033261992037296295
Loss: 0.057156387716531754
Loss: 0.04725230857729912
Loss: 0.07192412763834
Loss: 0.07628562301397324
Loss: 0.01851353608071804
Loss: 0.2126442790031433
Loss: 0.020215613767504692
Loss: 0.030691303312778473
Loss: 0.05656309053301811
Loss: 0.04370877146720886
Loss: 0.0189498458057642
Loss: 0.08970453590154648
Loss: 0.035452619194984436
Loss: 0.025511475279927254
Loss: 0.17693403363227844
Loss: 0.08146640658378601
Loss: 0.0031517120078206062
Loss: 0.0030880477279424667
Loss: 0.01808943599462509
Loss: 0.008755690418183804
Loss: 0.06225396692752838
Loss: 0.02587301656603813
Loss: 0.024724092334508896
Loss: 0.15100684762001038
[Train] Epoch 39, accuracy 1.0
[Eval] Epoch 39, loss 5.121164, accuracy 0.998264
Loss: 0.026760851964354515
Loss: 0.019700592383742332
Loss: 0.020297987386584282
Loss: 0.014734161086380482
Loss: 0.03504049405455589
Loss: 0.011773773469030857
Loss: 0.008373639546334743
Loss: 0.00898395013064146
Loss: 0.0079668452963233
Loss: 0.044977832585573196
Loss: 0.034000955522060394
Loss: 0.017482440918684006
Loss: 0.0183721836656332
Loss: 0.011025546118617058
Loss: 0.07389158755540848
Loss: 0.0644402876496315
Loss: 0.05471872165799141
Loss: 0.034944046288728714
Loss: 0.027143796905875206
Loss: 0.04350683465600014
Loss: 0.0361759215593338
Loss: 0.053987618535757065
Loss: 0.006019020918756723
Loss: 0.003354282584041357
Loss: 0.02449919655919075
Loss: 0.07284236699342728
Loss: 0.013502627611160278
Loss: 0.011759540066123009
Loss: 0.027115637436509132
Loss: 0.042479462921619415
Loss: 0.06029114872217178
Loss: 0.013833301141858101
Loss: 0.006226696074008942
Loss: 0.19660766422748566
Loss: 0.051221031695604324
Loss: 0.027408387511968613
Loss: 0.1271381974220276
Loss: 0.0841749981045723
Loss: 0.07641789317131042
Loss: 0.07188986241817474
Loss: 0.08987163007259369
Loss: 0.03761610388755798
Loss: 0.02361960895359516
Loss: 0.009499129839241505
Loss: 0.004940913990139961
Loss: 0.022455962374806404
Loss: 0.025324387475848198
Loss: 0.011569554917514324
Loss: 0.01310943253338337
Loss: 0.005343303084373474
Loss: 0.007395414635539055
Loss: 0.020961083471775055
Loss: 0.009932000190019608
Loss: 0.0031951337587088346
Loss: 0.004888680763542652
Loss: 0.14381378889083862
Loss: 0.007681719493120909
Loss: 0.05352739989757538
Loss: 0.01430045161396265
Loss: 0.03141384199261665
Loss: 0.0387258380651474
Loss: 0.04851676523685455
Loss: 0.013076511211693287
Loss: 0.02707592584192753
Loss: 0.013816878199577332
Loss: 0.03954977169632912
Loss: 0.14581406116485596
Loss: 0.15502935647964478
Loss: 0.08835494518280029
Loss: 0.10405196249485016
Loss: 0.03490547463297844
Loss: 0.004495217464864254
Loss: 0.025458477437496185
Loss: 0.0027825371362268925
Loss: 0.10426396876573563
Loss: 0.08142256736755371
Loss: 0.04919937625527382
Loss: 0.05825551599264145
Loss: 0.19762355089187622
Loss: 0.07005191594362259
Loss: 0.1286308765411377
Loss: 0.11673751473426819
Loss: 0.08561115711927414
Loss: 0.0068422723561525345
Loss: 0.021000783890485764
Loss: 0.0405299998819828
Loss: 0.12460532039403915
Loss: 0.028440987691283226
Loss: 0.014365899376571178
Loss: 0.031804248690605164
[Train] Epoch 40, accuracy 1.0
[Eval] Epoch 40, loss 5.128496, accuracy 0.998264
Loss: 0.12757380306720734
Loss: 0.038411010056734085
Loss: 0.07224712520837784
Loss: 0.12124611437320709
Loss: 0.01860702969133854
Loss: 0.03966999426484108
Loss: 0.0015239289496093988
Loss: 0.0032253717072308064
Loss: 0.11859285086393356
Loss: 0.09550438821315765
Loss: 0.0013660464901477098
Loss: 0.035142023116350174
Loss: 0.17490549385547638
Loss: 0.09498785436153412
Loss: 0.0536787174642086
Loss: 0.016451695933938026
Loss: 0.03272702917456627
Loss: 0.039431631565093994
Loss: 0.04099123552441597
Loss: 0.258108913898468
Loss: 0.038481853902339935
Loss: 0.010802696458995342
Loss: 0.048098739236593246
Loss: 0.04719116538763046
Loss: 0.013313421979546547
Loss: 0.039894949644804
Loss: 0.10160514712333679
Loss: 0.06262204051017761
Loss: 0.052706167101860046
Loss: 0.014039439149200916
Loss: 0.0907035619020462
Loss: 0.03163500502705574
Loss: 0.019015837460756302
Loss: 0.010251948609948158
Loss: 0.038675811141729355
Loss: 0.11123260110616684
Loss: 0.05356432870030403
Loss: 0.029108131304383278
Loss: 0.013147343881428242
Loss: 0.0034455929417163134
Loss: 0.004286557901650667
Loss: 0.012470507062971592
Loss: 0.0022844288032501936
Loss: 0.007562599610537291
Loss: 0.008594417944550514
Loss: 0.010035298764705658
Loss: 0.015648584812879562
Loss: 0.0460970513522625
Loss: 0.012746855616569519
Loss: 0.007189885247498751
Loss: 0.14793343842029572
Loss: 0.05963520333170891
Loss: 0.09048628062009811
Loss: 0.007416676729917526
Loss: 0.01859084516763687
Loss: 0.05666784569621086
Loss: 0.0166353527456522
Loss: 0.0858505442738533
Loss: 0.009450845420360565
Loss: 0.04549651965498924
Loss: 0.07829133421182632
Loss: 0.02547108754515648
Loss: 0.030481692403554916
Loss: 0.002677702810615301
Loss: 0.0335717611014843
Loss: 0.04497387632727623
Loss: 0.0637609213590622
Loss: 0.0399869866669178
Loss: 0.015984898433089256
Loss: 0.052259139716625214
Loss: 0.07220984250307083
Loss: 0.04123665392398834
Loss: 0.024652324616909027
Loss: 0.009502182714641094
Loss: 0.07168789952993393
Loss: 0.026728283613920212
Loss: 0.01066860556602478
Loss: 0.0477786548435688
Loss: 0.0226567592471838
Loss: 0.01911277323961258
Loss: 0.0024992942344397306
Loss: 0.0797726958990097
Loss: 0.012104933150112629
Loss: 0.015536186285316944
Loss: 0.01247403770685196
Loss: 0.015490062534809113
Loss: 0.007190584670752287
Loss: 0.04413086920976639
Loss: 0.007400549482554197
Loss: 0.007025271188467741
[Train] Epoch 41, accuracy 1.0
[Eval] Epoch 41, loss 5.119658, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.0313715860247612
Loss: 0.22003652155399323
Loss: 0.029715321958065033
Loss: 0.028478406369686127
Loss: 0.0017574331723153591
Loss: 0.026728926226496696
Loss: 0.006198415998369455
Loss: 0.022290438413619995
Loss: 0.004015262704342604
Loss: 0.0038585658185184
Loss: 0.0725005567073822
Loss: 0.09949996322393417
Loss: 0.04197395220398903
Loss: 0.07468407601118088
Loss: 0.08986009657382965
Loss: 0.0451168492436409
Loss: 0.0012697696220129728
Loss: 0.026513632386922836
Loss: 0.04329146817326546
Loss: 0.030970610678195953
Loss: 0.06215948238968849
Loss: 0.07360035926103592
Loss: 0.01157588791102171
Loss: 0.016782909631729126
Loss: 0.030976930633187294
Loss: 0.004740988370031118
Loss: 0.1629483997821808
Loss: 0.028268305584788322
Loss: 0.003039661096408963
Loss: 0.02449045330286026
Loss: 0.04988902807235718
Loss: 0.01833784393966198
Loss: 0.0192146897315979
Loss: 0.03224772959947586
Loss: 0.026852255687117577
Loss: 0.15586459636688232
Loss: 0.06549280881881714
Loss: 0.007735255640000105
Loss: 0.12127520889043808
Loss: 0.00739929499104619
Loss: 0.1120995357632637
Loss: 0.04553627967834473
Loss: 0.0048875827342271805
Loss: 0.08315512537956238
Loss: 0.03597104921936989
Loss: 0.11320769786834717
Loss: 0.01720556989312172
Loss: 0.016796892508864403
Loss: 0.2539079189300537
Loss: 0.043454233556985855
Loss: 0.03420673683285713
Loss: 0.1795586794614792
Loss: 0.15654820203781128
Loss: 0.05001739785075188
Loss: 0.002352014183998108
Loss: 0.03146551921963692
Loss: 0.011308860965073109
Loss: 0.03771401196718216
Loss: 0.07731504738330841
Loss: 0.0552331805229187
Loss: 0.006280103698372841
Loss: 0.016178088262677193
Loss: 0.005103288684040308
Loss: 0.021094685420393944
Loss: 0.060664817690849304
Loss: 0.039303719997406006
Loss: 0.08925041556358337
Loss: 0.1832626312971115
Loss: 0.010070031508803368
Loss: 0.008763114921748638
Loss: 0.07756870239973068
Loss: 0.01811068505048752
Loss: 0.002450313651934266
Loss: 0.05221595615148544
Loss: 0.008459534496068954
Loss: 0.04709092900156975
Loss: 0.004857683088630438
Loss: 0.005643975455313921
Loss: 0.003855679649859667
Loss: 0.006316634826362133
Loss: 0.07182411849498749
Loss: 0.03379424661397934
Loss: 0.022165073081851006
Loss: 0.02445538528263569
Loss: 0.04428079351782799
Loss: 0.007631970103830099
Loss: 0.0005254388670437038
Loss: 0.02747489884495735
Loss: 0.054877374321222305
Loss: 0.07174058258533478
[Train] Epoch 42, accuracy 1.0
[Eval] Epoch 42, loss 5.120412, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.10357377678155899
Loss: 0.00969207938760519
Loss: 0.07996270805597305
Loss: 0.006646725814789534
Loss: 0.07258976995944977
Loss: 0.006056451238691807
Loss: 0.001801026752218604
Loss: 0.005559555254876614
Loss: 0.035306647419929504
Loss: 0.0075583928264677525
Loss: 0.00983520969748497
Loss: 0.07774343341588974
Loss: 0.007007972802966833
Loss: 0.08096340298652649
Loss: 0.12829619646072388
Loss: 0.06956472992897034
Loss: 0.02911071665585041
Loss: 0.058701612055301666
Loss: 0.01348701398819685
Loss: 0.04067012295126915
Loss: 0.014350561425089836
Loss: 0.028045132756233215
Loss: 0.09458288550376892
Loss: 0.14644695818424225
Loss: 0.015293575823307037
Loss: 0.013772300444543362
Loss: 0.021366393193602562
Loss: 0.00906035490334034
Loss: 0.016216415911912918
Loss: 0.004202278330922127
Loss: 0.006070127710700035
Loss: 0.011288686655461788
Loss: 0.005345648154616356
Loss: 0.0024693452287465334
Loss: 0.04511099308729172
Loss: 0.23401756584644318
Loss: 0.02386646904051304
Loss: 0.00987006351351738
Loss: 0.0747298076748848
Loss: 0.01715279556810856
Loss: 0.003515461226925254
Loss: 0.05550076439976692
Loss: 0.012031054124236107
Loss: 0.004293575417250395
Loss: 0.022134216502308846
Loss: 0.016347242519259453
Loss: 0.007359775714576244
Loss: 0.019849149510264397
Loss: 0.022561974823474884
Loss: 0.05000681057572365
Loss: 0.046550650149583817
Loss: 0.017710471525788307
Loss: 0.11435575783252716
Loss: 0.003919783979654312
Loss: 0.04125097393989563
Loss: 0.10779210925102234
Loss: 0.004141479730606079
Loss: 0.0454183965921402
Loss: 0.003713951911777258
Loss: 0.08636260032653809
Loss: 0.03812479227781296
Loss: 0.009121520444750786
Loss: 0.001771997194737196
Loss: 0.0400509275496006
Loss: 0.07384270429611206
Loss: 0.006471121683716774
Loss: 0.0067711216397583485
Loss: 0.024092573672533035
Loss: 0.019950535148382187
Loss: 0.009894395247101784
Loss: 0.05187484249472618
Loss: 0.004913485608994961
Loss: 0.0021203255746513605
Loss: 0.132673978805542
Loss: 0.01252754032611847
Loss: 0.0023445419501513243
Loss: 0.03947692736983299
Loss: 0.04852558299899101
Loss: 0.08374589681625366
Loss: 0.02410404197871685
Loss: 0.10686708241701126
Loss: 0.0010546338744461536
Loss: 0.001321588410064578
Loss: 0.024446817114949226
Loss: 0.0074781994335353374
Loss: 0.01625136472284794
Loss: 0.08578312397003174
Loss: 0.021998031064867973
Loss: 0.15760010480880737
Loss: 0.05115533620119095
[Train] Epoch 43, accuracy 1.0
[Eval] Epoch 43, loss 5.120560, accuracy 0.999306
Loss: 0.07418603450059891
Loss: 0.06919877231121063
Loss: 0.008600393310189247
Loss: 0.013689656741917133
Loss: 0.011319701559841633
Loss: 0.010036187246441841
Loss: 0.026940062642097473
Loss: 0.005353046581149101
Loss: 0.026118358597159386
Loss: 0.007987852208316326
Loss: 0.03310612961649895
Loss: 0.027617530897259712
Loss: 0.07408410310745239
Loss: 0.02727207913994789
Loss: 0.015942946076393127
Loss: 0.10767775774002075
Loss: 0.05484870448708534
Loss: 0.021749626845121384
Loss: 0.03522695228457451
Loss: 0.03613542392849922
Loss: 0.021640729159116745
Loss: 0.09984143078327179
Loss: 0.052914172410964966
Loss: 0.033616408705711365
Loss: 0.03845704719424248
Loss: 0.07187470048666
Loss: 0.009064804762601852
Loss: 0.0667506530880928
Loss: 0.1089068353176117
Loss: 0.0015207019168883562
Loss: 0.07745024561882019
Loss: 0.002549889963120222
Loss: 0.002981743076816201
Loss: 0.007767774630337954
Loss: 0.023301342502236366
Loss: 0.10861741751432419
Loss: 0.10537441819906235
Loss: 0.0037684638518840075
Loss: 0.007504444569349289
Loss: 0.08060905337333679
Loss: 0.06170417740941048
Loss: 0.07070000469684601
Loss: 0.0016888233367353678
Loss: 0.046168409287929535
Loss: 0.0195270124822855
Loss: 0.06479893624782562
Loss: 0.02550472877919674
Loss: 0.002299005864188075
Loss: 0.004622547421604395
Loss: 0.0009749221499077976
Loss: 0.06533636152744293
Loss: 0.05318472534418106
Loss: 0.08172399550676346
Loss: 0.06198640912771225
Loss: 0.022893326357007027
Loss: 0.015656230971217155
Loss: 0.010559020563960075
Loss: 0.004089789465069771
Loss: 0.012038830667734146
Loss: 0.030019551515579224
Loss: 0.01837942749261856
Loss: 0.03383190929889679
Loss: 0.008144612424075603
Loss: 0.20685604214668274
Loss: 0.056469108909368515
Loss: 0.027875296771526337
Loss: 0.009450148791074753
Loss: 0.005054600071161985
Loss: 0.0032786682713776827
Loss: 0.036759667098522186
Loss: 0.015969669446349144
Loss: 0.008324802853167057
Loss: 0.026638517156243324
Loss: 0.014206966385245323
Loss: 0.007941054180264473
Loss: 0.006551999598741531
Loss: 0.0029645271133631468
Loss: 0.0036775474436581135
Loss: 0.014277204871177673
Loss: 0.004768477287143469
Loss: 0.012525958009064198
Loss: 0.00991750881075859
Loss: 0.08602030575275421
Loss: 0.04012499749660492
Loss: 0.015465108677744865
Loss: 0.0013545880792662501
Loss: 0.06079282611608505
Loss: 0.0474935919046402
Loss: 0.030867943540215492
Loss: 0.0415169894695282
[Train] Epoch 44, accuracy 1.0
[Eval] Epoch 44, loss 5.119641, accuracy 0.998958
Loss: 0.040808457881212234
Loss: 0.004096470773220062
Loss: 0.06051326543092728
Loss: 0.013890061527490616
Loss: 0.0652148649096489
Loss: 0.009341200813651085
Loss: 0.06256578117609024
Loss: 0.09453748911619186
Loss: 0.0526604987680912
Loss: 0.0052606998942792416
Loss: 0.03080042265355587
Loss: 0.04633685201406479
Loss: 0.010839641094207764
Loss: 0.008658342994749546
Loss: 0.05647410452365875
Loss: 0.06256401538848877
Loss: 0.014249238185584545
Loss: 0.06383853405714035
Loss: 0.05392792075872421
Loss: 0.03358179330825806
Loss: 0.025409778580069542
Loss: 0.009675650857388973
Loss: 0.019224034622311592
Loss: 0.04972065985202789
Loss: 0.03114594705402851
Loss: 0.08123349398374557
Loss: 0.016374783590435982
Loss: 0.01669277809560299
Loss: 0.031076015904545784
Loss: 0.05478833243250847
Loss: 0.07014964520931244
Loss: 0.05302095785737038
Loss: 0.011183703318238258
Loss: 0.056418269872665405
Loss: 0.03271093964576721
Loss: 0.014775604009628296
Loss: 0.012327960692346096
Loss: 0.00173370901029557
Loss: 0.02884218841791153
Loss: 0.0027275588363409042
Loss: 0.0010447290260344744
Loss: 0.010822983458638191
Loss: 0.00675513781607151
Loss: 0.12568658590316772
Loss: 0.0056594256311655045
Loss: 0.007097659166902304
Loss: 0.012305501848459244
Loss: 0.012178225442767143
Loss: 0.012514999136328697
Loss: 0.011405768804252148
Loss: 0.00835033506155014
Loss: 0.025608355179429054
Loss: 0.06198897957801819
Loss: 0.005516480188816786
Loss: 0.007464038673788309
Loss: 0.06636098772287369
Loss: 0.010838747024536133
Loss: 0.008586885407567024
Loss: 0.0033655089791864157
Loss: 0.008640232495963573
Loss: 0.0584297776222229
Loss: 0.013129686005413532
Loss: 0.0030062575824558735
Loss: 0.007334727793931961
Loss: 0.01037656981498003
Loss: 0.01729782670736313
Loss: 0.03818998858332634
Loss: 0.001234231749549508
Loss: 0.014685104601085186
Loss: 0.06613704562187195
Loss: 0.023261569440364838
Loss: 0.018392683938145638
Loss: 0.0014577743131667376
Loss: 0.08281247317790985
Loss: 0.022525863721966743
Loss: 0.015115591697394848
Loss: 0.004374281037598848
Loss: 0.0007132610189728439
Loss: 0.007731723133474588
Loss: 0.00563422217965126
Loss: 0.05068766698241234
Loss: 0.037969961762428284
Loss: 0.023521125316619873
Loss: 0.0030713805463165045
Loss: 0.024459606036543846
Loss: 0.0486873984336853
Loss: 0.01603722758591175
Loss: 0.12202661484479904
Loss: 0.006246685516089201
Loss: 0.019069166854023933
[Train] Epoch 45, accuracy 1.0
[Eval] Epoch 45, loss 5.121555, accuracy 0.998611
Loss: 0.013986771926283836
Loss: 0.014141769148409367
Loss: 0.05194583535194397
Loss: 0.031133456155657768
Loss: 0.01980133168399334
Loss: 0.028827356174588203
Loss: 0.11227448284626007
Loss: 0.0265671219676733
Loss: 0.0822761207818985
Loss: 0.005444778595119715
Loss: 0.047729216516017914
Loss: 0.009770584292709827
Loss: 0.007958212867379189
Loss: 0.0023983032442629337
Loss: 0.007161297835409641
Loss: 0.03575136512517929
Loss: 0.003066836856305599
Loss: 0.0020151345524936914
Loss: 0.005992022808641195
Loss: 0.017286961898207664
Loss: 0.006067993585020304
Loss: 0.02790307253599167
Loss: 0.012910707853734493
Loss: 0.03536069765686989
Loss: 0.00845218263566494
Loss: 0.013133727014064789
Loss: 0.053388651460409164
Loss: 0.02582825906574726
Loss: 0.0016678139800205827
Loss: 0.025669464841485023
Loss: 0.028015123680233955
Loss: 0.019743001088500023
Loss: 0.001591206411831081
Loss: 0.056039124727249146
Loss: 0.05807894840836525
Loss: 0.020237835124135017
Loss: 0.030660083517432213
Loss: 0.09278630465269089
Loss: 0.0030945560429245234
Loss: 0.09213361889123917
Loss: 0.0012970600510016084
Loss: 0.0030550125520676374
Loss: 0.019662324339151382
Loss: 0.02002839744091034
Loss: 0.004866369999945164
Loss: 0.05087043344974518
Loss: 0.04042677953839302
Loss: 0.019061114639043808
Loss: 0.05352848395705223
Loss: 0.0043459986336529255
Loss: 0.006790689192712307
Loss: 0.005285969469696283
Loss: 0.011436298489570618
Loss: 0.08362998068332672
Loss: 0.010257587768137455
Loss: 0.0014262598706409335
Loss: 0.02205735072493553
Loss: 0.07615330070257187
Loss: 0.017490215599536896
Loss: 0.0008124279556795955
Loss: 0.02929210476577282
Loss: 0.055502716451883316
Loss: 0.06217646226286888
Loss: 0.030993036925792694
Loss: 0.09389171004295349
Loss: 0.04737997055053711
Loss: 0.019068723544478416
Loss: 0.02499350719153881
Loss: 0.0028605505358427763
Loss: 0.024815963581204414
Loss: 0.0379638746380806
Loss: 0.046439629048109055
Loss: 0.003283543512225151
Loss: 0.0015674125170335174
Loss: 0.03507426008582115
Loss: 0.02053721435368061
Loss: 0.021505357697606087
Loss: 0.003369046375155449
Loss: 0.002311247866600752
Loss: 0.04190835729241371
Loss: 0.004450993146747351
Loss: 0.02668233960866928
Loss: 0.014955664053559303
Loss: 0.027154719457030296
Loss: 0.0019792558159679174
Loss: 0.12099724262952805
Loss: 0.016857817769050598
Loss: 0.0021991522517055273
Loss: 0.016920533031225204
Loss: 0.021654421463608742
[Train] Epoch 46, accuracy 1.0
[Eval] Epoch 46, loss 5.116475, accuracy 0.998264
Loss: 0.05308062210679054
Loss: 0.11836213618516922
Loss: 0.03221810236573219
Loss: 0.02029886096715927
Loss: 0.017400650307536125
Loss: 0.010774537920951843
Loss: 0.02980872057378292
Loss: 0.013064781203866005
Loss: 0.026950813829898834
Loss: 0.048728618770837784
Loss: 0.00511927530169487
Loss: 0.09485726058483124
Loss: 0.0017846486298367381
Loss: 0.003070328151807189
Loss: 0.07589243352413177
Loss: 0.00445958599448204
Loss: 0.0016202789265662432
Loss: 0.006131818518042564
Loss: 0.018915271386504173
Loss: 0.006958473939448595
Loss: 0.0017034746706485748
Loss: 0.01692802831530571
Loss: 0.002553205704316497
Loss: 0.014058486558496952
Loss: 0.008698815479874611
Loss: 0.017000019550323486
Loss: 0.014479831792414188
Loss: 0.0493956096470356
Loss: 0.01622701622545719
Loss: 0.027561163529753685
Loss: 0.0014001254457980394
Loss: 0.0022795922122895718
Loss: 0.09054918587207794
Loss: 0.008823427371680737
Loss: 0.026951195672154427
Loss: 0.0012497007846832275
Loss: 0.040933359414339066
Loss: 0.035151731222867966
Loss: 0.030847355723381042
Loss: 0.006032466888427734
Loss: 0.009943889454007149
Loss: 0.03510340303182602
Loss: 0.007571774534881115
Loss: 0.02019542083144188
Loss: 0.01823263242840767
Loss: 0.025895819067955017
Loss: 0.011567385867238045
Loss: 0.008889663964509964
Loss: 0.06475236266851425
Loss: 0.04742199555039406
Loss: 0.013986210338771343
Loss: 0.03462078049778938
Loss: 0.03226884454488754
Loss: 0.0017505389405414462
Loss: 0.009498262777924538
Loss: 0.005828969180583954
Loss: 0.009421085938811302
Loss: 0.03283902630209923
Loss: 0.003273374866694212
Loss: 0.021127456799149513
Loss: 0.003553390735760331
Loss: 0.01458312664180994
Loss: 0.023463424295186996
Loss: 0.0008594741811975837
Loss: 0.0023718092124909163
Loss: 0.003247553249821067
Loss: 0.014144708402454853
Loss: 0.01107204332947731
Loss: 0.00198775390163064
Loss: 0.00842479057610035
Loss: 0.028573600575327873
Loss: 0.010301196947693825
Loss: 0.012973912991583347
Loss: 0.040783047676086426
Loss: 0.0029150680638849735
Loss: 0.0031270449981093407
Loss: 0.018263230100274086
Loss: 0.006001658737659454
Loss: 0.017036378383636475
Loss: 0.006172703113406897
Loss: 0.03362414985895157
Loss: 0.0025559705682098866
Loss: 0.13162903487682343
Loss: 0.11772522330284119
Loss: 0.013098113238811493
Loss: 0.03973374515771866
Loss: 0.0474068745970726
Loss: 0.04058195650577545
Loss: 0.014648539945483208
Loss: 0.043912384659051895
[Train] Epoch 47, accuracy 1.0
[Eval] Epoch 47, loss 5.112879, accuracy 0.998611
Loss: 0.017854658886790276
Loss: 0.04901215806603432
Loss: 0.035569656640291214
Loss: 0.04308737441897392
Loss: 0.01583414524793625
Loss: 0.03967592865228653
Loss: 0.20153650641441345
Loss: 0.06301435083150864
Loss: 0.03163178637623787
Loss: 0.0024828955065459013
Loss: 0.0059490688145160675
Loss: 0.0027226083911955357
Loss: 0.005131817888468504
Loss: 0.017450813204050064
Loss: 0.008710197173058987
Loss: 0.005576610565185547
Loss: 0.004034525714814663
Loss: 0.0014982642605900764
Loss: 0.0316433385014534
Loss: 0.054507944732904434
Loss: 0.07796930521726608
Loss: 0.009662024676799774
Loss: 0.005561960395425558
Loss: 0.018195878714323044
Loss: 0.10410713404417038
Loss: 0.061282142996788025
Loss: 0.03580872341990471
Loss: 0.0016165527049452066
Loss: 0.009027044288814068
Loss: 0.025684859603643417
Loss: 0.06024949997663498
Loss: 0.003934816457331181
Loss: 0.019072532653808594
Loss: 0.010684765875339508
Loss: 0.0240595955401659
Loss: 0.03878836706280708
Loss: 0.054762739688158035
Loss: 0.038837771862745285
Loss: 0.010503415949642658
Loss: 0.0052243489772081375
Loss: 0.016990050673484802
Loss: 0.0011767635587602854
Loss: 0.0173727385699749
Loss: 0.007159329950809479
Loss: 0.003417715895920992
Loss: 0.041526395827531815
Loss: 0.0018951852107420564
Loss: 0.06426335871219635
Loss: 0.002752755070105195
Loss: 0.031170101836323738
Loss: 0.0004394666466396302
Loss: 0.04223551228642464
Loss: 0.11963893473148346
Loss: 0.10178428143262863
Loss: 0.0009227548725903034
Loss: 0.04280347377061844
Loss: 0.03707768768072128
Loss: 0.0412101224064827
Loss: 0.02963220328092575
Loss: 0.030601685866713524
Loss: 0.01281227171421051
Loss: 0.04829341918230057
Loss: 0.020663000643253326
Loss: 0.04832429438829422
Loss: 0.14102286100387573
Loss: 0.05072666332125664
Loss: 0.01717047207057476
Loss: 0.02618720382452011
Loss: 0.012203948572278023
Loss: 0.0009429202764295042
Loss: 0.011374503374099731
Loss: 0.002404294442385435
Loss: 0.00540390657261014
Loss: 0.0037542120553553104
Loss: 0.007765386253595352
Loss: 0.0028797094710171223
Loss: 0.032502129673957825
Loss: 0.05364412069320679
Loss: 0.012929036282002926
Loss: 0.008444609120488167
Loss: 0.0022568190470337868
Loss: 0.0005917276139371097
Loss: 0.07356180250644684
Loss: 0.0015731807798147202
Loss: 0.009468099102377892
Loss: 0.04492007568478584
Loss: 0.009122065268456936
Loss: 0.036343395709991455
Loss: 0.003121288027614355
Loss: 0.0645388811826706
[Train] Epoch 48, accuracy 1.0
[Eval] Epoch 48, loss 5.116083, accuracy 0.998611
Loss: 0.019574467092752457
Loss: 0.06240333989262581
Loss: 0.02289164625108242
Loss: 0.0008931308402679861
Loss: 0.003208087058737874
Loss: 0.011772786267101765
Loss: 0.0005741793429479003
Loss: 0.00027223126380704343
Loss: 0.010938314720988274
Loss: 0.01147033553570509
Loss: 0.03585001081228256
Loss: 0.03922208771109581
Loss: 0.0245685838162899
Loss: 0.008776888251304626
Loss: 0.0017699202289804816
Loss: 0.03304564580321312
Loss: 0.012082692235708237
Loss: 0.008667150512337685
Loss: 0.005726807285100222
Loss: 0.01298367790877819
Loss: 0.008670873939990997
Loss: 0.005146967247128487
Loss: 0.003902442054823041
Loss: 0.0019756953697651625
Loss: 0.026129787787795067
Loss: 0.010844499804079533
Loss: 0.029393620789051056
Loss: 0.010078156366944313
Loss: 0.08088777214288712
Loss: 0.001700350665487349
Loss: 0.004612353164702654
Loss: 0.006697815377265215
Loss: 0.0282950010150671
Loss: 0.01744011603295803
Loss: 0.001354409847408533
Loss: 0.010394158773124218
Loss: 0.01422305777668953
Loss: 0.01206649374216795
Loss: 0.004143870901316404
Loss: 0.05632777139544487
Loss: 0.007095576263964176
Loss: 0.0015829267213121057
Loss: 0.006298376247286797
Loss: 0.009660815820097923
Loss: 0.020863763988018036
Loss: 0.00684897368773818
Loss: 0.0011360736098140478
Loss: 0.04083295911550522
Loss: 0.0050216903910040855
Loss: 0.012088224291801453
Loss: 0.0796462744474411
Loss: 0.008040969260036945
Loss: 0.02759680338203907
Loss: 0.021628789603710175
Loss: 0.004390386864542961
Loss: 0.008578998036682606
Loss: 0.0007869161199778318
Loss: 0.007645650766789913
Loss: 0.00413940055295825
Loss: 0.04052795097231865
Loss: 0.0006447144551202655
Loss: 0.005543812178075314
Loss: 0.0030921350698918104
Loss: 0.0005898158415220678
Loss: 0.06976913660764694
Loss: 0.002006837632507086
Loss: 0.013356033712625504
Loss: 0.004208992701023817
Loss: 0.012738904915750027
Loss: 0.018345922231674194
Loss: 0.006615160033106804
Loss: 0.012119599618017673
Loss: 0.0027517960406839848
Loss: 0.013764851726591587
Loss: 0.011161583475768566
Loss: 0.019945666193962097
Loss: 0.027806619182229042
Loss: 0.05226742848753929
Loss: 0.00854545272886753
Loss: 0.01311412826180458
Loss: 0.014528794214129448
Loss: 0.02407190576195717
Loss: 0.005600547883659601
Loss: 0.000545945658814162
Loss: 0.007096024230122566
Loss: 0.0019515064777806401
Loss: 0.014042455703020096
Loss: 0.0046727885492146015
Loss: 0.049887120723724365
Loss: 0.014246051199734211
[Train] Epoch 49, accuracy 1.0
[Eval] Epoch 49, loss 5.112830, accuracy 0.998611
Loss: 0.015623954124748707
Loss: 0.0030773996841162443
Loss: 0.011928724125027657
Loss: 0.0029663422610610723
Loss: 0.003384408075362444
Loss: 0.001665501855313778
Loss: 0.025071993470191956
Loss: 0.026319434866309166
Loss: 0.008614100515842438
Loss: 0.0037876716814935207
Loss: 0.08749578893184662
Loss: 0.03516204282641411
Loss: 0.028329776600003242
Loss: 0.0030076594557613134
Loss: 0.001392294536344707
Loss: 0.0007666777237318456
Loss: 0.004633609671145678
Loss: 0.047651637345552444
Loss: 0.0021763138938695192
Loss: 0.036462534219026566
Loss: 0.01352881919592619
Loss: 0.013918441720306873
Loss: 0.003016899572685361
Loss: 0.0739661157131195
Loss: 0.0003312502522021532
Loss: 0.013952521607279778
Loss: 0.004424527287483215
Loss: 0.03183458000421524
Loss: 0.0010860009351745248
Loss: 0.03842883184552193
Loss: 0.004332392476499081
Loss: 0.002054918557405472
Loss: 0.007065651938319206
Loss: 0.030435822904109955
Loss: 0.011770029552280903
Loss: 0.011657110415399075
Loss: 0.005698888096958399
Loss: 0.0018042512238025665
Loss: 0.02867249771952629
Loss: 0.0005364713724702597
Loss: 0.00939926691353321
Loss: 0.007378119509667158
Loss: 0.004896276164799929
Loss: 0.050205305218696594
Loss: 0.0039825281128287315
Loss: 0.031801193952560425
Loss: 0.03180807828903198
Loss: 0.006453456357121468
Loss: 0.002401839243248105
Loss: 0.0755881741642952
Loss: 0.13062214851379395
Loss: 0.007437624502927065
Loss: 0.011434870772063732
Loss: 0.021749865263700485
Loss: 0.03784443438053131
Loss: 0.0003999017644673586
Loss: 0.0075125438161194324
Loss: 0.010386820882558823
Loss: 0.06501786410808563
Loss: 0.04586617648601532
Loss: 0.027916673570871353
Loss: 0.00327183841727674
Loss: 0.040132392197847366
Loss: 0.018711300566792488
Loss: 0.020499657839536667
Loss: 0.02261449582874775
Loss: 0.006480222102254629
Loss: 0.006248597055673599
Loss: 0.017621682956814766
Loss: 0.023269055411219597
Loss: 0.006285260431468487
Loss: 0.0012163115898147225
Loss: 0.009656975045800209
Loss: 0.08746073395013809
Loss: 0.0028210876043885946
Loss: 0.013556140474975109
Loss: 0.007107450161129236
Loss: 0.08885557949542999
Loss: 0.00978283304721117
Loss: 0.020395513623952866
Loss: 0.026284564286470413
Loss: 0.0016588801518082619
Loss: 0.007442778442054987
Loss: 0.02836713194847107
Loss: 0.002696382347494364
Loss: 0.02751714177429676
Loss: 0.006326325703412294
Loss: 0.03979067504405975
Loss: 0.035176780074834824
Loss: 0.01775771751999855
[Train] Epoch 50, accuracy 1.0
[Eval] Epoch 50, loss 5.112531, accuracy 0.998264
Best accuracy: 0.999306
Loss: 38.420040130615234
Loss: 38.572593688964844
Loss: 38.744163513183594
Loss: 38.31746292114258
Loss: 38.608272552490234
Loss: 38.9196662902832
Loss: 38.53191375732422
Loss: 38.426605224609375
Loss: 38.54882049560547
Loss: 38.677921295166016
Loss: 38.399803161621094
Loss: 38.12709045410156
Loss: 38.36720657348633
Loss: 38.42959976196289
Loss: 37.97496795654297
Loss: 38.01813888549805
Loss: 38.23638153076172
Loss: 37.96742248535156
Loss: 38.29779052734375
Loss: 38.00236892700195
Loss: 38.03508758544922
Loss: 38.07714080810547
Loss: 38.10023880004883
Loss: 37.82948684692383
Loss: 38.4749641418457
Loss: 37.812408447265625
Loss: 38.06460189819336
Loss: 37.87009811401367
Loss: 37.9407958984375
Loss: 37.95186996459961
Loss: 37.82634735107422
Loss: 37.88471221923828
Loss: 37.923179626464844
Loss: 37.677371978759766
Loss: 37.97356033325195
Loss: 37.93838119506836
Loss: 37.74275207519531
Loss: 37.60313034057617
Loss: 37.90949249267578
Loss: 37.916439056396484
Loss: 37.72038650512695
Loss: 37.4874267578125
Loss: 37.533721923828125
Loss: 37.444976806640625
Loss: 37.46066665649414
Loss: 37.35098648071289
Loss: 37.70553970336914
Loss: 37.426143646240234
Loss: 37.668739318847656
Loss: 37.4112548828125
Loss: 37.32103729248047
Loss: 37.61038589477539
Loss: 37.492469787597656
Loss: 37.70130157470703
Loss: 37.373023986816406
Loss: 37.27872848510742
Loss: 37.24507141113281
Loss: 37.25029754638672
Loss: 37.32975387573242
Loss: 37.4119758605957
Loss: 37.33444595336914
Loss: 37.3272819519043
Loss: 37.088768005371094
Loss: 37.33613967895508
Loss: 37.41617965698242
Loss: 37.481380462646484
Loss: 37.54462814331055
Loss: 37.38340759277344
Loss: 37.26601028442383
Loss: 37.20181655883789
Loss: 37.19956588745117
Loss: 37.287353515625
Loss: 37.09407424926758
Loss: 37.15083312988281
Loss: 37.25519561767578
Loss: 37.08395004272461
Loss: 37.1787223815918
Loss: 37.40398025512695
Loss: 37.14772415161133
Loss: 37.300289154052734
Loss: 37.52723693847656
Loss: 37.48707962036133
Loss: 37.235687255859375
Loss: 37.052223205566406
Loss: 37.43684005737305
Loss: 37.58769226074219
Loss: 37.24422073364258
Loss: 37.38594436645508
Loss: 37.060203552246094
Loss: 37.2545166015625
[Train] Epoch 1, accuracy 0.0066840277777777775
[Eval] Epoch 1, loss 5.877460, accuracy 0.010764
Model saved as x_small_model_weights_best.pth
Loss: 37.205928802490234
Loss: 37.300392150878906
Loss: 37.06135177612305
Loss: 37.098793029785156
Loss: 37.46272659301758
Loss: 37.51722717285156
Loss: 37.12032699584961
Loss: 37.53539276123047
Loss: 37.034393310546875
Loss: 37.33241653442383
Loss: 37.25210189819336
Loss: 37.12663269042969
Loss: 37.39369583129883
Loss: 37.285526275634766
Loss: 37.04682159423828
Loss: 37.47028732299805
Loss: 37.32628631591797
Loss: 37.02511978149414
Loss: 37.18364715576172
Loss: 37.249732971191406
Loss: 37.4765510559082
Loss: 36.85196304321289
Loss: 37.23054885864258
Loss: 36.99165725708008
Loss: 37.28750228881836
Loss: 37.23369598388672
Loss: 37.351348876953125
Loss: 37.29072952270508
Loss: 36.914772033691406
Loss: 36.9520149230957
Loss: 37.14186096191406
Loss: 37.05137252807617
Loss: 36.97748947143555
Loss: 36.63827133178711
Loss: 37.148170471191406
Loss: 37.610443115234375
Loss: 36.89237976074219
Loss: 36.9248046875
Loss: 37.044429779052734
Loss: 36.69823455810547
Loss: 36.92477798461914
Loss: 36.70806884765625
Loss: 36.874855041503906
Loss: 37.151241302490234
Loss: 36.838584899902344
Loss: 37.006675720214844
Loss: 37.19091033935547
Loss: 36.81301498413086
Loss: 37.074363708496094
Loss: 36.706092834472656
Loss: 36.797943115234375
Loss: 36.6998291015625
Loss: 36.722137451171875
Loss: 36.892555236816406
Loss: 36.645652770996094
Loss: 36.63173294067383
Loss: 36.89197540283203
Loss: 36.66072082519531
Loss: 36.523765563964844
Loss: 36.583984375
Loss: 36.58127975463867
Loss: 36.418060302734375
Loss: 36.92864990234375
Loss: 36.611167907714844
Loss: 36.44316101074219
Loss: 36.511173248291016
Loss: 36.62308883666992
Loss: 36.36980438232422
Loss: 36.84121322631836
Loss: 36.494144439697266
Loss: 36.2457389831543
Loss: 36.44400405883789
Loss: 36.30803298950195
Loss: 35.93897247314453
Loss: 36.13047790527344
Loss: 36.04790115356445
Loss: 36.136417388916016
Loss: 36.22029495239258
Loss: 36.275882720947266
Loss: 36.10734176635742
Loss: 36.23081970214844
Loss: 36.03252410888672
Loss: 35.86255645751953
Loss: 35.885215759277344
Loss: 35.69580078125
Loss: 35.83405685424805
Loss: 35.84565353393555
Loss: 35.76080322265625
Loss: 35.839664459228516
Loss: 35.446739196777344
[Train] Epoch 2, accuracy 0.041666666666666664
[Eval] Epoch 2, loss 5.824893, accuracy 0.156944
Model saved as x_small_model_weights_best.pth
Loss: 35.27680587768555
Loss: 35.53645706176758
Loss: 35.534950256347656
Loss: 34.855804443359375
Loss: 35.66181182861328
Loss: 35.46446990966797
Loss: 35.332977294921875
Loss: 34.886531829833984
Loss: 35.38501739501953
Loss: 35.4918098449707
Loss: 34.94049835205078
Loss: 35.16500473022461
Loss: 35.074337005615234
Loss: 35.20859909057617
Loss: 34.77940368652344
Loss: 34.58961486816406
Loss: 34.62995147705078
Loss: 34.75810623168945
Loss: 34.72058868408203
Loss: 34.646305084228516
Loss: 34.728389739990234
Loss: 34.87202453613281
Loss: 34.55061340332031
Loss: 34.60382080078125
Loss: 34.84920883178711
Loss: 34.44786071777344
Loss: 34.83761978149414
Loss: 34.904296875
Loss: 34.01469421386719
Loss: 34.04445266723633
Loss: 34.044612884521484
Loss: 34.60218048095703
Loss: 34.39019775390625
Loss: 33.22856140136719
Loss: 34.27132797241211
Loss: 33.91944122314453
Loss: 34.25846481323242
Loss: 33.7556037902832
Loss: 33.725276947021484
Loss: 33.10337829589844
Loss: 33.14411926269531
Loss: 33.168724060058594
Loss: 33.891902923583984
Loss: 33.313045501708984
Loss: 34.014766693115234
Loss: 32.980323791503906
Loss: 33.11137771606445
Loss: 33.4661750793457
Loss: 33.48270797729492
Loss: 33.154205322265625
Loss: 33.43888473510742
Loss: 33.02901077270508
Loss: 32.60347366333008
Loss: 33.41371154785156
Loss: 33.28402328491211
Loss: 33.35906219482422
Loss: 31.914363861083984
Loss: 33.2938346862793
Loss: 32.87031555175781
Loss: 31.82073211669922
Loss: 31.95194435119629
Loss: 32.00102233886719
Loss: 32.508819580078125
Loss: 32.56455993652344
Loss: 31.195249557495117
Loss: 31.43604850769043
Loss: 31.86991310119629
Loss: 31.566577911376953
Loss: 31.282197952270508
Loss: 30.990747451782227
Loss: 31.24526023864746
Loss: 31.139875411987305
Loss: 31.871376037597656
Loss: 31.332035064697266
Loss: 31.735795974731445
Loss: 30.85457420349121
Loss: 30.26481056213379
Loss: 30.12823486328125
Loss: 31.140213012695312
Loss: 29.89177131652832
Loss: 30.407711029052734
Loss: 29.858642578125
Loss: 30.37516975402832
Loss: 29.89134407043457
Loss: 29.769546508789062
Loss: 30.340896606445312
Loss: 30.188518524169922
Loss: 29.374847412109375
Loss: 30.045560836791992
Loss: 29.556468963623047
[Train] Epoch 3, accuracy 0.4046875
[Eval] Epoch 3, loss 5.610920, accuracy 0.735764
Model saved as x_small_model_weights_best.pth
Loss: 28.676876068115234
Loss: 27.89235496520996
Loss: 28.783111572265625
Loss: 27.58014678955078
Loss: 28.727540969848633
Loss: 27.530315399169922
Loss: 27.5037841796875
Loss: 27.660078048706055
Loss: 27.060527801513672
Loss: 26.369869232177734
Loss: 28.357704162597656
Loss: 26.899137496948242
Loss: 27.68354034423828
Loss: 28.268991470336914
Loss: 27.508525848388672
Loss: 26.92806625366211
Loss: 27.167659759521484
Loss: 26.737485885620117
Loss: 26.93832015991211
Loss: 27.61678123474121
Loss: 26.584436416625977
Loss: 26.39461898803711
Loss: 26.967052459716797
Loss: 27.019371032714844
Loss: 26.77802276611328
Loss: 25.477819442749023
Loss: 27.14419174194336
Loss: 25.79692840576172
Loss: 27.099849700927734
Loss: 25.944068908691406
Loss: 26.913429260253906
Loss: 26.178190231323242
Loss: 26.285198211669922
Loss: 27.65653419494629
Loss: 25.977760314941406
Loss: 27.342649459838867
Loss: 24.873926162719727
Loss: 25.269882202148438
Loss: 24.35087776184082
Loss: 24.825498580932617
Loss: 25.651504516601562
Loss: 25.073238372802734
Loss: 24.80682373046875
Loss: 26.205102920532227
Loss: 25.006752014160156
Loss: 24.783334732055664
Loss: 25.911270141601562
Loss: 24.539653778076172
Loss: 24.333206176757812
Loss: 23.91594696044922
Loss: 22.68109130859375
Loss: 23.512025833129883
Loss: 25.58484649658203
Loss: 23.13884925842285
Loss: 23.052413940429688
Loss: 24.43922996520996
Loss: 23.51885986328125
Loss: 23.548095703125
Loss: 24.997486114501953
Loss: 25.179336547851562
Loss: 23.32083511352539
Loss: 23.09973907470703
Loss: 23.47319793701172
Loss: 25.248594284057617
Loss: 22.569311141967773
Loss: 23.154571533203125
Loss: 22.199203491210938
Loss: 23.107149124145508
Loss: 24.116689682006836
Loss: 21.50539207458496
Loss: 22.68606185913086
Loss: 23.117801666259766
Loss: 22.209848403930664
Loss: 22.463958740234375
Loss: 23.16866111755371
Loss: 22.654321670532227
Loss: 23.738033294677734
Loss: 22.12619972229004
Loss: 22.365245819091797
Loss: 22.57786750793457
Loss: 21.985416412353516
Loss: 21.468894958496094
Loss: 21.516260147094727
Loss: 21.44021987915039
Loss: 22.307491302490234
Loss: 21.30921745300293
Loss: 21.0815372467041
Loss: 20.603816986083984
Loss: 21.71649169921875
Loss: 21.083820343017578
[Train] Epoch 4, accuracy 0.8188368055555556
[Eval] Epoch 4, loss 5.441124, accuracy 0.940625
Model saved as x_small_model_weights_best.pth
Loss: 19.50552749633789
Loss: 20.556842803955078
Loss: 19.873762130737305
Loss: 19.605937957763672
Loss: 20.209810256958008
Loss: 21.612003326416016
Loss: 18.383432388305664
Loss: 19.477144241333008
Loss: 18.497440338134766
Loss: 18.47844123840332
Loss: 18.880935668945312
Loss: 19.67637062072754
Loss: 18.372407913208008
Loss: 18.844125747680664
Loss: 19.8371639251709
Loss: 17.5792179107666
Loss: 18.127944946289062
Loss: 18.9791202545166
Loss: 19.364118576049805
Loss: 17.76297950744629
Loss: 19.619600296020508
Loss: 17.93057632446289
Loss: 18.698957443237305
Loss: 19.246841430664062
Loss: 18.942285537719727
Loss: 18.6712589263916
Loss: 18.43109130859375
Loss: 18.363405227661133
Loss: 15.921457290649414
Loss: 18.574491500854492
Loss: 18.165454864501953
Loss: 18.692686080932617
Loss: 18.172306060791016
Loss: 17.133075714111328
Loss: 17.454158782958984
Loss: 18.81386947631836
Loss: 16.495880126953125
Loss: 19.160144805908203
Loss: 17.106332778930664
Loss: 17.54393768310547
Loss: 17.371707916259766
Loss: 16.821537017822266
Loss: 15.893555641174316
Loss: 18.22244644165039
Loss: 17.516542434692383
Loss: 18.502355575561523
Loss: 17.463159561157227
Loss: 16.197002410888672
Loss: 17.503774642944336
Loss: 17.622724533081055
Loss: 16.603416442871094
Loss: 15.669855117797852
Loss: 16.00198745727539
Loss: 16.81480598449707
Loss: 17.20793914794922
Loss: 16.0435848236084
Loss: 17.887752532958984
Loss: 15.24758529663086
Loss: 15.097208023071289
Loss: 16.871244430541992
Loss: 15.449601173400879
Loss: 15.528889656066895
Loss: 16.739913940429688
Loss: 15.160139083862305
Loss: 16.04355239868164
Loss: 14.117986679077148
Loss: 14.859116554260254
Loss: 15.386026382446289
Loss: 15.982507705688477
Loss: 16.081850051879883
Loss: 15.11528205871582
Loss: 15.973184585571289
Loss: 15.85796070098877
Loss: 15.218850135803223
Loss: 15.299239158630371
Loss: 13.829278945922852
Loss: 15.819135665893555
Loss: 13.798430442810059
Loss: 14.908360481262207
Loss: 15.710630416870117
Loss: 15.4535493850708
Loss: 16.036865234375
Loss: 13.928866386413574
Loss: 15.013040542602539
Loss: 15.746073722839355
Loss: 15.004413604736328
Loss: 14.469709396362305
Loss: 14.42583179473877
Loss: 14.543342590332031
Loss: 15.045689582824707
[Train] Epoch 5, accuracy 0.94140625
[Eval] Epoch 5, loss 5.354929, accuracy 0.968056
Model saved as x_small_model_weights_best.pth
Loss: 14.967191696166992
Loss: 13.897067070007324
Loss: 14.343313217163086
Loss: 13.010902404785156
Loss: 13.702911376953125
Loss: 12.534730911254883
Loss: 13.083324432373047
Loss: 14.378100395202637
Loss: 13.039839744567871
Loss: 14.820866584777832
Loss: 12.291902542114258
Loss: 13.418331146240234
Loss: 13.518104553222656
Loss: 13.73490047454834
Loss: 14.055096626281738
Loss: 12.38381576538086
Loss: 13.965662956237793
Loss: 13.514315605163574
Loss: 12.951605796813965
Loss: 14.024599075317383
Loss: 12.066023826599121
Loss: 14.069507598876953
Loss: 13.013456344604492
Loss: 12.488255500793457
Loss: 11.785533905029297
Loss: 13.882354736328125
Loss: 12.410099029541016
Loss: 12.679213523864746
Loss: 12.50304889678955
Loss: 13.424250602722168
Loss: 12.322639465332031
Loss: 13.148818016052246
Loss: 13.127197265625
Loss: 11.906248092651367
Loss: 12.500815391540527
Loss: 13.024373054504395
Loss: 13.836161613464355
Loss: 13.592325210571289
Loss: 11.879508972167969
Loss: 11.953521728515625
Loss: 12.517156600952148
Loss: 11.65660572052002
Loss: 12.810574531555176
Loss: 12.276583671569824
Loss: 12.800146102905273
Loss: 13.300137519836426
Loss: 11.434588432312012
Loss: 12.362822532653809
Loss: 11.758517265319824
Loss: 12.531267166137695
Loss: 12.270519256591797
Loss: 12.25617504119873
Loss: 12.321194648742676
Loss: 11.307025909423828
Loss: 11.733457565307617
Loss: 12.517744064331055
Loss: 11.31165885925293
Loss: 10.827692031860352
Loss: 11.725556373596191
Loss: 10.258594512939453
Loss: 9.795222282409668
Loss: 11.208706855773926
Loss: 10.337782859802246
Loss: 11.479002952575684
Loss: 12.402973175048828
Loss: 11.240890502929688
Loss: 10.868730545043945
Loss: 11.424145698547363
Loss: 11.208226203918457
Loss: 10.979095458984375
Loss: 13.158042907714844
Loss: 10.443571090698242
Loss: 10.79310417175293
Loss: 11.037955284118652
Loss: 11.379505157470703
Loss: 12.154059410095215
Loss: 12.510139465332031
Loss: 10.446057319641113
Loss: 11.3690185546875
Loss: 11.136338233947754
Loss: 11.644933700561523
Loss: 10.756828308105469
Loss: 11.104401588439941
Loss: 10.638870239257812
Loss: 11.933491706848145
Loss: 10.807171821594238
Loss: 9.408968925476074
Loss: 10.204849243164062
Loss: 12.531549453735352
Loss: 11.949779510498047
[Train] Epoch 6, accuracy 0.9759548611111111
[Eval] Epoch 6, loss 5.298346, accuracy 0.981944
Model saved as x_small_model_weights_best.pth
Loss: 9.83081340789795
Loss: 9.522233009338379
Loss: 10.61736011505127
Loss: 9.732725143432617
Loss: 9.448854446411133
Loss: 9.288912773132324
Loss: 10.453012466430664
Loss: 9.729470252990723
Loss: 9.007270812988281
Loss: 9.26801586151123
Loss: 9.46364974975586
Loss: 10.157184600830078
Loss: 8.568804740905762
Loss: 9.701705932617188
Loss: 9.060142517089844
Loss: 7.7147345542907715
Loss: 8.226253509521484
Loss: 9.371784210205078
Loss: 8.368175506591797
Loss: 9.1285982131958
Loss: 9.353145599365234
Loss: 8.62376880645752
Loss: 8.733803749084473
Loss: 7.928945541381836
Loss: 8.53425407409668
Loss: 9.514992713928223
Loss: 9.219036102294922
Loss: 9.095776557922363
Loss: 8.88512897491455
Loss: 8.817852020263672
Loss: 10.0745210647583
Loss: 10.025044441223145
Loss: 8.424277305603027
Loss: 8.772869110107422
Loss: 8.997748374938965
Loss: 9.076770782470703
Loss: 9.49310302734375
Loss: 9.167268753051758
Loss: 7.518609046936035
Loss: 7.6563944816589355
Loss: 8.626216888427734
Loss: 9.10229206085205
Loss: 8.868875503540039
Loss: 7.456963539123535
Loss: 7.858098983764648
Loss: 8.114004135131836
Loss: 8.04404067993164
Loss: 8.330095291137695
Loss: 8.849098205566406
Loss: 8.914100646972656
Loss: 7.54315185546875
Loss: 7.169815540313721
Loss: 7.2384352684021
Loss: 8.425394058227539
Loss: 8.820206642150879
Loss: 7.439239501953125
Loss: 7.975594520568848
Loss: 7.229519844055176
Loss: 8.522876739501953
Loss: 7.275195598602295
Loss: 7.218062877655029
Loss: 7.661179065704346
Loss: 7.648106575012207
Loss: 8.796744346618652
Loss: 9.101387977600098
Loss: 7.22128963470459
Loss: 6.826878547668457
Loss: 8.178667068481445
Loss: 7.637731075286865
Loss: 7.740828990936279
Loss: 8.099630355834961
Loss: 8.442588806152344
Loss: 7.313529014587402
Loss: 8.3364896774292
Loss: 8.49319076538086
Loss: 8.801128387451172
Loss: 8.039448738098145
Loss: 7.274315357208252
Loss: 8.217564582824707
Loss: 7.178050518035889
Loss: 8.837136268615723
Loss: 8.449817657470703
Loss: 6.8007378578186035
Loss: 7.76897668838501
Loss: 7.227156639099121
Loss: 7.735385894775391
Loss: 7.3262200355529785
Loss: 7.700131416320801
Loss: 7.025029182434082
Loss: 6.263712406158447
[Train] Epoch 7, accuracy 0.9905381944444445
[Eval] Epoch 7, loss 5.299630, accuracy 0.988542
Model saved as x_small_model_weights_best.pth
Loss: 6.842012405395508
Loss: 7.876344680786133
Loss: 7.350040435791016
Loss: 7.516110420227051
Loss: 6.603578090667725
Loss: 6.941519260406494
Loss: 6.658550262451172
Loss: 6.6682820320129395
Loss: 7.915675640106201
Loss: 6.959089279174805
Loss: 4.565779209136963
Loss: 7.162990093231201
Loss: 6.474494457244873
Loss: 6.529866695404053
Loss: 6.3015875816345215
Loss: 5.359321594238281
Loss: 6.213161468505859
Loss: 8.704818725585938
Loss: 6.24599027633667
Loss: 5.758505344390869
Loss: 6.482937335968018
Loss: 6.787458419799805
Loss: 6.214366912841797
Loss: 6.404446601867676
Loss: 5.382318019866943
Loss: 6.032238483428955
Loss: 5.662688255310059
Loss: 7.0951714515686035
Loss: 6.250905513763428
Loss: 6.325639724731445
Loss: 5.073131561279297
Loss: 6.330322742462158
Loss: 7.496490955352783
Loss: 6.732284069061279
Loss: 5.878511905670166
Loss: 6.9865007400512695
Loss: 5.452584266662598
Loss: 6.537278175354004
Loss: 6.820438861846924
Loss: 5.6581525802612305
Loss: 6.437221050262451
Loss: 5.815174102783203
Loss: 6.211615085601807
Loss: 6.367682933807373
Loss: 6.767790794372559
Loss: 6.156646728515625
Loss: 5.717837333679199
Loss: 4.596630573272705
Loss: 6.475508213043213
Loss: 7.27562141418457
Loss: 5.972221851348877
Loss: 7.634057998657227
Loss: 6.205295085906982
Loss: 6.033403396606445
Loss: 6.58249568939209
Loss: 6.596010684967041
Loss: 5.901637077331543
Loss: 4.4576497077941895
Loss: 6.381648063659668
Loss: 6.773277282714844
Loss: 5.664560317993164
Loss: 5.646515369415283
Loss: 5.852048873901367
Loss: 5.172512531280518
Loss: 6.768702030181885
Loss: 6.603917121887207
Loss: 6.321104049682617
Loss: 5.367758274078369
Loss: 6.457625865936279
Loss: 5.222214698791504
Loss: 5.067849636077881
Loss: 5.691585540771484
Loss: 4.583067893981934
Loss: 5.947293281555176
Loss: 6.195211887359619
Loss: 5.831178665161133
Loss: 5.837998390197754
Loss: 5.78339147567749
Loss: 4.974673271179199
Loss: 5.636556625366211
Loss: 4.544918537139893
Loss: 4.5193047523498535
Loss: 4.834622859954834
Loss: 6.556705951690674
Loss: 6.287858963012695
Loss: 5.700721263885498
Loss: 4.35753870010376
Loss: 5.201504707336426
Loss: 4.995372295379639
Loss: 6.378348350524902
[Train] Epoch 8, accuracy 0.996875
[Eval] Epoch 8, loss 5.263845, accuracy 0.991667
Model saved as x_small_model_weights_best.pth
Loss: 4.224325656890869
Loss: 5.693369388580322
Loss: 4.99055290222168
Loss: 4.413161754608154
Loss: 4.660316467285156
Loss: 4.900299072265625
Loss: 4.937010765075684
Loss: 3.767659902572632
Loss: 4.859501838684082
Loss: 5.052565574645996
Loss: 4.436791896820068
Loss: 5.303276538848877
Loss: 4.97570276260376
Loss: 5.2804765701293945
Loss: 5.36074686050415
Loss: 5.464675426483154
Loss: 4.22620964050293
Loss: 4.761553764343262
Loss: 4.512241363525391
Loss: 4.929072856903076
Loss: 4.656466484069824
Loss: 5.062389850616455
Loss: 4.03678035736084
Loss: 5.275327682495117
Loss: 5.867273330688477
Loss: 4.890100002288818
Loss: 3.9005494117736816
Loss: 5.476160049438477
Loss: 6.275750637054443
Loss: 5.889808654785156
Loss: 4.531125068664551
Loss: 4.226162910461426
Loss: 5.106416702270508
Loss: 4.007771968841553
Loss: 4.488129138946533
Loss: 5.573796272277832
Loss: 5.457038879394531
Loss: 5.338484764099121
Loss: 4.435704231262207
Loss: 4.9157586097717285
Loss: 4.579671859741211
Loss: 5.025632858276367
Loss: 4.300445556640625
Loss: 5.01991081237793
Loss: 3.2371890544891357
Loss: 5.448144435882568
Loss: 5.37860631942749
Loss: 4.5493879318237305
Loss: 4.496331214904785
Loss: 4.508538246154785
Loss: 4.588894367218018
Loss: 4.755275726318359
Loss: 3.645759105682373
Loss: 4.356590270996094
Loss: 3.1805429458618164
Loss: 4.538380146026611
Loss: 4.3794050216674805
Loss: 3.5710933208465576
Loss: 3.4312515258789062
Loss: 4.435154438018799
Loss: 3.394359827041626
Loss: 4.398802757263184
Loss: 4.002569198608398
Loss: 4.370170593261719
Loss: 4.95697546005249
Loss: 4.333221435546875
Loss: 4.230566024780273
Loss: 4.699167728424072
Loss: 3.5359842777252197
Loss: 4.9590654373168945
Loss: 4.541606903076172
Loss: 4.673058986663818
Loss: 5.04664945602417
Loss: 3.8570830821990967
Loss: 4.309730529785156
Loss: 4.442840576171875
Loss: 4.817041397094727
Loss: 4.1141557693481445
Loss: 4.809329986572266
Loss: 3.6976513862609863
Loss: 4.705416202545166
Loss: 3.6253292560577393
Loss: 4.207873344421387
Loss: 4.505029201507568
Loss: 3.899866819381714
Loss: 3.825897693634033
Loss: 3.9821829795837402
Loss: 3.844876766204834
Loss: 4.799591541290283
Loss: 3.8681976795196533
[Train] Epoch 9, accuracy 0.9978298611111112
[Eval] Epoch 9, loss 5.234710, accuracy 0.995833
Model saved as x_small_model_weights_best.pth
Loss: 2.9107279777526855
Loss: 3.1502034664154053
Loss: 3.447009325027466
Loss: 2.939042806625366
Loss: 2.647242307662964
Loss: 3.0471348762512207
Loss: 3.1595754623413086
Loss: 3.368210792541504
Loss: 3.3726935386657715
Loss: 3.440519094467163
Loss: 3.7470510005950928
Loss: 3.8274714946746826
Loss: 3.4346892833709717
Loss: 3.3304271697998047
Loss: 3.966989517211914
Loss: 3.45837140083313
Loss: 3.8326234817504883
Loss: 3.78169846534729
Loss: 3.120378017425537
Loss: 2.5461032390594482
Loss: 2.86745285987854
Loss: 3.3875064849853516
Loss: 2.925536632537842
Loss: 4.357180595397949
Loss: 3.1009020805358887
Loss: 3.8341593742370605
Loss: 4.199656963348389
Loss: 3.36849045753479
Loss: 2.8789055347442627
Loss: 3.8924155235290527
Loss: 4.068769454956055
Loss: 2.4174911975860596
Loss: 2.990518093109131
Loss: 4.106983184814453
Loss: 2.969167470932007
Loss: 3.6438088417053223
Loss: 2.893172264099121
Loss: 3.2436962127685547
Loss: 3.134073257446289
Loss: 3.6360387802124023
Loss: 3.0179765224456787
Loss: 3.4460315704345703
Loss: 3.686708927154541
Loss: 3.9376800060272217
Loss: 2.9857358932495117
Loss: 3.405217409133911
Loss: 3.4146628379821777
Loss: 3.2626328468322754
Loss: 2.8007936477661133
Loss: 3.2791268825531006
Loss: 3.631319284439087
Loss: 2.8350844383239746
Loss: 3.203366279602051
Loss: 3.7435173988342285
Loss: 3.0743486881256104
Loss: 3.5577681064605713
Loss: 3.392500638961792
Loss: 3.2789206504821777
Loss: 3.8761491775512695
Loss: 2.619619846343994
Loss: 3.6000771522521973
Loss: 3.1406166553497314
Loss: 3.6865665912628174
Loss: 2.2132985591888428
Loss: 4.108442783355713
Loss: 3.220512628555298
Loss: 2.9292588233947754
Loss: 2.373410940170288
Loss: 3.2999227046966553
Loss: 2.9496231079101562
Loss: 2.522484540939331
Loss: 3.4269967079162598
Loss: 3.576136589050293
Loss: 3.2653119564056396
Loss: 2.788194179534912
Loss: 3.131148099899292
Loss: 3.381045341491699
Loss: 2.525113582611084
Loss: 3.763847827911377
Loss: 2.504584789276123
Loss: 2.9804904460906982
Loss: 3.5112805366516113
Loss: 2.7597811222076416
Loss: 2.5865159034729004
Loss: 2.4495675563812256
Loss: 4.091326713562012
Loss: 2.9573473930358887
Loss: 2.9625370502471924
Loss: 3.6950149536132812
Loss: 2.999356746673584
[Train] Epoch 10, accuracy 0.9986111111111111
[Eval] Epoch 10, loss 5.223601, accuracy 0.995833
Model saved as x_small_model_weights_best.pth
Loss: 2.538106679916382
Loss: 2.8658299446105957
Loss: 2.670711040496826
Loss: 2.210153341293335
Loss: 3.1425631046295166
Loss: 2.476224660873413
Loss: 2.8361098766326904
Loss: 2.118269920349121
Loss: 2.901595115661621
Loss: 2.6832616329193115
Loss: 2.5705642700195312
Loss: 2.335205078125
Loss: 3.3201639652252197
Loss: 3.1613855361938477
Loss: 3.676947593688965
Loss: 3.1459755897521973
Loss: 2.934530735015869
Loss: 2.922687530517578
Loss: 2.4533400535583496
Loss: 2.72678279876709
Loss: 2.504615545272827
Loss: 2.8616943359375
Loss: 2.8721184730529785
Loss: 3.033966541290283
Loss: 2.689330816268921
Loss: 2.8497588634490967
Loss: 3.6606295108795166
Loss: 2.561652183532715
Loss: 3.0519158840179443
Loss: 2.719644546508789
Loss: 2.2682530879974365
Loss: 2.5782008171081543
Loss: 2.974775791168213
Loss: 1.9376931190490723
Loss: 2.348837375640869
Loss: 2.518279552459717
Loss: 2.5818188190460205
Loss: 2.161257266998291
Loss: 2.440187931060791
Loss: 1.834444522857666
Loss: 2.6355555057525635
Loss: 2.0723330974578857
Loss: 2.8418331146240234
Loss: 2.2401511669158936
Loss: 2.8717169761657715
Loss: 2.3245773315429688
Loss: 2.1819865703582764
Loss: 2.611940383911133
Loss: 2.4937846660614014
Loss: 2.2553508281707764
Loss: 2.879992723464966
Loss: 2.032069683074951
Loss: 2.3662383556365967
Loss: 2.490968704223633
Loss: 2.1501641273498535
Loss: 2.611438751220703
Loss: 2.659986972808838
Loss: 2.5930991172790527
Loss: 2.7607481479644775
Loss: 2.6398885250091553
Loss: 2.8649630546569824
Loss: 2.2163784503936768
Loss: 2.356910228729248
Loss: 2.3323986530303955
Loss: 2.0169076919555664
Loss: 2.628458023071289
Loss: 2.5948755741119385
Loss: 2.1690423488616943
Loss: 2.276850938796997
Loss: 2.622016191482544
Loss: 2.2552661895751953
Loss: 2.414315700531006
Loss: 2.64005446434021
Loss: 1.7963494062423706
Loss: 2.141875982284546
Loss: 2.5825071334838867
Loss: 3.25070858001709
Loss: 2.0166754722595215
Loss: 1.83212149143219
Loss: 2.087796449661255
Loss: 2.7291526794433594
Loss: 2.541527509689331
Loss: 2.3092737197875977
Loss: 2.6531786918640137
Loss: 3.3277690410614014
Loss: 2.1295325756073
Loss: 2.610271453857422
Loss: 2.8203837871551514
Loss: 2.221527099609375
Loss: 1.9031343460083008
[Train] Epoch 11, accuracy 0.9990451388888889
[Eval] Epoch 11, loss 5.205250, accuracy 0.996181
Model saved as x_small_model_weights_best.pth
Loss: 1.8158622980117798
Loss: 2.0613603591918945
Loss: 2.265634298324585
Loss: 1.73600435256958
Loss: 2.382460355758667
Loss: 1.943524718284607
Loss: 2.401326894760132
Loss: 1.8156641721725464
Loss: 1.9097906351089478
Loss: 2.053530693054199
Loss: 2.215522289276123
Loss: 2.3242266178131104
Loss: 1.7902357578277588
Loss: 2.756761312484741
Loss: 2.512801170349121
Loss: 2.3122377395629883
Loss: 2.056107521057129
Loss: 1.9130743741989136
Loss: 2.1937475204467773
Loss: 2.705784320831299
Loss: 2.2589523792266846
Loss: 2.3747518062591553
Loss: 1.8537817001342773
Loss: 2.6905956268310547
Loss: 2.0292859077453613
Loss: 2.011127471923828
Loss: 2.197873830795288
Loss: 1.7478419542312622
Loss: 1.6144295930862427
Loss: 2.58726167678833
Loss: 2.1446139812469482
Loss: 2.7393860816955566
Loss: 2.3393404483795166
Loss: 3.066364049911499
Loss: 1.5176820755004883
Loss: 2.3054795265197754
Loss: 2.9332425594329834
Loss: 1.5877234935760498
Loss: 2.4726271629333496
Loss: 2.3258395195007324
Loss: 1.8620131015777588
Loss: 1.761130452156067
Loss: 1.823716163635254
Loss: 1.585073471069336
Loss: 2.115227699279785
Loss: 2.5775811672210693
Loss: 2.4202888011932373
Loss: 2.792527437210083
Loss: 2.2088847160339355
Loss: 2.38677716255188
Loss: 1.9316000938415527
Loss: 2.10152268409729
Loss: 1.4681713581085205
Loss: 1.8544666767120361
Loss: 1.9946467876434326
Loss: 1.591314435005188
Loss: 1.7846424579620361
Loss: 1.5897172689437866
Loss: 1.4807037115097046
Loss: 1.6636457443237305
Loss: 2.361262321472168
Loss: 2.061251401901245
Loss: 2.0558714866638184
Loss: 1.7395262718200684
Loss: 2.1067001819610596
Loss: 2.4863903522491455
Loss: 2.4208827018737793
Loss: 1.4169139862060547
Loss: 1.5043468475341797
Loss: 2.321770429611206
Loss: 1.8896713256835938
Loss: 1.7905796766281128
Loss: 2.371528148651123
Loss: 2.0865423679351807
Loss: 2.036884307861328
Loss: 1.9100565910339355
Loss: 1.5975359678268433
Loss: 1.671682357788086
Loss: 1.7622840404510498
Loss: 2.154883623123169
Loss: 1.7133562564849854
Loss: 1.9524668455123901
Loss: 1.926455020904541
Loss: 1.9887930154800415
Loss: 2.1944422721862793
Loss: 2.034104585647583
Loss: 1.4453656673431396
Loss: 1.8698586225509644
Loss: 2.018723726272583
Loss: 1.3809261322021484
[Train] Epoch 12, accuracy 0.9994791666666667
[Eval] Epoch 12, loss 5.201081, accuracy 0.997569
Model saved as x_small_model_weights_best.pth
Loss: 1.7741833925247192
Loss: 2.104917526245117
Loss: 1.9776512384414673
Loss: 1.6249172687530518
Loss: 1.6464064121246338
Loss: 1.7951005697250366
Loss: 1.753236174583435
Loss: 1.6199887990951538
Loss: 1.912416696548462
Loss: 1.7577433586120605
Loss: 2.0668909549713135
Loss: 1.8717961311340332
Loss: 2.0938165187835693
Loss: 1.3485355377197266
Loss: 1.2396000623703003
Loss: 1.0891903638839722
Loss: 1.612870454788208
Loss: 1.9223098754882812
Loss: 1.6290504932403564
Loss: 1.3834375143051147
Loss: 1.7450486421585083
Loss: 1.3794589042663574
Loss: 2.155651330947876
Loss: 1.5463391542434692
Loss: 1.3956860303878784
Loss: 1.5189082622528076
Loss: 2.0421371459960938
Loss: 1.513805866241455
Loss: 1.5944669246673584
Loss: 1.529487133026123
Loss: 1.5185247659683228
Loss: 1.642625093460083
Loss: 1.7596546411514282
Loss: 1.112571358680725
Loss: 1.2804709672927856
Loss: 2.471597671508789
Loss: 2.137356758117676
Loss: 1.3140419721603394
Loss: 1.3933532238006592
Loss: 1.5989763736724854
Loss: 1.456077218055725
Loss: 2.098869800567627
Loss: 1.8565504550933838
Loss: 1.6756019592285156
Loss: 1.3741178512573242
Loss: 1.4461137056350708
Loss: 1.6736962795257568
Loss: 1.4247570037841797
Loss: 1.410369634628296
Loss: 1.3922502994537354
Loss: 1.25665283203125
Loss: 1.7002698183059692
Loss: 1.6157392263412476
Loss: 2.4078924655914307
Loss: 1.416098952293396
Loss: 1.2367924451828003
Loss: 1.6356934309005737
Loss: 1.8527699708938599
Loss: 1.9801172018051147
Loss: 1.0024458169937134
Loss: 1.8094884157180786
Loss: 1.5534108877182007
Loss: 2.0260801315307617
Loss: 1.6543071269989014
Loss: 1.195936918258667
Loss: 1.5264778137207031
Loss: 1.4258506298065186
Loss: 1.9769468307495117
Loss: 1.7965501546859741
Loss: 1.710707664489746
Loss: 1.5877593755722046
Loss: 1.5515272617340088
Loss: 1.5871995687484741
Loss: 1.5273680686950684
Loss: 1.5476744174957275
Loss: 2.007807493209839
Loss: 1.856052041053772
Loss: 1.516882300376892
Loss: 1.4788179397583008
Loss: 1.4357120990753174
Loss: 1.7679274082183838
Loss: 1.748186469078064
Loss: 1.0265753269195557
Loss: 2.0583860874176025
Loss: 1.6264986991882324
Loss: 1.6132234334945679
Loss: 1.3059673309326172
Loss: 1.377437949180603
Loss: 1.6955382823944092
Loss: 1.0097897052764893
[Train] Epoch 13, accuracy 0.9994791666666667
[Eval] Epoch 13, loss 5.191265, accuracy 0.997222
Loss: 1.1980020999908447
Loss: 1.6052875518798828
Loss: 1.3248876333236694
Loss: 1.2619495391845703
Loss: 1.2248131036758423
Loss: 1.2810617685317993
Loss: 1.3497600555419922
Loss: 0.9385722875595093
Loss: 1.3520464897155762
Loss: 1.2548303604125977
Loss: 1.2981709241867065
Loss: 1.8148915767669678
Loss: 1.9698737859725952
Loss: 1.5025300979614258
Loss: 1.2123640775680542
Loss: 2.063598871231079
Loss: 1.3094693422317505
Loss: 1.257330298423767
Loss: 1.3955745697021484
Loss: 1.312374472618103
Loss: 1.4376866817474365
Loss: 1.5688062906265259
Loss: 0.8715928196907043
Loss: 0.9766984581947327
Loss: 1.128348708152771
Loss: 1.3307527303695679
Loss: 1.9595801830291748
Loss: 1.1991995573043823
Loss: 1.368693232536316
Loss: 1.370276689529419
Loss: 0.635860800743103
Loss: 1.54838228225708
Loss: 1.302040457725525
Loss: 1.2149819135665894
Loss: 1.2851396799087524
Loss: 1.2319120168685913
Loss: 1.0358407497406006
Loss: 1.3233120441436768
Loss: 1.2459651231765747
Loss: 1.447962760925293
Loss: 1.8130772113800049
Loss: 1.2690166234970093
Loss: 1.8277490139007568
Loss: 0.9225833415985107
Loss: 1.4029744863510132
Loss: 1.326407790184021
Loss: 1.330737829208374
Loss: 1.0864890813827515
Loss: 1.6464673280715942
Loss: 1.0265223979949951
Loss: 0.9993937611579895
Loss: 1.0822056531906128
Loss: 1.4275177717208862
Loss: 1.0705608129501343
Loss: 1.6367909908294678
Loss: 1.5494316816329956
Loss: 1.7407784461975098
Loss: 1.5433025360107422
Loss: 0.903046190738678
Loss: 0.8808798789978027
Loss: 1.0802708864212036
Loss: 1.67298424243927
Loss: 1.122475266456604
Loss: 1.3854225873947144
Loss: 1.1025701761245728
Loss: 1.4472111463546753
Loss: 1.8678662776947021
Loss: 0.8541188836097717
Loss: 1.084160327911377
Loss: 1.7084770202636719
Loss: 1.779982089996338
Loss: 1.1995234489440918
Loss: 1.2306740283966064
Loss: 1.1620235443115234
Loss: 1.0243858098983765
Loss: 0.8327151536941528
Loss: 1.3441129922866821
Loss: 1.3262215852737427
Loss: 0.8603947162628174
Loss: 2.0791025161743164
Loss: 1.603297233581543
Loss: 1.3127552270889282
Loss: 1.1572552919387817
Loss: 1.2969233989715576
Loss: 1.4311060905456543
Loss: 0.9317758679389954
Loss: 1.2582532167434692
Loss: 0.9096080660820007
Loss: 0.9581048488616943
Loss: 1.759182095527649
[Train] Epoch 14, accuracy 0.9997395833333333
[Eval] Epoch 14, loss 5.191608, accuracy 0.997222
Loss: 0.8288239240646362
Loss: 1.0136466026306152
Loss: 1.3734720945358276
Loss: 0.964139997959137
Loss: 0.8745332360267639
Loss: 1.493548035621643
Loss: 1.0912590026855469
Loss: 1.6702181100845337
Loss: 1.7515912055969238
Loss: 1.3517276048660278
Loss: 0.8377147316932678
Loss: 0.8335001468658447
Loss: 1.3610243797302246
Loss: 1.026146650314331
Loss: 1.134187936782837
Loss: 1.1499555110931396
Loss: 1.1365180015563965
Loss: 1.162465214729309
Loss: 1.2684664726257324
Loss: 1.217799425125122
Loss: 1.3282796144485474
Loss: 0.8476085066795349
Loss: 1.2122015953063965
Loss: 1.224148154258728
Loss: 1.1438462734222412
Loss: 1.1775224208831787
Loss: 0.9234580993652344
Loss: 1.0598241090774536
Loss: 1.448383092880249
Loss: 0.921150803565979
Loss: 1.4916399717330933
Loss: 1.2885721921920776
Loss: 1.1813169717788696
Loss: 1.4599965810775757
Loss: 1.345112919807434
Loss: 1.0990885496139526
Loss: 0.6656282544136047
Loss: 0.991400420665741
Loss: 1.0499898195266724
Loss: 1.3215304613113403
Loss: 1.6007535457611084
Loss: 1.3111335039138794
Loss: 0.87749844789505
Loss: 1.1502898931503296
Loss: 0.9553577303886414
Loss: 1.20576012134552
Loss: 1.299403190612793
Loss: 0.7605789303779602
Loss: 0.8533743619918823
Loss: 1.3971666097640991
Loss: 1.105757713317871
Loss: 0.8692342638969421
Loss: 1.1096410751342773
Loss: 1.0959004163742065
Loss: 1.1381431818008423
Loss: 1.1840475797653198
Loss: 0.8623092174530029
Loss: 0.7284793257713318
Loss: 1.2320888042449951
Loss: 0.7752864956855774
Loss: 0.7818252444267273
Loss: 1.0874742269515991
Loss: 1.7969372272491455
Loss: 0.8538029193878174
Loss: 1.4390802383422852
Loss: 0.7724458575248718
Loss: 0.8656442761421204
Loss: 1.0800577402114868
Loss: 1.4727263450622559
Loss: 1.067647933959961
Loss: 0.7403456568717957
Loss: 0.8306427597999573
Loss: 1.2849388122558594
Loss: 1.6941927671432495
Loss: 0.6436311602592468
Loss: 0.6565384268760681
Loss: 0.9987604022026062
Loss: 0.6074506044387817
Loss: 1.8100582361221313
Loss: 0.8131545782089233
Loss: 0.6936878561973572
Loss: 0.8205555081367493
Loss: 1.3292064666748047
Loss: 1.0636872053146362
Loss: 0.8892612457275391
Loss: 0.9944791793823242
Loss: 1.3805830478668213
Loss: 0.9404104948043823
Loss: 1.214411973953247
Loss: 1.009364128112793
[Train] Epoch 15, accuracy 0.9997395833333333
[Eval] Epoch 15, loss 5.184888, accuracy 0.997917
Model saved as x_small_model_weights_best.pth
Loss: 0.9755942821502686
Loss: 0.9832709431648254
Loss: 0.6920092701911926
Loss: 0.8561024069786072
Loss: 1.0813854932785034
Loss: 0.9455593228340149
Loss: 0.8886589407920837
Loss: 1.3956562280654907
Loss: 1.444177269935608
Loss: 0.7629252672195435
Loss: 0.9416138529777527
Loss: 0.8142990469932556
Loss: 0.6954374313354492
Loss: 0.7722842693328857
Loss: 1.1391209363937378
Loss: 1.085853934288025
Loss: 2.1274850368499756
Loss: 0.8159701824188232
Loss: 0.8915895223617554
Loss: 0.9312823414802551
Loss: 0.46865490078926086
Loss: 0.8752396702766418
Loss: 1.1595356464385986
Loss: 1.0282882452011108
Loss: 0.6438339352607727
Loss: 1.171621561050415
Loss: 1.2562893629074097
Loss: 1.4107657670974731
Loss: 0.9499386548995972
Loss: 1.1438183784484863
Loss: 1.067649006843567
Loss: 0.7958880066871643
Loss: 0.7400460839271545
Loss: 1.0619242191314697
Loss: 1.1142946481704712
Loss: 0.8254529237747192
Loss: 0.654003381729126
Loss: 0.9531018733978271
Loss: 0.8572611808776855
Loss: 1.440314769744873
Loss: 1.3265604972839355
Loss: 0.9244173169136047
Loss: 1.2037216424942017
Loss: 1.0087316036224365
Loss: 0.5997521281242371
Loss: 1.0535908937454224
Loss: 0.8709955215454102
Loss: 0.8287776112556458
Loss: 0.606925368309021
Loss: 0.7780054807662964
Loss: 1.240127444267273
Loss: 1.237560510635376
Loss: 0.429706871509552
Loss: 0.8636231422424316
Loss: 0.67157381772995
Loss: 1.2501163482666016
Loss: 0.5757535099983215
Loss: 1.1523908376693726
Loss: 0.7422032356262207
Loss: 0.8954366445541382
Loss: 0.6284454464912415
Loss: 0.8323554396629333
Loss: 0.8227335214614868
Loss: 1.1587955951690674
Loss: 0.8786396384239197
Loss: 1.0025238990783691
Loss: 0.5152124762535095
Loss: 0.8475316166877747
Loss: 0.510185956954956
Loss: 0.8927868008613586
Loss: 0.6081801056861877
Loss: 0.9087714552879333
Loss: 0.9517514705657959
Loss: 0.8514122366905212
Loss: 1.0548042058944702
Loss: 0.8536238670349121
Loss: 0.7870169281959534
Loss: 0.7038890719413757
Loss: 0.8217032551765442
Loss: 0.7097389698028564
Loss: 0.7833232879638672
Loss: 0.9115293025970459
Loss: 0.706166684627533
Loss: 0.9082216620445251
Loss: 0.9930393099784851
Loss: 0.9431418776512146
Loss: 0.8471165299415588
Loss: 1.1086030006408691
Loss: 0.5962797403335571
Loss: 1.331866979598999
[Train] Epoch 16, accuracy 0.9997395833333333
[Eval] Epoch 16, loss 5.164922, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.7782427668571472
Loss: 0.8221516609191895
Loss: 0.8075938820838928
Loss: 0.8712795376777649
Loss: 0.4776851236820221
Loss: 0.9651641845703125
Loss: 0.9782689809799194
Loss: 0.5975168943405151
Loss: 0.36115023493766785
Loss: 0.6833174824714661
Loss: 0.872767984867096
Loss: 0.6659559607505798
Loss: 0.8004317879676819
Loss: 0.541275143623352
Loss: 0.8351460099220276
Loss: 0.4922650158405304
Loss: 1.0478239059448242
Loss: 0.478758841753006
Loss: 1.444807529449463
Loss: 1.2155685424804688
Loss: 0.6346654891967773
Loss: 0.5340015888214111
Loss: 0.7069513201713562
Loss: 0.8668884038925171
Loss: 0.5919594764709473
Loss: 0.7935667634010315
Loss: 0.7819831967353821
Loss: 0.7506116032600403
Loss: 0.4461410641670227
Loss: 0.8199256658554077
Loss: 0.7522619366645813
Loss: 0.8016831874847412
Loss: 0.5825905203819275
Loss: 0.6430525183677673
Loss: 0.6169173717498779
Loss: 0.6304009556770325
Loss: 1.0993156433105469
Loss: 0.939467191696167
Loss: 0.8654537200927734
Loss: 1.1474649906158447
Loss: 0.6814429759979248
Loss: 0.6381350159645081
Loss: 0.8750767707824707
Loss: 0.5876353979110718
Loss: 0.8809995055198669
Loss: 0.6884285807609558
Loss: 0.5556852221488953
Loss: 0.47671687602996826
Loss: 0.8103662729263306
Loss: 0.5671275854110718
Loss: 1.1271024942398071
Loss: 1.0789769887924194
Loss: 0.6010193228721619
Loss: 0.7797998785972595
Loss: 0.4234827160835266
Loss: 0.6423271894454956
Loss: 0.7004993557929993
Loss: 0.5867363810539246
Loss: 0.4596193730831146
Loss: 0.6811190247535706
Loss: 1.0468531847000122
Loss: 0.7916373014450073
Loss: 0.9684929251670837
Loss: 0.5698471665382385
Loss: 0.7004514336585999
Loss: 0.519763171672821
Loss: 0.37493881583213806
Loss: 0.6372969150543213
Loss: 1.208362340927124
Loss: 0.8629320859909058
Loss: 0.7705923318862915
Loss: 0.9380087852478027
Loss: 0.474862277507782
Loss: 1.0993000268936157
Loss: 0.8790408968925476
Loss: 0.5054903030395508
Loss: 0.7564914226531982
Loss: 0.6665359139442444
Loss: 0.9887831211090088
Loss: 0.8006848096847534
Loss: 0.6742780208587646
Loss: 0.43309155106544495
Loss: 0.7201728224754333
Loss: 0.8792542815208435
Loss: 0.7272695302963257
Loss: 0.6202130317687988
Loss: 0.6524407267570496
Loss: 0.6462565660476685
Loss: 0.7993709444999695
Loss: 0.7980892658233643
[Train] Epoch 17, accuracy 0.9998263888888889
[Eval] Epoch 17, loss 5.168092, accuracy 0.998264
Loss: 0.8542240858078003
Loss: 0.718349277973175
Loss: 0.5068331360816956
Loss: 0.683536946773529
Loss: 0.507600724697113
Loss: 0.7088379859924316
Loss: 0.4011542797088623
Loss: 0.6314399838447571
Loss: 1.0191515684127808
Loss: 0.5279414057731628
Loss: 0.6159323453903198
Loss: 0.4214814305305481
Loss: 0.3644326329231262
Loss: 0.5656206607818604
Loss: 0.6576758623123169
Loss: 0.7063992619514465
Loss: 0.8994039297103882
Loss: 0.6582536101341248
Loss: 0.6953995823860168
Loss: 0.3978188931941986
Loss: 0.8447761535644531
Loss: 0.8168901205062866
Loss: 0.6429967284202576
Loss: 0.783071756362915
Loss: 0.8202233910560608
Loss: 0.5025884509086609
Loss: 0.6836694478988647
Loss: 0.6147853136062622
Loss: 0.8391425609588623
Loss: 0.49274182319641113
Loss: 0.5407867431640625
Loss: 0.4886016845703125
Loss: 0.3517782688140869
Loss: 0.5531936883926392
Loss: 0.37382107973098755
Loss: 1.0181658267974854
Loss: 0.6761186718940735
Loss: 0.7453235387802124
Loss: 0.4074009358882904
Loss: 0.4828115701675415
Loss: 0.9142940640449524
Loss: 0.7448093295097351
Loss: 0.46875664591789246
Loss: 0.508560061454773
Loss: 0.590023398399353
Loss: 0.4978163242340088
Loss: 0.5357955694198608
Loss: 0.8253103494644165
Loss: 0.6137088537216187
Loss: 0.5645048022270203
Loss: 0.42554771900177
Loss: 0.7577207088470459
Loss: 0.5549872517585754
Loss: 0.5073610544204712
Loss: 0.5620303750038147
Loss: 0.5474497079849243
Loss: 0.8846166729927063
Loss: 0.72603440284729
Loss: 0.5004788637161255
Loss: 0.6492322683334351
Loss: 0.9662414193153381
Loss: 0.8455871343612671
Loss: 0.3940573036670685
Loss: 1.0013929605484009
Loss: 0.9072288274765015
Loss: 0.586509644985199
Loss: 0.35869285464286804
Loss: 0.429995596408844
Loss: 0.809064507484436
Loss: 0.7966523766517639
Loss: 0.6679393649101257
Loss: 0.803272008895874
Loss: 0.6101687550544739
Loss: 0.8208271265029907
Loss: 0.8121780753135681
Loss: 0.3100705146789551
Loss: 0.9552972912788391
Loss: 0.3244425058364868
Loss: 0.8426849842071533
Loss: 0.6034320592880249
Loss: 0.838819146156311
Loss: 0.5267965197563171
Loss: 0.45770564675331116
Loss: 0.4468142092227936
Loss: 0.8373571634292603
Loss: 0.7642935514450073
Loss: 0.5567353367805481
Loss: 0.9565711617469788
Loss: 1.2138357162475586
Loss: 0.5433458685874939
[Train] Epoch 18, accuracy 0.9998263888888889
[Eval] Epoch 18, loss 5.175167, accuracy 0.998264
Loss: 0.5041225552558899
Loss: 0.3287111520767212
Loss: 0.48182782530784607
Loss: 0.43734055757522583
Loss: 0.47312864661216736
Loss: 0.5945833325386047
Loss: 0.4796217978000641
Loss: 0.6111933588981628
Loss: 0.3926719129085541
Loss: 0.9102331399917603
Loss: 0.7457216382026672
Loss: 0.7347986698150635
Loss: 0.6469917893409729
Loss: 0.44756579399108887
Loss: 0.44436827301979065
Loss: 0.5538947582244873
Loss: 0.707815408706665
Loss: 0.4965837001800537
Loss: 0.48281586170196533
Loss: 0.4741780459880829
Loss: 0.42500582337379456
Loss: 0.3187240660190582
Loss: 0.6276797652244568
Loss: 0.6026352047920227
Loss: 0.417353093624115
Loss: 0.8172063231468201
Loss: 0.5542472004890442
Loss: 0.48842573165893555
Loss: 0.4022551476955414
Loss: 0.3573486804962158
Loss: 0.6587977409362793
Loss: 0.7867603302001953
Loss: 0.6108835339546204
Loss: 0.38027095794677734
Loss: 0.8675015568733215
Loss: 0.7110068202018738
Loss: 0.39091870188713074
Loss: 0.49856996536254883
Loss: 0.36689403653144836
Loss: 1.184823751449585
Loss: 0.49713778495788574
Loss: 0.5047380924224854
Loss: 0.24822194874286652
Loss: 0.7728585600852966
Loss: 0.7165827751159668
Loss: 0.6517987251281738
Loss: 0.4373786747455597
Loss: 0.7299777269363403
Loss: 0.6297488212585449
Loss: 0.6945872902870178
Loss: 0.27895140647888184
Loss: 0.8913440108299255
Loss: 0.6784318089485168
Loss: 0.31901705265045166
Loss: 0.41596725583076477
Loss: 0.5410468578338623
Loss: 0.26077792048454285
Loss: 0.6709067225456238
Loss: 0.48979493975639343
Loss: 0.8074800968170166
Loss: 1.0814387798309326
Loss: 0.48693737387657166
Loss: 0.3094726800918579
Loss: 0.469754695892334
Loss: 0.5135900974273682
Loss: 0.6117346882820129
Loss: 0.7238842844963074
Loss: 0.9844596982002258
Loss: 0.8183884024620056
Loss: 0.8559115529060364
Loss: 0.5751029849052429
Loss: 0.6750516891479492
Loss: 0.3116273880004883
Loss: 0.23715467751026154
Loss: 0.2883090376853943
Loss: 0.20528441667556763
Loss: 0.4835266172885895
Loss: 0.5588876605033875
Loss: 0.8497277498245239
Loss: 0.40316876769065857
Loss: 0.8341447710990906
Loss: 0.5641292929649353
Loss: 0.4123713970184326
Loss: 1.1696504354476929
Loss: 0.4939854145050049
Loss: 0.41709157824516296
Loss: 0.6646599769592285
Loss: 0.8310673236846924
Loss: 0.4955049157142639
Loss: 0.6454181671142578
[Train] Epoch 19, accuracy 0.9999131944444445
[Eval] Epoch 19, loss 5.166153, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.15659211575984955
Loss: 0.3071754276752472
Loss: 0.5731488466262817
Loss: 0.4338454008102417
Loss: 0.31473761796951294
Loss: 0.4038703739643097
Loss: 0.5773687362670898
Loss: 0.27535754442214966
Loss: 0.3859049677848816
Loss: 0.7395336627960205
Loss: 0.5856662392616272
Loss: 0.4103020131587982
Loss: 0.3175569176673889
Loss: 0.37464338541030884
Loss: 0.456614226102829
Loss: 0.558942437171936
Loss: 0.3528018891811371
Loss: 0.2813563346862793
Loss: 0.8605308532714844
Loss: 0.743638277053833
Loss: 0.3944728374481201
Loss: 0.7244267463684082
Loss: 0.5282102823257446
Loss: 0.44921547174453735
Loss: 0.2617274522781372
Loss: 0.6110568642616272
Loss: 0.7098434567451477
Loss: 0.5614984035491943
Loss: 0.7140380144119263
Loss: 0.3471776843070984
Loss: 0.48462292551994324
Loss: 0.37189552187919617
Loss: 0.7658445835113525
Loss: 0.4013436734676361
Loss: 0.5492278337478638
Loss: 0.7113692760467529
Loss: 0.38566160202026367
Loss: 0.4887484312057495
Loss: 0.6672882437705994
Loss: 0.24695712327957153
Loss: 0.3497562110424042
Loss: 0.39450979232788086
Loss: 0.4385739862918854
Loss: 0.4906720221042633
Loss: 0.32851436734199524
Loss: 0.25924402475357056
Loss: 0.483059823513031
Loss: 0.567852258682251
Loss: 0.27562546730041504
Loss: 0.4898524582386017
Loss: 0.4256317615509033
Loss: 0.3963121175765991
Loss: 0.4211258292198181
Loss: 0.2929540276527405
Loss: 0.3686666488647461
Loss: 0.5479943752288818
Loss: 0.2131679356098175
Loss: 0.33089545369148254
Loss: 0.6036853194236755
Loss: 0.6581449508666992
Loss: 0.31542161107063293
Loss: 0.554478108882904
Loss: 0.5728394985198975
Loss: 0.46773508191108704
Loss: 0.6051805019378662
Loss: 0.4272436797618866
Loss: 0.7742438316345215
Loss: 0.686019241809845
Loss: 0.6256241798400879
Loss: 0.38158008456230164
Loss: 0.2688177525997162
Loss: 0.3828369975090027
Loss: 0.5408579111099243
Loss: 0.55894535779953
Loss: 0.5424947738647461
Loss: 0.43907520174980164
Loss: 0.7554548978805542
Loss: 0.47080767154693604
Loss: 0.6007758975028992
Loss: 0.31737515330314636
Loss: 0.5479764342308044
Loss: 0.4272890090942383
Loss: 0.49696579575538635
Loss: 0.4384814202785492
Loss: 0.40460044145584106
Loss: 0.4765572249889374
Loss: 0.28834009170532227
Loss: 0.5245423316955566
Loss: 0.7869241237640381
Loss: 0.4827408790588379
[Train] Epoch 20, accuracy 0.9998263888888889
[Eval] Epoch 20, loss 5.167027, accuracy 0.998611
Loss: 0.3426104784011841
Loss: 0.3858124613761902
Loss: 0.28378117084503174
Loss: 0.629086971282959
Loss: 0.13201208412647247
Loss: 0.4673375189304352
Loss: 0.4162725806236267
Loss: 0.27567458152770996
Loss: 0.3511348068714142
Loss: 0.144758939743042
Loss: 0.2444927990436554
Loss: 0.33995816111564636
Loss: 0.5166606903076172
Loss: 0.5576281547546387
Loss: 0.15438538789749146
Loss: 0.7405495643615723
Loss: 0.2322634905576706
Loss: 0.3921228349208832
Loss: 0.4911789000034332
Loss: 0.45621979236602783
Loss: 0.29745084047317505
Loss: 0.18222327530384064
Loss: 0.46595829725265503
Loss: 0.3935602009296417
Loss: 0.3072638511657715
Loss: 0.7203423380851746
Loss: 0.3693256378173828
Loss: 0.5369125008583069
Loss: 0.30701515078544617
Loss: 0.49678561091423035
Loss: 0.44338998198509216
Loss: 0.49311232566833496
Loss: 0.655360758304596
Loss: 0.48083120584487915
Loss: 0.2948234975337982
Loss: 0.29580384492874146
Loss: 0.922909140586853
Loss: 0.4398231506347656
Loss: 0.6353360414505005
Loss: 0.5713662505149841
Loss: 0.5431286096572876
Loss: 0.3241158127784729
Loss: 0.3991059958934784
Loss: 0.5836067795753479
Loss: 0.3052493929862976
Loss: 0.31917035579681396
Loss: 0.6102248430252075
Loss: 1.1407297849655151
Loss: 0.3592248260974884
Loss: 0.5586413145065308
Loss: 0.2502673864364624
Loss: 0.5290328860282898
Loss: 0.316130131483078
Loss: 0.39896360039711
Loss: 0.3683874309062958
Loss: 0.25398409366607666
Loss: 0.482150137424469
Loss: 0.4885934889316559
Loss: 0.336275190114975
Loss: 0.25226742029190063
Loss: 0.602773904800415
Loss: 0.3921634554862976
Loss: 0.5259533524513245
Loss: 0.337674081325531
Loss: 0.32660382986068726
Loss: 0.4410991966724396
Loss: 0.5010538101196289
Loss: 0.3353678584098816
Loss: 0.594982385635376
Loss: 0.31040146946907043
Loss: 0.46941590309143066
Loss: 0.6845666766166687
Loss: 0.341100811958313
Loss: 0.25442302227020264
Loss: 0.3078650236129761
Loss: 0.6150325536727905
Loss: 0.7943568229675293
Loss: 0.579255223274231
Loss: 0.33638885617256165
Loss: 0.4062460660934448
Loss: 0.5237076878547668
Loss: 0.6079686284065247
Loss: 0.2866589426994324
Loss: 0.4743526875972748
Loss: 0.5893777012825012
Loss: 0.7574805617332458
Loss: 0.4850495755672455
Loss: 0.12987537682056427
Loss: 0.6779178977012634
Loss: 0.34963253140449524
[Train] Epoch 21, accuracy 0.9998263888888889
[Eval] Epoch 21, loss 5.161703, accuracy 0.998264
Loss: 0.4340698719024658
Loss: 0.26795440912246704
Loss: 0.3543338477611542
Loss: 0.49854299426078796
Loss: 0.5152491927146912
Loss: 0.44003716111183167
Loss: 0.23346053063869476
Loss: 0.4589099884033203
Loss: 0.6024730801582336
Loss: 0.31945064663887024
Loss: 0.10803064703941345
Loss: 0.19872601330280304
Loss: 0.5159762501716614
Loss: 0.3466257154941559
Loss: 0.6085185408592224
Loss: 0.4834150969982147
Loss: 0.14739608764648438
Loss: 0.4218011200428009
Loss: 0.41445717215538025
Loss: 0.3434082865715027
Loss: 0.6405519247055054
Loss: 0.5311173796653748
Loss: 0.24747635424137115
Loss: 0.3536306321620941
Loss: 0.18785560131072998
Loss: 0.22733664512634277
Loss: 0.4832778871059418
Loss: 0.42608168721199036
Loss: 0.25689950585365295
Loss: 0.3509599268436432
Loss: 0.2913759648799896
Loss: 0.35330766439437866
Loss: 0.10803930461406708
Loss: 0.37827616930007935
Loss: 0.6692999005317688
Loss: 0.33449211716651917
Loss: 0.4092487692832947
Loss: 0.2460070103406906
Loss: 0.26200753450393677
Loss: 0.26803940534591675
Loss: 0.441079705953598
Loss: 0.5616759657859802
Loss: 0.3618744909763336
Loss: 0.5804640650749207
Loss: 0.17933541536331177
Loss: 0.5258540511131287
Loss: 0.20765075087547302
Loss: 0.2464258372783661
Loss: 0.3370639383792877
Loss: 0.6655736565589905
Loss: 0.2608513832092285
Loss: 0.5010944604873657
Loss: 0.6773202419281006
Loss: 0.37393510341644287
Loss: 0.3455272912979126
Loss: 0.4329678416252136
Loss: 0.43510445952415466
Loss: 0.36212000250816345
Loss: 0.4003024995326996
Loss: 0.3959915041923523
Loss: 0.39265188574790955
Loss: 0.3207124173641205
Loss: 0.18702161312103271
Loss: 0.3914560377597809
Loss: 0.340236097574234
Loss: 0.3834157884120941
Loss: 0.4467344880104065
Loss: 0.2808713912963867
Loss: 0.42253345251083374
Loss: 0.5306016206741333
Loss: 0.36714068055152893
Loss: 0.491148442029953
Loss: 0.48807811737060547
Loss: 0.19398152828216553
Loss: 0.40162724256515503
Loss: 0.4891951382160187
Loss: 0.502465009689331
Loss: 0.4198940396308899
Loss: 0.5155289173126221
Loss: 0.3119589388370514
Loss: 0.3021325170993805
Loss: 0.39056625962257385
Loss: 0.2059069722890854
Loss: 0.4548323154449463
Loss: 0.2491469532251358
Loss: 0.3044058680534363
Loss: 0.49948570132255554
Loss: 0.42795953154563904
Loss: 0.20362241566181183
Loss: 0.14629288017749786
[Train] Epoch 22, accuracy 0.9998263888888889
[Eval] Epoch 22, loss 5.157800, accuracy 0.997222
Loss: 0.21240131556987762
Loss: 0.3563789427280426
Loss: 0.35483160614967346
Loss: 0.3861848711967468
Loss: 0.21547311544418335
Loss: 0.1425544023513794
Loss: 0.20775282382965088
Loss: 0.20093831419944763
Loss: 0.30623310804367065
Loss: 0.3941495716571808
Loss: 0.20869910717010498
Loss: 0.35209041833877563
Loss: 0.23105230927467346
Loss: 0.32096824049949646
Loss: 0.40908703207969666
Loss: 0.5005670189857483
Loss: 0.6494588851928711
Loss: 0.29084932804107666
Loss: 0.6040627956390381
Loss: 0.097461998462677
Loss: 0.3056008219718933
Loss: 0.2837475538253784
Loss: 0.7444579005241394
Loss: 0.48246586322784424
Loss: 0.2690284252166748
Loss: 0.3503858149051666
Loss: 0.301847904920578
Loss: 0.5546433329582214
Loss: 0.2556820511817932
Loss: 0.2465653121471405
Loss: 0.5346216559410095
Loss: 0.4959231913089752
Loss: 0.33655083179473877
Loss: 0.4000987410545349
Loss: 0.2530967891216278
Loss: 0.4969329237937927
Loss: 0.2304687798023224
Loss: 0.1121225655078888
Loss: 0.23090782761573792
Loss: 0.4826856553554535
Loss: 0.6494866609573364
Loss: 0.26950621604919434
Loss: 0.286978155374527
Loss: 0.39133328199386597
Loss: 0.19221121072769165
Loss: 0.3116529881954193
Loss: 0.2487839162349701
Loss: 0.3418790102005005
Loss: 0.18766207993030548
Loss: 0.3058951199054718
Loss: 0.42778128385543823
Loss: 0.31245627999305725
Loss: 0.2681645154953003
Loss: 0.6186270713806152
Loss: 0.23734045028686523
Loss: 0.2534485161304474
Loss: 0.3454604744911194
Loss: 0.43182581663131714
Loss: 0.28279006481170654
Loss: 0.3728174865245819
Loss: 0.3698291778564453
Loss: 0.4077290892601013
Loss: 0.43254122138023376
Loss: 0.10184153914451599
Loss: 0.29702305793762207
Loss: 0.39382943511009216
Loss: 0.18629013001918793
Loss: 0.6316463947296143
Loss: 0.47298967838287354
Loss: 0.3075335919857025
Loss: 0.28678226470947266
Loss: 0.226969912648201
Loss: 0.3692511022090912
Loss: 0.2960248291492462
Loss: 0.07401536405086517
Loss: 0.3043489158153534
Loss: 0.5262937545776367
Loss: 0.4403340518474579
Loss: 0.36735060811042786
Loss: 0.6704302430152893
Loss: 0.3185999095439911
Loss: 0.2335418164730072
Loss: 0.14468364417552948
Loss: 0.3028820753097534
Loss: 0.4545636475086212
Loss: 0.13065926730632782
Loss: 0.24093516170978546
Loss: 0.2429569661617279
Loss: 0.15706133842468262
Loss: 0.2710912823677063
[Train] Epoch 23, accuracy 0.9997395833333333
[Eval] Epoch 23, loss 5.156675, accuracy 0.997917
Loss: 0.18895046412944794
Loss: 0.3163822591304779
Loss: 0.19394227862358093
Loss: 0.3426249027252197
Loss: 0.38012370467185974
Loss: 0.2801065444946289
Loss: 0.21547745168209076
Loss: 0.30121418833732605
Loss: 0.2288878858089447
Loss: 0.30243751406669617
Loss: 0.2824349105358124
Loss: 0.18147292733192444
Loss: 0.3854127526283264
Loss: 0.5266969799995422
Loss: 0.5308619141578674
Loss: 0.5903277397155762
Loss: 0.22465971112251282
Loss: 0.10594641417264938
Loss: 0.19337037205696106
Loss: 0.3322904109954834
Loss: 0.17048664391040802
Loss: 0.19362112879753113
Loss: 0.13282857835292816
Loss: 0.3128584623336792
Loss: 0.20428025722503662
Loss: 0.2525976598262787
Loss: 0.31676411628723145
Loss: 0.44773560762405396
Loss: 0.2145971655845642
Loss: 0.551141619682312
Loss: 0.515440046787262
Loss: 0.25626352429389954
Loss: 0.3012261390686035
Loss: 0.14560295641422272
Loss: 0.33770477771759033
Loss: 0.17342841625213623
Loss: 0.15157264471054077
Loss: 0.3227126896381378
Loss: 0.3709903359413147
Loss: 0.26381129026412964
Loss: 0.3599814176559448
Loss: 0.29731518030166626
Loss: 0.3471325933933258
Loss: 0.2072412669658661
Loss: 0.13143689930438995
Loss: 0.1954856961965561
Loss: 0.3313103914260864
Loss: 0.2552013397216797
Loss: 0.3071603775024414
Loss: 0.3056585490703583
Loss: 0.799403727054596
Loss: 0.25516536831855774
Loss: 0.21728330850601196
Loss: 0.22654110193252563
Loss: 0.24973264336585999
Loss: 0.26598766446113586
Loss: 0.5607109069824219
Loss: 0.3368552327156067
Loss: 0.21781478822231293
Loss: 0.28071850538253784
Loss: 0.5694347023963928
Loss: 0.17189903557300568
Loss: 0.2542341649532318
Loss: 0.27624309062957764
Loss: 0.4780201017856598
Loss: 0.2163226157426834
Loss: 0.1359001100063324
Loss: 0.30603834986686707
Loss: 0.41659486293792725
Loss: 0.4685102701187134
Loss: 0.4643198549747467
Loss: 0.297582745552063
Loss: 0.29010123014450073
Loss: 0.21047785878181458
Loss: 0.2966460883617401
Loss: 0.2732658386230469
Loss: 0.3031938970088959
Loss: 0.35775038599967957
Loss: 0.5125625729560852
Loss: 0.315061092376709
Loss: 0.22773917019367218
Loss: 0.1799565553665161
Loss: 0.3385068476200104
Loss: 0.5251753330230713
Loss: 0.1155155748128891
Loss: 0.2683994174003601
Loss: 0.2579136788845062
Loss: 0.15679632127285004
Loss: 0.19239693880081177
Loss: 0.390470415353775
[Train] Epoch 24, accuracy 0.9998263888888889
[Eval] Epoch 24, loss 5.162926, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.11054832488298416
Loss: 0.08587773144245148
Loss: 0.5138624906539917
Loss: 0.265840083360672
Loss: 0.14346562325954437
Loss: 0.2720741331577301
Loss: 0.09427192062139511
Loss: 0.21501827239990234
Loss: 0.2666970193386078
Loss: 0.39088037610054016
Loss: 0.19837157428264618
Loss: 0.17826059460639954
Loss: 0.040886297821998596
Loss: 0.482001394033432
Loss: 0.20129314064979553
Loss: 0.2988470196723938
Loss: 0.29255375266075134
Loss: 0.32349422574043274
Loss: 0.48818036913871765
Loss: 0.18682000041007996
Loss: 0.09247652441263199
Loss: 0.05777645856142044
Loss: 0.14635680615901947
Loss: 0.14934462308883667
Loss: 0.2607780694961548
Loss: 0.2575256824493408
Loss: 0.1471572071313858
Loss: 0.3901987671852112
Loss: 0.46609729528427124
Loss: 0.44403505325317383
Loss: 0.20870009064674377
Loss: 0.37498316168785095
Loss: 0.16279013454914093
Loss: 0.13532698154449463
Loss: 0.11701276153326035
Loss: 0.23588413000106812
Loss: 0.5036618709564209
Loss: 0.19355545938014984
Loss: 0.17271141707897186
Loss: 0.45579200983047485
Loss: 0.41462647914886475
Loss: 0.3674611449241638
Loss: 0.1781315803527832
Loss: 0.15987439453601837
Loss: 0.21659821271896362
Loss: 0.12775234878063202
Loss: 0.15776240825653076
Loss: 0.2084815949201584
Loss: 0.4898454546928406
Loss: 0.28249138593673706
Loss: 0.4202818274497986
Loss: 0.33908575773239136
Loss: 0.110488161444664
Loss: 0.14743684232234955
Loss: 0.14979100227355957
Loss: 0.16067612171173096
Loss: 0.20886904001235962
Loss: 0.32729166746139526
Loss: 0.5153275728225708
Loss: 0.17011618614196777
Loss: 0.24654003977775574
Loss: 0.3035648465156555
Loss: 0.058717552572488785
Loss: 0.2778611481189728
Loss: 0.26455190777778625
Loss: 0.3175729811191559
Loss: 0.0412181131541729
Loss: 0.08158489316701889
Loss: 0.5093045830726624
Loss: 0.3343794345855713
Loss: 0.22764386236667633
Loss: 0.2365366518497467
Loss: 0.41396743059158325
Loss: 0.3041466176509857
Loss: 0.25894299149513245
Loss: 0.15593332052230835
Loss: 0.06762682646512985
Loss: 0.2231312096118927
Loss: 0.17346395552158356
Loss: 0.2702893614768982
Loss: 0.2347891926765442
Loss: 0.6604219675064087
Loss: 0.2810439467430115
Loss: 0.18594703078269958
Loss: 0.2857242822647095
Loss: 0.1709904968738556
Loss: 0.15694931149482727
Loss: 0.6092055439949036
Loss: 0.29224902391433716
Loss: 0.24021485447883606
[Train] Epoch 25, accuracy 0.9998263888888889
[Eval] Epoch 25, loss 5.156767, accuracy 0.997917
Loss: 0.11958276480436325
Loss: 0.08620477467775345
Loss: 0.1385035514831543
Loss: 0.19788269698619843
Loss: 0.3121013343334198
Loss: 0.32024455070495605
Loss: 0.11468597501516342
Loss: 0.3424418270587921
Loss: 0.08742060512304306
Loss: 0.1720084846019745
Loss: 0.27874666452407837
Loss: 0.20419788360595703
Loss: 0.2484964281320572
Loss: 0.30394867062568665
Loss: 0.6848264932632446
Loss: 0.2429836094379425
Loss: 0.23321764171123505
Loss: 0.7215511798858643
Loss: 0.16400308907032013
Loss: 0.3473987281322479
Loss: 0.12925682961940765
Loss: 0.11754458397626877
Loss: 0.236398845911026
Loss: 0.1336362510919571
Loss: 0.29573437571525574
Loss: 0.16554750502109528
Loss: 0.2671752870082855
Loss: 0.2080899327993393
Loss: 0.24799418449401855
Loss: 0.2074028104543686
Loss: 0.2449290007352829
Loss: 0.3587550222873688
Loss: 0.20586057007312775
Loss: 0.328582227230072
Loss: 0.14251069724559784
Loss: 0.6691778898239136
Loss: 0.23151636123657227
Loss: 0.2144351452589035
Loss: 0.2935706675052643
Loss: 0.33992892503738403
Loss: 0.33178025484085083
Loss: 0.3303740918636322
Loss: 0.21858783066272736
Loss: 0.22384682297706604
Loss: 0.18130970001220703
Loss: 0.26635730266571045
Loss: 0.14892517030239105
Loss: 0.4863071143627167
Loss: 0.19203464686870575
Loss: 0.42521876096725464
Loss: 0.19466114044189453
Loss: 0.21149027347564697
Loss: 0.48967868089675903
Loss: 0.2705107629299164
Loss: 0.1677418351173401
Loss: 0.09141431748867035
Loss: 0.25631457567214966
Loss: 0.34943780303001404
Loss: 0.17843322455883026
Loss: 0.26142260432243347
Loss: 0.15471838414669037
Loss: 0.2544058561325073
Loss: 0.20806093513965607
Loss: 0.28631213307380676
Loss: 0.1969679892063141
Loss: 0.09689576178789139
Loss: 0.1564204841852188
Loss: 0.11914141476154327
Loss: 0.39397916197776794
Loss: 0.12542524933815002
Loss: 0.2632724344730377
Loss: 0.22794343531131744
Loss: 0.2100725769996643
Loss: 0.13335490226745605
Loss: 0.3432842791080475
Loss: 0.17118223011493683
Loss: 0.2973785996437073
Loss: 0.3162764608860016
Loss: 0.11051101237535477
Loss: 0.2605559229850769
Loss: 0.5983931422233582
Loss: 0.2504213750362396
Loss: 0.12461897730827332
Loss: 0.1834351271390915
Loss: 0.33640366792678833
Loss: 0.23245501518249512
Loss: 0.2736787497997284
Loss: 0.2796933650970459
Loss: 0.34861820936203003
Loss: 0.3299424946308136
[Train] Epoch 26, accuracy 0.9997395833333333
[Eval] Epoch 26, loss 5.151013, accuracy 0.998264
Loss: 0.3942561447620392
Loss: 0.3072530925273895
Loss: 0.2075788825750351
Loss: 0.2393685281276703
Loss: 0.3807251453399658
Loss: 0.19068728387355804
Loss: 0.07962995022535324
Loss: 0.12281306833028793
Loss: 0.3118096888065338
Loss: 0.15112589299678802
Loss: 0.16147781908512115
Loss: 0.45958858728408813
Loss: 0.2885902225971222
Loss: 0.28133466839790344
Loss: 0.14440880715847015
Loss: 0.14239434897899628
Loss: 0.23381318151950836
Loss: 0.15273110568523407
Loss: 0.33497878909111023
Loss: 0.17277181148529053
Loss: 0.20086656510829926
Loss: 0.15527169406414032
Loss: 0.20159821212291718
Loss: 0.46649008989334106
Loss: 0.22134771943092346
Loss: 0.08813374489545822
Loss: 0.4063488841056824
Loss: 0.10358944535255432
Loss: 0.3838660418987274
Loss: 0.32178279757499695
Loss: 0.2351662814617157
Loss: 0.21222230792045593
Loss: 0.2634136378765106
Loss: 0.20143908262252808
Loss: 0.2782481014728546
Loss: 0.24236588180065155
Loss: 0.2752070724964142
Loss: 0.18587075173854828
Loss: 0.2186427116394043
Loss: 0.1412898451089859
Loss: 0.17094095051288605
Loss: 0.2506539821624756
Loss: 0.15670917928218842
Loss: 0.08129262924194336
Loss: 0.1893596649169922
Loss: 0.22814178466796875
Loss: 0.2706329822540283
Loss: 0.2978823184967041
Loss: 0.27456262707710266
Loss: 0.12449505925178528
Loss: 0.4099016785621643
Loss: 0.1829233467578888
Loss: 0.1708664447069168
Loss: 0.17493721842765808
Loss: 0.2405412644147873
Loss: 0.13843804597854614
Loss: 0.20392070710659027
Loss: 0.6338569521903992
Loss: 0.12546053528785706
Loss: 0.12264171242713928
Loss: 0.22324900329113007
Loss: 0.15119589865207672
Loss: 0.2012249380350113
Loss: 0.23522716760635376
Loss: 0.32317236065864563
Loss: 0.20801980793476105
Loss: 0.058546144515275955
Loss: 0.19248630106449127
Loss: 0.18409910798072815
Loss: 0.3313569724559784
Loss: 0.2220454066991806
Loss: 0.13905377686023712
Loss: 0.29317840933799744
Loss: 0.21691909432411194
Loss: 0.08034095168113708
Loss: 0.10669568181037903
Loss: 0.22753438353538513
Loss: 0.13504144549369812
Loss: 0.5171398520469666
Loss: 0.06638698279857635
Loss: 0.32156258821487427
Loss: 0.35059747099876404
Loss: 0.13178464770317078
Loss: 0.07945284247398376
Loss: 0.20236331224441528
Loss: 0.031426798552274704
Loss: 0.22714321315288544
Loss: 0.3247841000556946
Loss: 0.1304776966571808
Loss: 0.09338852763175964
[Train] Epoch 27, accuracy 0.9999131944444445
[Eval] Epoch 27, loss 5.149133, accuracy 0.998264
Loss: 0.15056733787059784
Loss: 0.2126464992761612
Loss: 0.06665771454572678
Loss: 0.15562336146831512
Loss: 0.09823020547628403
Loss: 0.2954327464103699
Loss: 0.057797204703092575
Loss: 0.159417986869812
Loss: 0.030053094029426575
Loss: 0.056929152458906174
Loss: 0.08229195326566696
Loss: 0.14129529893398285
Loss: 0.2693844437599182
Loss: 0.26758456230163574
Loss: 0.1840895712375641
Loss: 0.41723817586898804
Loss: 0.11465093493461609
Loss: 0.2067680060863495
Loss: 0.15402384102344513
Loss: 0.039431117475032806
Loss: 0.1977875828742981
Loss: 0.39760759472846985
Loss: 0.31369930505752563
Loss: 0.23821938037872314
Loss: 0.2373589277267456
Loss: 0.1748248040676117
Loss: 0.05595541000366211
Loss: 0.18903321027755737
Loss: 0.28210657835006714
Loss: 0.20636175572872162
Loss: 0.2099405974149704
Loss: 0.10013766586780548
Loss: 0.4499293565750122
Loss: 0.11737357079982758
Loss: 0.11757078021764755
Loss: 0.038162827491760254
Loss: 0.03551875427365303
Loss: 0.2266138195991516
Loss: 0.13485871255397797
Loss: 0.0889742448925972
Loss: 0.30944788455963135
Loss: 0.04581970348954201
Loss: 0.08409512788057327
Loss: 0.31865787506103516
Loss: 0.02310449443757534
Loss: 0.708160936832428
Loss: 0.05818141624331474
Loss: 0.17204654216766357
Loss: 0.207298144698143
Loss: 0.13154193758964539
Loss: 0.20461499691009521
Loss: 0.2580175995826721
Loss: 0.2525765299797058
Loss: 0.12020384520292282
Loss: 0.2375420778989792
Loss: 0.23421543836593628
Loss: 0.2180328369140625
Loss: 0.43010014295578003
Loss: 0.10031979531049728
Loss: 0.13003741204738617
Loss: 0.19068613648414612
Loss: 0.24566897749900818
Loss: 0.3584635257720947
Loss: 0.15680760145187378
Loss: 0.3351636826992035
Loss: 0.1747438907623291
Loss: 0.07503469288349152
Loss: 0.15156325697898865
Loss: 0.40094104409217834
Loss: 0.08625394850969315
Loss: 0.1210162341594696
Loss: 0.14821402728557587
Loss: 0.15506070852279663
Loss: 0.13341283798217773
Loss: 0.30624738335609436
Loss: 0.18463261425495148
Loss: 0.029152534902095795
Loss: 0.2303236424922943
Loss: 0.17960156500339508
Loss: 0.11244861781597137
Loss: 0.3172369599342346
Loss: 0.11282296478748322
Loss: 0.014678819105029106
Loss: 0.22811003029346466
Loss: 0.08586441725492477
Loss: 0.30633267760276794
Loss: 0.2617332637310028
Loss: 0.06849026679992676
Loss: 0.11245029419660568
Loss: 0.24801090359687805
[Train] Epoch 28, accuracy 0.9999131944444445
[Eval] Epoch 28, loss 5.148882, accuracy 0.998611
Model saved as x_small_model_weights_best.pth
Loss: 0.13191550970077515
Loss: 0.1516440361738205
Loss: 0.05513650178909302
Loss: 0.24150647222995758
Loss: 0.12990279495716095
Loss: 0.04068184643983841
Loss: 0.13641446828842163
Loss: 0.1704225391149521
Loss: 0.14486989378929138
Loss: 0.22664161026477814
Loss: 0.12013108283281326
Loss: 0.13710440695285797
Loss: 0.12865637242794037
Loss: 0.04803859815001488
Loss: 0.1471598595380783
Loss: 0.09950407594442368
Loss: 0.045209065079689026
Loss: 0.311223566532135
Loss: 0.08599770814180374
Loss: 0.16443148255348206
Loss: 0.14037472009658813
Loss: 0.2373669594526291
Loss: 0.11494781076908112
Loss: 0.1049405112862587
Loss: 0.18824179470539093
Loss: 0.29333212971687317
Loss: 0.17944619059562683
Loss: 0.1260027289390564
Loss: 0.12244522571563721
Loss: 0.07928899675607681
Loss: 0.17483878135681152
Loss: 0.1100982129573822
Loss: 0.07292687147855759
Loss: 0.1499926596879959
Loss: 0.17576085031032562
Loss: 0.14272364974021912
Loss: 0.056949764490127563
Loss: 0.2626855671405792
Loss: 0.18226179480552673
Loss: 0.12678839266300201
Loss: 0.11746296286582947
Loss: 0.16979679465293884
Loss: 0.07562600076198578
Loss: 0.23262877762317657
Loss: 0.2785930931568146
Loss: 0.1732814759016037
Loss: 0.08846625685691833
Loss: 0.10059355199337006
Loss: 0.15712860226631165
Loss: 0.17042326927185059
Loss: 0.07480031996965408
Loss: 0.13261739909648895
Loss: 0.049217402935028076
Loss: 0.13757722079753876
Loss: 0.18196417391300201
Loss: 0.3261052072048187
Loss: 0.24673707783222198
Loss: 0.09256365895271301
Loss: 0.08947300165891647
Loss: 0.21318568289279938
Loss: 0.09349758177995682
Loss: 0.23250755667686462
Loss: 0.16495443880558014
Loss: 0.08108003437519073
Loss: 0.08888161927461624
Loss: 0.06857343018054962
Loss: 0.3503454327583313
Loss: 0.31581518054008484
Loss: 0.06484803557395935
Loss: 0.11384275555610657
Loss: 0.3223543167114258
Loss: 0.22476261854171753
Loss: 0.11811990290880203
Loss: 0.1913924366235733
Loss: 0.09514326602220535
Loss: 0.18152648210525513
Loss: 0.1948075294494629
Loss: 0.16773781180381775
Loss: 0.013032055459916592
Loss: 0.22193819284439087
Loss: 0.09666714817285538
Loss: 0.0492856465280056
Loss: 0.17938345670700073
Loss: 0.056686338037252426
Loss: 0.17691540718078613
Loss: 0.05795897915959358
Loss: 0.09083312749862671
Loss: 0.2995264530181885
Loss: 0.2774626612663269
Loss: 0.04255286604166031
[Train] Epoch 29, accuracy 0.9999131944444445
[Eval] Epoch 29, loss 5.143042, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.12461750954389572
Loss: 0.07325273752212524
Loss: 0.3322764039039612
Loss: 0.12707024812698364
Loss: 0.18712715804576874
Loss: 0.17160195112228394
Loss: 0.043704353272914886
Loss: 0.07780545204877853
Loss: 0.22408883273601532
Loss: 0.1345200091600418
Loss: 0.13858363032341003
Loss: 0.10602668672800064
Loss: 0.14006809890270233
Loss: 0.020927155390381813
Loss: 0.08162079006433487
Loss: 0.0945814996957779
Loss: 0.229190394282341
Loss: 0.21891584992408752
Loss: 0.13168534636497498
Loss: 0.07761497795581818
Loss: 0.16374066472053528
Loss: 0.029386932030320168
Loss: 0.1455884873867035
Loss: 0.06545957177877426
Loss: 0.13700231909751892
Loss: 0.1688278168439865
Loss: 0.04572826623916626
Loss: 0.07069908082485199
Loss: 0.2431415319442749
Loss: 0.12368416786193848
Loss: 0.1077607274055481
Loss: 0.030338935554027557
Loss: 0.1841094046831131
Loss: 0.030345384031534195
Loss: 0.06018630415201187
Loss: 0.2168387919664383
Loss: 0.14050881564617157
Loss: 0.15537050366401672
Loss: 0.050855450332164764
Loss: 0.321703165769577
Loss: 0.11387946456670761
Loss: 0.10417601466178894
Loss: 0.242009237408638
Loss: 0.016489174216985703
Loss: 0.2153581976890564
Loss: 0.060348138213157654
Loss: 0.25232645869255066
Loss: 0.014362079091370106
Loss: 0.18084560334682465
Loss: 0.08879634737968445
Loss: 0.14552274346351624
Loss: 0.18541434407234192
Loss: 0.11136145144701004
Loss: 0.10103911906480789
Loss: 0.19387772679328918
Loss: 0.10527458041906357
Loss: 0.17616082727909088
Loss: 0.39446666836738586
Loss: 0.23650780320167542
Loss: 0.11399415135383606
Loss: 0.10302610695362091
Loss: 0.054779767990112305
Loss: 0.10036426782608032
Loss: 0.0832613930106163
Loss: 0.08401037752628326
Loss: 0.26383015513420105
Loss: 0.3274206817150116
Loss: 0.2224060297012329
Loss: 0.12101932615041733
Loss: 0.2192954123020172
Loss: 0.058745913207530975
Loss: 0.07149779051542282
Loss: 0.1079905703663826
Loss: 0.07313447445631027
Loss: 0.012267209589481354
Loss: 0.0642278641462326
Loss: 0.22544704377651215
Loss: 0.045299120247364044
Loss: 0.4007329046726227
Loss: 0.10298877954483032
Loss: 0.09836413711309433
Loss: 0.17932763695716858
Loss: 0.14957159757614136
Loss: 0.08050841093063354
Loss: 0.10653897374868393
Loss: 0.19296087324619293
Loss: 0.16035382449626923
Loss: 0.07423745840787888
Loss: 0.1469176709651947
Loss: 0.1231704130768776
[Train] Epoch 30, accuracy 1.0
[Eval] Epoch 30, loss 5.145338, accuracy 0.997917
Loss: 0.12777599692344666
Loss: 0.06900713592767715
Loss: 0.12390528619289398
Loss: 0.1656816601753235
Loss: 0.24215203523635864
Loss: 0.06492207944393158
Loss: 0.04196973145008087
Loss: 0.12073086202144623
Loss: 0.05102778598666191
Loss: 0.2813470661640167
Loss: 0.03871098533272743
Loss: 0.22252731025218964
Loss: 0.07640266418457031
Loss: 0.11382603645324707
Loss: 0.056545108556747437
Loss: 0.12785792350769043
Loss: 0.2164204716682434
Loss: 0.02899252250790596
Loss: 0.2099505066871643
Loss: 0.03791874274611473
Loss: 0.16794417798519135
Loss: 0.05388399586081505
Loss: 0.13853862881660461
Loss: 0.3349390923976898
Loss: 0.09082718938589096
Loss: 0.05894605442881584
Loss: 0.09945069998502731
Loss: 0.13391096889972687
Loss: 0.09588055312633514
Loss: 0.12845495343208313
Loss: 0.10208521038293839
Loss: 0.20727531611919403
Loss: 0.0989922434091568
Loss: 0.018744397908449173
Loss: 0.21633528172969818
Loss: 0.09215662628412247
Loss: 0.15757305920124054
Loss: 0.06134546920657158
Loss: 0.21893350780010223
Loss: 0.16186243295669556
Loss: 0.01607971079647541
Loss: 0.04447145015001297
Loss: 0.05882026255130768
Loss: 0.2762485444545746
Loss: 0.11123869568109512
Loss: 0.0916367843747139
Loss: 0.122310109436512
Loss: 0.10495517402887344
Loss: 0.0888577327132225
Loss: 0.2267918586730957
Loss: 0.4012898802757263
Loss: 0.14193499088287354
Loss: 0.08488880842924118
Loss: 0.2013331949710846
Loss: 0.03172004595398903
Loss: 0.18923404812812805
Loss: 0.11219513416290283
Loss: 0.0453667938709259
Loss: 0.06288805603981018
Loss: 0.4852747917175293
Loss: 0.0529261939227581
Loss: 0.09595810621976852
Loss: 0.10512542724609375
Loss: 0.09319961816072464
Loss: 0.1606597602367401
Loss: 0.06651127338409424
Loss: 0.02511967346072197
Loss: 0.18981991708278656
Loss: 0.021099716424942017
Loss: 0.08996722847223282
Loss: 0.15020830929279327
Loss: 0.10661754012107849
Loss: 0.046246640384197235
Loss: 0.1515733301639557
Loss: 0.14843566715717316
Loss: 0.0715366080403328
Loss: 0.13345922529697418
Loss: 0.2931605875492096
Loss: 0.0606471449136734
Loss: 0.04955045506358147
Loss: 0.019025735557079315
Loss: 0.359115868806839
Loss: 0.11170513927936554
Loss: 0.11519622057676315
Loss: 0.1424006223678589
Loss: 0.050446487963199615
Loss: 0.03900126740336418
Loss: 0.2616059482097626
Loss: 0.0514523983001709
Loss: 0.17576463520526886
[Train] Epoch 31, accuracy 1.0
[Eval] Epoch 31, loss 5.147241, accuracy 0.997917
Loss: 0.10630689561367035
Loss: 0.18478283286094666
Loss: 0.017684703692793846
Loss: 0.19131211936473846
Loss: 0.10113698244094849
Loss: 0.03925377130508423
Loss: 0.15859386324882507
Loss: 0.07484530657529831
Loss: 0.052747029811143875
Loss: 0.11414062976837158
Loss: 0.4895286560058594
Loss: 0.18296773731708527
Loss: 0.09982992708683014
Loss: 0.2504577040672302
Loss: 0.2852816879749298
Loss: 0.1712355762720108
Loss: 0.14303971827030182
Loss: 0.06473895162343979
Loss: 0.12123621255159378
Loss: 0.10224910080432892
Loss: 0.1272943913936615
Loss: 0.27441462874412537
Loss: 0.056159503757953644
Loss: 0.09565208107233047
Loss: 0.2636915147304535
Loss: 0.11964963376522064
Loss: 0.05950906127691269
Loss: 0.2769332826137543
Loss: 0.17565175890922546
Loss: 0.03884970024228096
Loss: 0.044630203396081924
Loss: 0.11689156293869019
Loss: 0.17867393791675568
Loss: 0.029817752540111542
Loss: 0.08962659537792206
Loss: 0.1121329739689827
Loss: 0.11399409919977188
Loss: 0.2195187360048294
Loss: 0.04562284052371979
Loss: 0.14698387682437897
Loss: 0.21618174016475677
Loss: 0.12038809806108475
Loss: 0.051438670605421066
Loss: 0.14649301767349243
Loss: 0.09618666023015976
Loss: 0.04604759439826012
Loss: 0.2744266092777252
Loss: 0.04108726978302002
Loss: 0.13936983048915863
Loss: 0.048843864351511
Loss: 0.09036440402269363
Loss: 0.11526649445295334
Loss: 0.048457756638526917
Loss: 0.17829565703868866
Loss: 0.016561297699809074
Loss: 0.049366481602191925
Loss: 0.09691116958856583
Loss: 0.03511880710721016
Loss: 0.013818525709211826
Loss: 0.13522054255008698
Loss: 0.06486590206623077
Loss: 0.12733513116836548
Loss: 0.03744298219680786
Loss: 0.15171988308429718
Loss: 0.18964986503124237
Loss: 0.19980166852474213
Loss: 0.055189356207847595
Loss: 0.07271202653646469
Loss: 0.07300631701946259
Loss: 0.26767492294311523
Loss: 0.4194316267967224
Loss: 0.01131642796099186
Loss: 0.13365225493907928
Loss: 0.03605948016047478
Loss: 0.04577147960662842
Loss: 0.20785166323184967
Loss: 0.16238325834274292
Loss: 0.09981713443994522
Loss: 0.06982620060443878
Loss: 0.12345784157514572
Loss: 0.150377556681633
Loss: 0.016426431015133858
Loss: 0.14200465381145477
Loss: 0.26041072607040405
Loss: 0.19756101071834564
Loss: 0.008797782473266125
Loss: 0.18022531270980835
Loss: 0.09291154146194458
Loss: 0.08454325050115585
Loss: 0.0701618418097496
[Train] Epoch 32, accuracy 0.9999131944444445
[Eval] Epoch 32, loss 5.141383, accuracy 0.997917
Loss: 0.15653583407402039
Loss: 0.14280585944652557
Loss: 0.14729809761047363
Loss: 0.22629041969776154
Loss: 0.0804358497262001
Loss: 0.11612468212842941
Loss: 0.1477176547050476
Loss: 0.06161194294691086
Loss: 0.03903154656291008
Loss: 0.0445682629942894
Loss: 0.07154951989650726
Loss: 0.055765341967344284
Loss: 0.27650776505470276
Loss: 0.3899882733821869
Loss: 0.04849204421043396
Loss: 0.09364096075296402
Loss: 0.1340213418006897
Loss: 0.06156478822231293
Loss: 0.058688804507255554
Loss: 0.02581067569553852
Loss: 0.037009235471487045
Loss: 0.1281529664993286
Loss: 0.1296396255493164
Loss: 0.0622820109128952
Loss: 0.11697345227003098
Loss: 0.0318375863134861
Loss: 0.06995072215795517
Loss: 0.04154109209775925
Loss: 0.06974224001169205
Loss: 0.2470932900905609
Loss: 0.23844073712825775
Loss: 0.12190175801515579
Loss: 0.11222930997610092
Loss: 0.14166474342346191
Loss: 0.0593610554933548
Loss: 0.11119228601455688
Loss: 0.03454342111945152
Loss: 0.03708168491721153
Loss: 0.13606126606464386
Loss: 0.10611200332641602
Loss: 0.25668275356292725
Loss: 0.15722575783729553
Loss: 0.20162217319011688
Loss: 0.08100533485412598
Loss: 0.019158098846673965
Loss: 0.06600714474916458
Loss: 0.084250807762146
Loss: 0.07353091239929199
Loss: 0.08600088953971863
Loss: 0.08184094727039337
Loss: 0.10493941605091095
Loss: 0.12363504618406296
Loss: 0.03388587757945061
Loss: 0.04678522050380707
Loss: 0.1357097029685974
Loss: 0.18936452269554138
Loss: 0.15422402322292328
Loss: 0.0904705673456192
Loss: 0.014011609368026257
Loss: 0.16142910718917847
Loss: 0.02937101386487484
Loss: 0.26187101006507874
Loss: 0.10410495102405548
Loss: 0.03958979249000549
Loss: 0.1386975347995758
Loss: 0.23337337374687195
Loss: 0.13108479976654053
Loss: 0.019992709159851074
Loss: 0.054463692009449005
Loss: 0.14303143322467804
Loss: 0.20548895001411438
Loss: 0.24762912094593048
Loss: 0.052163101732730865
Loss: 0.18445348739624023
Loss: 0.06685107946395874
Loss: 0.039410945028066635
Loss: 0.07156990468502045
Loss: 0.09443607181310654
Loss: 0.2118181586265564
Loss: 0.11844013631343842
Loss: 0.103260338306427
Loss: 0.06426657736301422
Loss: 0.025263890624046326
Loss: 0.09967467188835144
Loss: 0.055217839777469635
Loss: 0.16787287592887878
Loss: 0.2739287316799164
Loss: 0.16129429638385773
Loss: 0.14423781633377075
Loss: 0.08079072833061218
[Train] Epoch 33, accuracy 0.9999131944444445
[Eval] Epoch 33, loss 5.133600, accuracy 0.998611
Loss: 0.1344645470380783
Loss: 0.04817261919379234
Loss: 0.14262273907661438
Loss: 0.010933858342468739
Loss: 0.15178561210632324
Loss: 0.19224900007247925
Loss: 0.03853205218911171
Loss: 0.09459751844406128
Loss: 0.07882669568061829
Loss: 0.04492717981338501
Loss: 0.12889151275157928
Loss: 0.14417660236358643
Loss: 0.045175548642873764
Loss: 0.11777333170175552
Loss: 0.2508592903614044
Loss: 0.06634102016687393
Loss: 0.0406828448176384
Loss: 0.1034071072936058
Loss: 0.1476711630821228
Loss: 0.03327649086713791
Loss: 0.13552898168563843
Loss: 0.08337157219648361
Loss: 0.11686795204877853
Loss: 0.100967638194561
Loss: 0.09060977399349213
Loss: 0.1463676393032074
Loss: 0.036968477070331573
Loss: 0.026357922703027725
Loss: 0.11025208979845047
Loss: 0.04463503509759903
Loss: 0.03026304952800274
Loss: 0.04896271973848343
Loss: 0.055964987725019455
Loss: 0.0827847346663475
Loss: 0.24488341808319092
Loss: 0.05706825107336044
Loss: 0.14486905932426453
Loss: 0.04234572499990463
Loss: 0.0855904147028923
Loss: 0.11760970205068588
Loss: 0.045181214809417725
Loss: 0.004931000526994467
Loss: 0.014000613242387772
Loss: 0.05052123963832855
Loss: 0.1083889901638031
Loss: 0.09460987150669098
Loss: 0.12269676476716995
Loss: 0.006153047550469637
Loss: 0.35453036427497864
Loss: 0.061545636504888535
Loss: 0.045898523181676865
Loss: 0.04928164184093475
Loss: 0.022783715277910233
Loss: 0.01976315677165985
Loss: 0.034883636981248856
Loss: 0.29074832797050476
Loss: 0.05777978152036667
Loss: 0.08767685294151306
Loss: 0.008847366087138653
Loss: 0.027128154411911964
Loss: 0.11994446069002151
Loss: 0.06826595216989517
Loss: 0.10262846946716309
Loss: 0.05503969267010689
Loss: 0.16636300086975098
Loss: 0.20179598033428192
Loss: 0.06336241960525513
Loss: 0.11987870931625366
Loss: 0.03643481060862541
Loss: 0.059829868376255035
Loss: 0.049972519278526306
Loss: 0.10841933637857437
Loss: 0.12920205295085907
Loss: 0.06217313930392265
Loss: 0.2934722304344177
Loss: 0.00868987012654543
Loss: 0.2605638802051544
Loss: 0.1693052053451538
Loss: 0.1254083216190338
Loss: 0.01959598995745182
Loss: 0.0111852353438735
Loss: 0.0768292024731636
Loss: 0.16801032423973083
Loss: 0.13424724340438843
Loss: 0.04984821006655693
Loss: 0.12132510542869568
Loss: 0.012623529881238937
Loss: 0.13937833905220032
Loss: 0.21791541576385498
Loss: 0.16264867782592773
[Train] Epoch 34, accuracy 0.9999131944444445
[Eval] Epoch 34, loss 5.149981, accuracy 0.998611
Loss: 0.044748321175575256
Loss: 0.04636486619710922
Loss: 0.09670377522706985
Loss: 0.06040216237306595
Loss: 0.15624989569187164
Loss: 0.08790566772222519
Loss: 0.11780479550361633
Loss: 0.031161392107605934
Loss: 0.09723739326000214
Loss: 0.028704281896352768
Loss: 0.02382010966539383
Loss: 0.026955565437674522
Loss: 0.062349963933229446
Loss: 0.01154700294137001
Loss: 0.07535425573587418
Loss: 0.09681639820337296
Loss: 0.08688641339540482
Loss: 0.12934356927871704
Loss: 0.04565548151731491
Loss: 0.020694337785243988
Loss: 0.047539010643959045
Loss: 0.0055058239959180355
Loss: 0.03605308383703232
Loss: 0.08802541345357895
Loss: 0.09609652310609818
Loss: 0.04391901195049286
Loss: 0.06523094326257706
Loss: 0.09037423133850098
Loss: 0.07808447629213333
Loss: 0.041831642389297485
Loss: 0.05489950627088547
Loss: 0.06557363271713257
Loss: 0.20002371072769165
Loss: 0.17613370716571808
Loss: 0.049812860786914825
Loss: 0.131148561835289
Loss: 0.04307808354496956
Loss: 0.05136801302433014
Loss: 0.01303122378885746
Loss: 0.046531014144420624
Loss: 0.040906764566898346
Loss: 0.11440987884998322
Loss: 0.07346148043870926
Loss: 0.014441514387726784
Loss: 0.08685024082660675
Loss: 0.08674310892820358
Loss: 0.09101703763008118
Loss: 0.10626493394374847
Loss: 0.06422793120145798
Loss: 0.3161746561527252
Loss: 0.017989888787269592
Loss: 0.025133369490504265
Loss: 0.15759631991386414
Loss: 0.11068453639745712
Loss: 0.04668675363063812
Loss: 0.01458681933581829
Loss: 0.18734204769134521
Loss: 0.09917549043893814
Loss: 0.08828514069318771
Loss: 0.05945645272731781
Loss: 0.08880908787250519
Loss: 0.08490021526813507
Loss: 0.06351537257432938
Loss: 0.06129991635680199
Loss: 0.05512591451406479
Loss: 0.05303991213440895
Loss: 0.05141730606555939
Loss: 0.1542714685201645
Loss: 0.12448633462190628
Loss: 0.07177912443876266
Loss: 0.061356257647275925
Loss: 0.06191898137331009
Loss: 0.15010759234428406
Loss: 0.194098100066185
Loss: 0.16021227836608887
Loss: 0.013384650461375713
Loss: 0.11567649245262146
Loss: 0.06506000459194183
Loss: 0.08861887454986572
Loss: 0.12294426560401917
Loss: 0.060695480555295944
Loss: 0.2336675226688385
Loss: 0.10935568064451218
Loss: 0.017193645238876343
Loss: 0.07634951919317245
Loss: 0.07862560451030731
Loss: 0.12555325031280518
Loss: 0.04986618086695671
Loss: 0.16632987558841705
Loss: 0.11492988467216492
[Train] Epoch 35, accuracy 1.0
[Eval] Epoch 35, loss 5.136541, accuracy 0.998611
Loss: 0.05230381712317467
Loss: 0.027727600187063217
Loss: 0.043711718171834946
Loss: 0.23816810548305511
Loss: 0.019360987469553947
Loss: 0.04969992861151695
Loss: 0.014963711611926556
Loss: 0.06311433762311935
Loss: 0.12948845326900482
Loss: 0.04189889132976532
Loss: 0.046104781329631805
Loss: 0.06437268853187561
Loss: 0.15995770692825317
Loss: 0.10843370109796524
Loss: 0.24432465434074402
Loss: 0.09741589426994324
Loss: 0.2126319408416748
Loss: 0.059421688318252563
Loss: 0.06631837785243988
Loss: 0.02499989978969097
Loss: 0.02679661475121975
Loss: 0.01272070687264204
Loss: 0.15631432831287384
Loss: 0.10673891007900238
Loss: 0.0634097084403038
Loss: 0.0903293788433075
Loss: 0.06358859688043594
Loss: 0.06745760887861252
Loss: 0.0382455512881279
Loss: 0.008777227252721786
Loss: 0.1270594745874405
Loss: 0.14765390753746033
Loss: 0.26268064975738525
Loss: 0.04412876442074776
Loss: 0.04466322064399719
Loss: 0.06143893301486969
Loss: 0.15731915831565857
Loss: 0.037610385566949844
Loss: 0.12422467023134232
Loss: 0.06276874244213104
Loss: 0.05797215551137924
Loss: 0.09847662597894669
Loss: 0.11295212060213089
Loss: 0.09719201922416687
Loss: 0.09191612154245377
Loss: 0.026972653344273567
Loss: 0.015418781898915768
Loss: 0.010371497832238674
Loss: 0.028410138562321663
Loss: 0.04924384877085686
Loss: 0.2553882300853729
Loss: 0.16728928685188293
Loss: 0.15808811783790588
Loss: 0.12943486869335175
Loss: 0.1153910756111145
Loss: 0.029881466180086136
Loss: 0.020933574065566063
Loss: 0.042658835649490356
Loss: 0.14601129293441772
Loss: 0.008132215589284897
Loss: 0.006604257971048355
Loss: 0.11147431284189224
Loss: 0.03070559911429882
Loss: 0.19176021218299866
Loss: 0.024868007749319077
Loss: 0.15324290096759796
Loss: 0.1499258130788803
Loss: 0.07852721214294434
Loss: 0.19226107001304626
Loss: 0.06505651026964188
Loss: 0.053493451327085495
Loss: 0.027101201936602592
Loss: 0.06891912966966629
Loss: 0.0755845159292221
Loss: 0.052815988659858704
Loss: 0.050262968987226486
Loss: 0.0902094766497612
Loss: 0.039701081812381744
Loss: 0.0971643477678299
Loss: 0.03929043933749199
Loss: 0.039496809244155884
Loss: 0.05138323828577995
Loss: 0.2947538197040558
Loss: 0.10424981266260147
Loss: 0.012826311402022839
Loss: 0.11745726317167282
Loss: 0.11873775720596313
Loss: 0.08536320179700851
Loss: 0.05824476480484009
Loss: 0.010289110243320465
[Train] Epoch 36, accuracy 1.0
[Eval] Epoch 36, loss 5.128714, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.08632486313581467
Loss: 0.020702257752418518
Loss: 0.0394040010869503
Loss: 0.06796299666166306
Loss: 0.09801606833934784
Loss: 0.02196723222732544
Loss: 0.10068600624799728
Loss: 0.03794756531715393
Loss: 0.02700146473944187
Loss: 0.1629888117313385
Loss: 0.07393151521682739
Loss: 0.1691620796918869
Loss: 0.052658021450042725
Loss: 0.16639326512813568
Loss: 0.085655577480793
Loss: 0.06729353964328766
Loss: 0.016520455479621887
Loss: 0.010097416117787361
Loss: 0.19480158388614655
Loss: 0.08741507679224014
Loss: 0.04399546608328819
Loss: 0.05832146108150482
Loss: 0.029882755130529404
Loss: 0.16617275774478912
Loss: 0.043459054082632065
Loss: 0.026115499436855316
Loss: 0.006312381010502577
Loss: 0.06506667286157608
Loss: 0.02263401634991169
Loss: 0.0713929757475853
Loss: 0.05712754279375076
Loss: 0.07144477963447571
Loss: 0.08262552320957184
Loss: 0.051823314279317856
Loss: 0.0399288646876812
Loss: 0.01815023086965084
Loss: 0.015164821408689022
Loss: 0.21589472889900208
Loss: 0.028185449540615082
Loss: 0.02651260979473591
Loss: 0.24778765439987183
Loss: 0.008452453650534153
Loss: 0.12560386955738068
Loss: 0.024331483989953995
Loss: 0.0033563438337296247
Loss: 0.007026776671409607
Loss: 0.011891446076333523
Loss: 0.10831509530544281
Loss: 0.13923268020153046
Loss: 0.1276770532131195
Loss: 0.1670435518026352
Loss: 0.09376241266727448
Loss: 0.020355064421892166
Loss: 0.029083136469125748
Loss: 0.018911758437752724
Loss: 0.021410660818219185
Loss: 0.11954152584075928
Loss: 0.09475000947713852
Loss: 0.013523975387215614
Loss: 0.12256155908107758
Loss: 0.01738642528653145
Loss: 0.07506369799375534
Loss: 0.15685886144638062
Loss: 0.11232631653547287
Loss: 0.018154356628656387
Loss: 0.08206167817115784
Loss: 0.05529022589325905
Loss: 0.06850546598434448
Loss: 0.019731156527996063
Loss: 0.09939420223236084
Loss: 0.03211979195475578
Loss: 0.0651768371462822
Loss: 0.04973152279853821
Loss: 0.07093551754951477
Loss: 0.07171249389648438
Loss: 0.011143665760755539
Loss: 0.08139829337596893
Loss: 0.11904259771108627
Loss: 0.08317359536886215
Loss: 0.025607042014598846
Loss: 0.05019637942314148
Loss: 0.07124140113592148
Loss: 0.045975856482982635
Loss: 0.020975308492779732
Loss: 0.07663938403129578
Loss: 0.09096045047044754
Loss: 0.05983133241534233
Loss: 0.007140935864299536
Loss: 0.050922930240631104
Loss: 0.03562778979539871
[Train] Epoch 37, accuracy 1.0
[Eval] Epoch 37, loss 5.132318, accuracy 0.999306
Loss: 0.15130646526813507
Loss: 0.04717535153031349
Loss: 0.022659137845039368
Loss: 0.008331507444381714
Loss: 0.12843263149261475
Loss: 0.12299341708421707
Loss: 0.048660583794116974
Loss: 0.14248058199882507
Loss: 0.009714122861623764
Loss: 0.12931624054908752
Loss: 0.024249915033578873
Loss: 0.06455865502357483
Loss: 0.019628694280982018
Loss: 0.13538627326488495
Loss: 0.03703060746192932
Loss: 0.08610746264457703
Loss: 0.009403840638697147
Loss: 0.06096993386745453
Loss: 0.22210457921028137
Loss: 0.12520122528076172
Loss: 0.03044026345014572
Loss: 0.034835249185562134
Loss: 0.15550093352794647
Loss: 0.1494549810886383
Loss: 0.028296152129769325
Loss: 0.008624178357422352
Loss: 0.10214466601610184
Loss: 0.03494253754615784
Loss: 0.015303992666304111
Loss: 0.15706279873847961
Loss: 0.0186962578445673
Loss: 0.0913417786359787
Loss: 0.035186056047677994
Loss: 0.011172453872859478
Loss: 0.035411253571510315
Loss: 0.10246197134256363
Loss: 0.03464987128973007
Loss: 0.11270816624164581
Loss: 0.025272412225604057
Loss: 0.05712145194411278
Loss: 0.011831856332719326
Loss: 0.016635870561003685
Loss: 0.08833185583353043
Loss: 0.02779066190123558
Loss: 0.2796720564365387
Loss: 0.10491074621677399
Loss: 0.044198960065841675
Loss: 0.027652733027935028
Loss: 0.037926070392131805
Loss: 0.0440683588385582
Loss: 0.003875316586345434
Loss: 0.0027838428504765034
Loss: 0.043555136770009995
Loss: 0.08013606816530228
Loss: 0.20256337523460388
Loss: 0.07528664916753769
Loss: 0.055521417409181595
Loss: 0.11515386402606964
Loss: 0.09911644458770752
Loss: 0.0493985190987587
Loss: 0.12429744005203247
Loss: 0.1090414747595787
Loss: 0.034950971603393555
Loss: 0.026781966909766197
Loss: 0.05556130409240723
Loss: 0.19849610328674316
Loss: 0.020440442487597466
Loss: 0.07157531380653381
Loss: 0.009509274736046791
Loss: 0.010832360945641994
Loss: 0.10362933576107025
Loss: 0.020791547372937202
Loss: 0.05651185289025307
Loss: 0.051875725388526917
Loss: 0.08925586938858032
Loss: 0.028049495071172714
Loss: 0.030041005462408066
Loss: 0.004049457609653473
Loss: 0.08728470653295517
Loss: 0.05282038077712059
Loss: 0.06357632577419281
Loss: 0.08087325096130371
Loss: 0.14410804212093353
Loss: 0.010029474273324013
Loss: 0.010824517346918583
Loss: 0.12468316406011581
Loss: 0.0591890849173069
Loss: 0.026214703917503357
Loss: 0.08286741375923157
Loss: 0.004900816828012466
[Train] Epoch 38, accuracy 1.0
[Eval] Epoch 38, loss 5.129548, accuracy 0.998611
Loss: 0.025424400344491005
Loss: 0.008013411425054073
Loss: 0.10876453667879105
Loss: 0.026827633380889893
Loss: 0.018074337393045425
Loss: 0.10560032725334167
Loss: 0.006720332428812981
Loss: 0.027484431862831116
Loss: 0.141904816031456
Loss: 0.011294319294393063
Loss: 0.0032600124832242727
Loss: 0.05902813374996185
Loss: 0.0727306604385376
Loss: 0.08610997349023819
Loss: 0.07235058397054672
Loss: 0.014064522460103035
Loss: 0.008573034778237343
Loss: 0.11201506853103638
Loss: 0.03888064622879028
Loss: 0.040491171181201935
Loss: 0.013653076253831387
Loss: 0.08326125890016556
Loss: 0.04253116622567177
Loss: 0.012550118379294872
Loss: 0.015784569084644318
Loss: 0.008605703711509705
Loss: 0.06965118646621704
Loss: 0.05250852182507515
Loss: 0.02430829219520092
Loss: 0.05335391312837601
Loss: 0.03554050624370575
Loss: 0.026800045743584633
Loss: 0.04703632742166519
Loss: 0.08459891378879547
Loss: 0.062020622193813324
Loss: 0.04743845760822296
Loss: 0.004915094003081322
Loss: 0.03306574374437332
Loss: 0.020664798095822334
Loss: 0.08853738009929657
Loss: 0.008717675693333149
Loss: 0.11199545115232468
Loss: 0.012551361694931984
Loss: 0.17789284884929657
Loss: 0.03638070449233055
Loss: 0.021508291363716125
Loss: 0.019480250775814056
Loss: 0.008495218120515347
Loss: 0.06415097415447235
Loss: 0.052513185888528824
Loss: 0.004175545647740364
Loss: 0.05015520378947258
Loss: 0.006928366608917713
Loss: 0.024338774383068085
Loss: 0.017882291227579117
Loss: 0.05646393820643425
Loss: 0.04034890979528427
Loss: 0.008370122872292995
Loss: 0.025026265531778336
Loss: 0.08474027365446091
Loss: 0.05275004357099533
Loss: 0.0877092033624649
Loss: 0.06117156893014908
Loss: 0.012314524501562119
Loss: 0.012960444204509258
Loss: 0.011055116541683674
Loss: 0.10230455547571182
Loss: 0.0026960037648677826
Loss: 0.12647543847560883
Loss: 0.2530991733074188
Loss: 0.004634917248040438
Loss: 0.003994638565927744
Loss: 0.10209652781486511
Loss: 0.008590169250965118
Loss: 0.11313827335834503
Loss: 0.07169558107852936
Loss: 0.03203462064266205
Loss: 0.027377277612686157
Loss: 0.09426212310791016
Loss: 0.09622376412153244
Loss: 0.15739572048187256
Loss: 0.03480027616024017
Loss: 0.0392807237803936
Loss: 0.05200169235467911
Loss: 0.03583894297480583
Loss: 0.14487360417842865
Loss: 0.028454352170228958
Loss: 0.022995619103312492
Loss: 0.17094869911670685
Loss: 0.027551976963877678
[Train] Epoch 39, accuracy 1.0
[Eval] Epoch 39, loss 5.131088, accuracy 0.999306
Loss: 0.09021593630313873
Loss: 0.06530531495809555
Loss: 0.004091052804142237
Loss: 0.04303840547800064
Loss: 0.023424074053764343
Loss: 0.04049990326166153
Loss: 0.14947329461574554
Loss: 0.020769812166690826
Loss: 0.0899113193154335
Loss: 0.011455201543867588
Loss: 0.05185578018426895
Loss: 0.12417352944612503
Loss: 0.014088817872107029
Loss: 0.03193226084113121
Loss: 0.09440428018569946
Loss: 0.18982957303524017
Loss: 0.005969212856143713
Loss: 0.07134021818637848
Loss: 0.03303002193570137
Loss: 0.036469124257564545
Loss: 0.01771392673254013
Loss: 0.03652093559503555
Loss: 0.022350065410137177
Loss: 0.0423467792570591
Loss: 0.0594334676861763
Loss: 0.0023850398138165474
Loss: 0.06503616273403168
Loss: 0.026031551882624626
Loss: 0.020935876294970512
Loss: 0.10679206997156143
Loss: 0.020825350657105446
Loss: 0.0231988076120615
Loss: 0.019769150763750076
Loss: 0.06430862843990326
Loss: 0.05646948516368866
Loss: 0.025666750967502594
Loss: 0.05766045302152634
Loss: 0.13385604321956635
Loss: 0.003899303264915943
Loss: 0.020368920639157295
Loss: 0.11620278656482697
Loss: 0.006635785568505526
Loss: 0.01143205538392067
Loss: 0.023337600752711296
Loss: 0.12941034138202667
Loss: 0.07381686568260193
Loss: 0.04776204004883766
Loss: 0.03729873523116112
Loss: 0.012090089730918407
Loss: 0.009577667340636253
Loss: 0.037284355610609055
Loss: 0.061989378184080124
Loss: 0.012590162456035614
Loss: 0.07022101432085037
Loss: 0.14717084169387817
Loss: 0.0262234378606081
Loss: 0.03313140943646431
Loss: 0.022823391482234
Loss: 0.052903298288583755
Loss: 0.07235042005777359
Loss: 0.06536964327096939
Loss: 0.08201901614665985
Loss: 0.00593591807410121
Loss: 0.0302975382655859
Loss: 0.16214066743850708
Loss: 0.017021169885993004
Loss: 0.013319582678377628
Loss: 0.03950712829828262
Loss: 0.0423780232667923
Loss: 0.012534946203231812
Loss: 0.09905792772769928
Loss: 0.04026177152991295
Loss: 0.05119400471448898
Loss: 0.016028830781579018
Loss: 0.005836388096213341
Loss: 0.06573513150215149
Loss: 0.015681203454732895
Loss: 0.003432901343330741
Loss: 0.05786747485399246
Loss: 0.07157419621944427
Loss: 0.06401057541370392
Loss: 0.02736758068203926
Loss: 0.07754002511501312
Loss: 0.01685405895113945
Loss: 0.08099599182605743
Loss: 0.010977741330862045
Loss: 0.04575025662779808
Loss: 0.016364440321922302
Loss: 0.0409511923789978
Loss: 0.0158208217471838
[Train] Epoch 40, accuracy 1.0
[Eval] Epoch 40, loss 5.133297, accuracy 0.998611
Loss: 0.07687123864889145
Loss: 0.06513845920562744
Loss: 0.0465957373380661
Loss: 0.04082835465669632
Loss: 0.0327845998108387
Loss: 0.16054114699363708
Loss: 0.03496670722961426
Loss: 0.10313916951417923
Loss: 0.01743706315755844
Loss: 0.05753612890839577
Loss: 0.03165503591299057
Loss: 0.1175508052110672
Loss: 0.006151416338980198
Loss: 0.007156536914408207
Loss: 0.011720813810825348
Loss: 0.0031790693756192923
Loss: 0.02579534240067005
Loss: 0.008617463521659374
Loss: 0.006365178152918816
Loss: 0.010103190317749977
Loss: 0.1658829003572464
Loss: 0.0055108098313212395
Loss: 0.005945014767348766
Loss: 0.011012552306056023
Loss: 0.0027763163670897484
Loss: 0.005359398201107979
Loss: 0.0024701848160475492
Loss: 0.09377406537532806
Loss: 0.026100674644112587
Loss: 0.0181846022605896
Loss: 0.12732237577438354
Loss: 0.007366660051047802
Loss: 0.04601109400391579
Loss: 0.01808927021920681
Loss: 0.016902824863791466
Loss: 0.009152648039162159
Loss: 0.0031592510640621185
Loss: 0.058688290417194366
Loss: 0.13325124979019165
Loss: 0.12638138234615326
Loss: 0.02701820805668831
Loss: 0.10143807530403137
Loss: 0.010865223594009876
Loss: 0.032666418701410294
Loss: 0.00882425345480442
Loss: 0.027027016505599022
Loss: 0.08054658770561218
Loss: 0.034671902656555176
Loss: 0.044594477862119675
Loss: 0.06662221252918243
Loss: 0.009629239328205585
Loss: 0.08829149603843689
Loss: 0.0020546342711895704
Loss: 0.0741599053144455
Loss: 0.008077539503574371
Loss: 0.12602499127388
Loss: 0.06201944500207901
Loss: 0.012168331071734428
Loss: 0.07979326695203781
Loss: 0.13426227867603302
Loss: 0.17407435178756714
Loss: 0.038144126534461975
Loss: 0.0643024891614914
Loss: 0.05264468118548393
Loss: 0.06136316806077957
Loss: 0.040324434638023376
Loss: 0.0030978068243712187
Loss: 0.11946889758110046
Loss: 0.05130895599722862
Loss: 0.06538563221693039
Loss: 0.012618564069271088
Loss: 0.06214766949415207
Loss: 0.016945935785770416
Loss: 0.06900829076766968
Loss: 0.06293129920959473
Loss: 0.0033515256363898516
Loss: 0.02544671855866909
Loss: 0.005498924758285284
Loss: 0.03751034662127495
Loss: 0.025163397192955017
Loss: 0.014959788881242275
Loss: 0.04375613108277321
Loss: 0.09948291629552841
Loss: 0.019811980426311493
Loss: 0.01697513461112976
Loss: 0.0409768745303154
Loss: 0.030318161472678185
Loss: 0.09652048349380493
Loss: 0.03732055053114891
Loss: 0.027616582810878754
[Train] Epoch 41, accuracy 1.0
[Eval] Epoch 41, loss 5.123810, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.022793754935264587
Loss: 0.017172427847981453
Loss: 0.0074430955573916435
Loss: 0.02009432576596737
Loss: 0.025804294273257256
Loss: 0.051891569048166275
Loss: 0.0214129239320755
Loss: 0.0018575438298285007
Loss: 0.0039005856961011887
Loss: 0.031010570004582405
Loss: 0.02128223143517971
Loss: 0.04849119111895561
Loss: 0.016489172354340553
Loss: 0.00410583196207881
Loss: 0.08048339933156967
Loss: 0.04123985767364502
Loss: 0.005544077605009079
Loss: 0.11339990794658661
Loss: 0.08632383495569229
Loss: 0.08620120584964752
Loss: 0.08385807275772095
Loss: 0.02027592994272709
Loss: 0.014374828897416592
Loss: 0.060505129396915436
Loss: 0.009041724726557732
Loss: 0.00819448847323656
Loss: 0.03228466957807541
Loss: 0.07094759494066238
Loss: 0.007407730910927057
Loss: 0.005232721567153931
Loss: 0.15998362004756927
Loss: 0.007075091823935509
Loss: 0.029367875307798386
Loss: 0.038755081593990326
Loss: 0.07275855541229248
Loss: 0.005590218584984541
Loss: 0.10069316625595093
Loss: 0.0063486951403319836
Loss: 0.050508543848991394
Loss: 0.011418992653489113
Loss: 0.00777528015896678
Loss: 0.024422843009233475
Loss: 0.0347600132226944
Loss: 0.030361026525497437
Loss: 0.04687684029340744
Loss: 0.026064330711960793
Loss: 0.029063545167446136
Loss: 0.012300796806812286
Loss: 0.0012791422195732594
Loss: 0.0056610736064612865
Loss: 0.13118600845336914
Loss: 0.024446578696370125
Loss: 0.0034106120001524687
Loss: 0.01666841097176075
Loss: 0.06362229585647583
Loss: 0.03310234844684601
Loss: 0.1118229329586029
Loss: 0.14336396753787994
Loss: 0.03512973338365555
Loss: 0.01832493767142296
Loss: 0.027863487601280212
Loss: 0.02214564010500908
Loss: 0.04308141767978668
Loss: 0.03559710457921028
Loss: 0.004892368335276842
Loss: 0.0026941890828311443
Loss: 0.003277758602052927
Loss: 0.11638979613780975
Loss: 0.10805905610322952
Loss: 0.015551264397799969
Loss: 0.015131155028939247
Loss: 0.058161720633506775
Loss: 0.003791059833019972
Loss: 0.0630553662776947
Loss: 0.008120865561068058
Loss: 0.02639099210500717
Loss: 0.18733589351177216
Loss: 0.025798318907618523
Loss: 0.015772148966789246
Loss: 0.04273087531328201
Loss: 0.046438347548246384
Loss: 0.037307411432266235
Loss: 0.013304134830832481
Loss: 0.01932632550597191
Loss: 0.005318214651197195
Loss: 0.0317809134721756
Loss: 0.061509884893894196
Loss: 0.010591359809041023
Loss: 0.03908587992191315
Loss: 0.06793732196092606
[Train] Epoch 42, accuracy 1.0
[Eval] Epoch 42, loss 5.127368, accuracy 0.999306
Loss: 0.015771519392728806
Loss: 0.04864969104528427
Loss: 0.006419358309358358
Loss: 0.012286446057260036
Loss: 0.08540543913841248
Loss: 0.005454184487462044
Loss: 0.01606503687798977
Loss: 0.0017906981520354748
Loss: 0.014714635908603668
Loss: 0.023628806695342064
Loss: 0.010217716917395592
Loss: 0.010948168113827705
Loss: 0.01468146126717329
Loss: 0.03932458907365799
Loss: 0.06757714599370956
Loss: 0.053447429090738297
Loss: 0.030604856088757515
Loss: 0.0073342532850801945
Loss: 0.014773322269320488
Loss: 0.049513038247823715
Loss: 0.05291683226823807
Loss: 0.025508562102913857
Loss: 0.09973295032978058
Loss: 0.005551256239414215
Loss: 0.003191019408404827
Loss: 0.019421136006712914
Loss: 0.06253336369991302
Loss: 0.05566076934337616
Loss: 0.061980120837688446
Loss: 0.091450996696949
Loss: 0.04001278430223465
Loss: 0.011373319663107395
Loss: 0.12303583323955536
Loss: 0.02228592149913311
Loss: 0.08262328803539276
Loss: 0.03191716596484184
Loss: 0.03645693510770798
Loss: 0.004945244640111923
Loss: 0.00250642211176455
Loss: 0.015185263007879257
Loss: 0.02034638822078705
Loss: 0.06448053568601608
Loss: 0.07729724794626236
Loss: 0.05354584380984306
Loss: 0.005608634557574987
Loss: 0.00515156053006649
Loss: 0.029882406815886497
Loss: 0.009961472824215889
Loss: 0.10014937818050385
Loss: 0.06158873438835144
Loss: 0.005639350041747093
Loss: 0.09355691820383072
Loss: 0.054160766303539276
Loss: 0.10776013135910034
Loss: 0.009011926129460335
Loss: 0.12337356805801392
Loss: 0.0022439465392380953
Loss: 0.003054328728467226
Loss: 0.07128216326236725
Loss: 0.003666175762191415
Loss: 0.0053795259445905685
Loss: 0.002367765177041292
Loss: 0.010458504781126976
Loss: 0.03661489859223366
Loss: 0.021202044561505318
Loss: 0.016848169267177582
Loss: 0.05489874258637428
Loss: 0.07812171429395676
Loss: 0.0197348203510046
Loss: 0.02155992016196251
Loss: 0.020203527063131332
Loss: 0.014559239149093628
Loss: 0.013786408118903637
Loss: 0.1949358433485031
Loss: 0.021115263924002647
Loss: 0.0008429476292803884
Loss: 0.01696723699569702
Loss: 0.05936384201049805
Loss: 0.03935578465461731
Loss: 0.03554176539182663
Loss: 0.09518935531377792
Loss: 0.01058928668498993
Loss: 0.01577509380877018
Loss: 0.0936308205127716
Loss: 0.003107980592176318
Loss: 0.05879723280668259
Loss: 0.027192525565624237
Loss: 0.00326365209184587
Loss: 0.08570419996976852
Loss: 0.06898432970046997
[Train] Epoch 43, accuracy 1.0
[Eval] Epoch 43, loss 5.122430, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.060138169676065445
Loss: 0.023523198440670967
Loss: 0.063445545732975
Loss: 0.08658426254987717
Loss: 0.030702266842126846
Loss: 0.008218836970627308
Loss: 0.045393459498882294
Loss: 0.05376128479838371
Loss: 0.036213502287864685
Loss: 0.00746502261608839
Loss: 0.009184327907860279
Loss: 0.0779339149594307
Loss: 0.035939719527959824
Loss: 0.012962517328560352
Loss: 0.007691115140914917
Loss: 0.004074522759765387
Loss: 0.014510375447571278
Loss: 0.04367385059595108
Loss: 0.0012542990734800696
Loss: 0.08477814495563507
Loss: 0.006571855396032333
Loss: 0.03471483290195465
Loss: 0.001452173339203
Loss: 0.025689387694001198
Loss: 0.056148502975702286
Loss: 0.026025814935564995
Loss: 0.07000846415758133
Loss: 0.061047833412885666
Loss: 0.015229959040880203
Loss: 0.0358298234641552
Loss: 0.01183111872524023
Loss: 0.09186116605997086
Loss: 0.04501146078109741
Loss: 0.02647949755191803
Loss: 0.0215286985039711
Loss: 0.07782421261072159
Loss: 0.0024996104184538126
Loss: 0.05544036254286766
Loss: 0.03741580247879028
Loss: 0.0028286310844123363
Loss: 0.10887236148118973
Loss: 0.010657810606062412
Loss: 0.009999513626098633
Loss: 0.0024544368498027325
Loss: 0.03188507631421089
Loss: 0.013781283050775528
Loss: 0.045140426605939865
Loss: 0.016422977671027184
Loss: 0.013401144184172153
Loss: 0.0030645523220300674
Loss: 0.007967175915837288
Loss: 0.11375304311513901
Loss: 0.00411180779337883
Loss: 0.004867865238338709
Loss: 0.010128423571586609
Loss: 0.010606647469103336
Loss: 0.015931399539113045
Loss: 0.027188068255782127
Loss: 0.04131719097495079
Loss: 0.011812529526650906
Loss: 0.0016759486170485616
Loss: 0.0019048401154577732
Loss: 0.004847134929150343
Loss: 0.03834693133831024
Loss: 0.0020275763235986233
Loss: 0.0037836432456970215
Loss: 0.035586025565862656
Loss: 0.020015696063637733
Loss: 0.05424825847148895
Loss: 0.008802666328847408
Loss: 0.0267182569950819
Loss: 0.010088441893458366
Loss: 0.034122269600629807
Loss: 0.003222365863621235
Loss: 0.017437081784009933
Loss: 0.001110880053602159
Loss: 0.012067662551999092
Loss: 0.000581545231398195
Loss: 0.03429262340068817
Loss: 0.026587169617414474
Loss: 0.03597026318311691
Loss: 0.045268699526786804
Loss: 0.010327300988137722
Loss: 0.10382719337940216
Loss: 0.024214668199419975
Loss: 0.006714038085192442
Loss: 0.03417831286787987
Loss: 0.17760911583900452
Loss: 0.0054976437240839005
Loss: 0.012525520287454128
[Train] Epoch 44, accuracy 1.0
[Eval] Epoch 44, loss 5.121719, accuracy 0.998611
Loss: 0.06681269407272339
Loss: 0.006334031466394663
Loss: 0.024209801107645035
Loss: 0.0037734080106019974
Loss: 0.012915131635963917
Loss: 0.10501409322023392
Loss: 0.004424679558724165
Loss: 0.11382756382226944
Loss: 0.022795824334025383
Loss: 0.0034483876079320908
Loss: 0.06564528495073318
Loss: 0.008312808349728584
Loss: 0.006294404622167349
Loss: 0.05405229702591896
Loss: 0.13992539048194885
Loss: 0.005199042148888111
Loss: 0.08970247954130173
Loss: 0.084979347884655
Loss: 0.008830157108604908
Loss: 0.005803439766168594
Loss: 0.006308444309979677
Loss: 0.007352638989686966
Loss: 0.027673622593283653
Loss: 0.08892013132572174
Loss: 0.0027340140659362078
Loss: 0.003502089297398925
Loss: 0.02939746156334877
Loss: 0.10567886382341385
Loss: 0.026015721261501312
Loss: 0.01924056187272072
Loss: 0.0014703009510412812
Loss: 0.012167870998382568
Loss: 0.003138413652777672
Loss: 0.00789297092705965
Loss: 0.0611109621822834
Loss: 0.007314399816095829
Loss: 0.024306217208504677
Loss: 0.19694417715072632
Loss: 0.11363127082586288
Loss: 0.08949000388383865
Loss: 0.0863746851682663
Loss: 0.005760199390351772
Loss: 0.027714530006051064
Loss: 0.02113119512796402
Loss: 0.07117275148630142
Loss: 0.013360761106014252
Loss: 0.05919816344976425
Loss: 0.059572380036115646
Loss: 0.055801257491111755
Loss: 0.05966589227318764
Loss: 0.028308173641562462
Loss: 0.010814676061272621
Loss: 0.011181646026670933
Loss: 0.0018548826919868588
Loss: 0.029992880299687386
Loss: 0.0033767037093639374
Loss: 0.03256087750196457
Loss: 0.01249059196561575
Loss: 0.06694929301738739
Loss: 0.008402294479310513
Loss: 0.11922919005155563
Loss: 0.0899563655257225
Loss: 0.06971070170402527
Loss: 0.00907206442207098
Loss: 0.0021647633984684944
Loss: 0.04092860221862793
Loss: 0.008452934212982655
Loss: 0.014967329800128937
Loss: 0.020682690665125847
Loss: 0.0066735465079545975
Loss: 0.026336679235100746
Loss: 0.0010098847560584545
Loss: 0.008737175725400448
Loss: 0.0957397073507309
Loss: 0.004907339811325073
Loss: 0.05437970533967018
Loss: 0.011894331313669682
Loss: 0.026120271533727646
Loss: 0.033263057470321655
Loss: 0.03956514969468117
Loss: 0.033617813140153885
Loss: 0.010915745981037617
Loss: 0.008815799839794636
Loss: 0.025149289518594742
Loss: 0.015676870942115784
Loss: 0.01932532526552677
Loss: 0.0018298437353223562
Loss: 0.004241356626152992
Loss: 0.02689131535589695
Loss: 0.002166225342079997
[Train] Epoch 45, accuracy 1.0
[Eval] Epoch 45, loss 5.122222, accuracy 0.998611
Loss: 0.0022169894073158503
Loss: 0.0745994821190834
Loss: 0.032791417092084885
Loss: 0.002825629897415638
Loss: 0.004230296704918146
Loss: 0.02428862266242504
Loss: 0.005720421206206083
Loss: 0.007710073608905077
Loss: 0.019868258386850357
Loss: 0.02259434200823307
Loss: 0.004868145100772381
Loss: 0.021855348721146584
Loss: 0.05788526311516762
Loss: 0.01076903659850359
Loss: 0.07018695026636124
Loss: 0.0037406294140964746
Loss: 0.015342103317379951
Loss: 0.024431463330984116
Loss: 0.016147291287779808
Loss: 0.08106275647878647
Loss: 0.0036719790659844875
Loss: 0.01077140774577856
Loss: 0.03449768200516701
Loss: 0.010013459250330925
Loss: 0.08251498639583588
Loss: 0.0608297735452652
Loss: 0.00249351654201746
Loss: 0.020606597885489464
Loss: 0.04462910443544388
Loss: 0.0031673579942435026
Loss: 0.05275391414761543
Loss: 0.002702223602682352
Loss: 0.01682986691594124
Loss: 0.1110050231218338
Loss: 0.012883518822491169
Loss: 0.005358522292226553
Loss: 0.00040864976472221315
Loss: 0.0008554717060178518
Loss: 0.003201257437467575
Loss: 0.04345010593533516
Loss: 0.05262325331568718
Loss: 0.01346396841108799
Loss: 0.00985209085047245
Loss: 0.07499335706233978
Loss: 0.017469443380832672
Loss: 0.01734679937362671
Loss: 0.003968621604144573
Loss: 0.037555959075689316
Loss: 0.05073389783501625
Loss: 0.035476796329021454
Loss: 0.06422066688537598
Loss: 0.007751252502202988
Loss: 0.02447253093123436
Loss: 0.05121797323226929
Loss: 0.0024697950575500727
Loss: 0.007942412048578262
Loss: 0.09621299058198929
Loss: 0.004891258664429188
Loss: 0.08471275866031647
Loss: 0.0023574507795274258
Loss: 0.004707988351583481
Loss: 0.023140225559473038
Loss: 0.019528869539499283
Loss: 0.007226842455565929
Loss: 0.16793683171272278
Loss: 0.025641141459345818
Loss: 0.005327593069523573
Loss: 0.001475519617088139
Loss: 0.05095616355538368
Loss: 0.012678352184593678
Loss: 0.005436512641608715
Loss: 0.010493260808289051
Loss: 0.0025183872785419226
Loss: 0.039539407938718796
Loss: 0.012890196405351162
Loss: 0.08201409876346588
Loss: 0.004115249030292034
Loss: 0.07077381759881973
Loss: 0.005163105204701424
Loss: 0.0050352937541902065
Loss: 0.0136643685400486
Loss: 0.009834657423198223
Loss: 0.028182556852698326
Loss: 0.04054559767246246
Loss: 0.015573795884847641
Loss: 0.09971092641353607
Loss: 0.0108460932970047
Loss: 0.04379548504948616
Loss: 0.027959497645497322
Loss: 0.06652934104204178
[Train] Epoch 46, accuracy 1.0
[Eval] Epoch 46, loss 5.122132, accuracy 0.998611
Loss: 0.00891487393528223
Loss: 0.0022785053588449955
Loss: 0.07103607058525085
Loss: 0.0020070767495781183
Loss: 0.03569744527339935
Loss: 0.0015985955251380801
Loss: 0.019526289775967598
Loss: 0.01660204865038395
Loss: 0.016474254429340363
Loss: 0.05198484659194946
Loss: 0.046993985772132874
Loss: 0.018832601606845856
Loss: 0.02543676272034645
Loss: 0.005636492278426886
Loss: 0.010620823130011559
Loss: 0.03709936514496803
Loss: 0.0037866057828068733
Loss: 0.008610847406089306
Loss: 0.05574808269739151
Loss: 0.10413467139005661
Loss: 0.03718722611665726
Loss: 0.13393841683864594
Loss: 0.005302242934703827
Loss: 0.012208709493279457
Loss: 0.016746027395129204
Loss: 0.09456898272037506
Loss: 0.024379896000027657
Loss: 0.012106521055102348
Loss: 0.012369595468044281
Loss: 0.005829505622386932
Loss: 0.024427782744169235
Loss: 0.09927842020988464
Loss: 0.009854728356003761
Loss: 0.02240392193198204
Loss: 0.034823834896087646
Loss: 0.0016121258959174156
Loss: 0.0242428220808506
Loss: 0.0014545039739459753
Loss: 0.01220112107694149
Loss: 0.004578184802085161
Loss: 0.008391555398702621
Loss: 0.03475363925099373
Loss: 0.027812950313091278
Loss: 0.019330661743879318
Loss: 0.005297581199556589
Loss: 0.00305339228361845
Loss: 0.08218446373939514
Loss: 0.0974806398153305
Loss: 0.0035831599961966276
Loss: 0.014582019299268723
Loss: 0.0032343119382858276
Loss: 0.005167375784367323
Loss: 0.017617400735616684
Loss: 0.013681330718100071
Loss: 0.10843316465616226
Loss: 0.010503889992833138
Loss: 0.01266002468764782
Loss: 0.01845748908817768
Loss: 0.016978800296783447
Loss: 0.010210356675088406
Loss: 0.04033096879720688
Loss: 0.0712362676858902
Loss: 0.01456452812999487
Loss: 0.056701671332120895
Loss: 0.00324623822234571
Loss: 0.023952636867761612
Loss: 0.03522415831685066
Loss: 0.012363005429506302
Loss: 0.0010760100558400154
Loss: 0.002602346008643508
Loss: 0.0011462140828371048
Loss: 0.07306481152772903
Loss: 0.04034889489412308
Loss: 0.014714828692376614
Loss: 0.03010493703186512
Loss: 0.017392780631780624
Loss: 0.00206623412668705
Loss: 0.0008280848851427436
Loss: 0.10671848058700562
Loss: 0.034886978566646576
Loss: 0.002513492712751031
Loss: 0.027907611802220345
Loss: 0.026262348517775536
Loss: 0.01926817186176777
Loss: 0.002429475774988532
Loss: 0.027676599100232124
Loss: 0.055948566645383835
Loss: 0.125263512134552
Loss: 0.010817667469382286
Loss: 0.005252638831734657
[Train] Epoch 47, accuracy 1.0
[Eval] Epoch 47, loss 5.121639, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.004706636071205139
Loss: 0.053445372730493546
Loss: 0.022175535559654236
Loss: 0.04666566103696823
Loss: 0.1323106437921524
Loss: 0.021750323474407196
Loss: 0.07547671347856522
Loss: 0.028067611157894135
Loss: 0.012903589755296707
Loss: 0.01637193188071251
Loss: 0.021234607324004173
Loss: 0.01214243471622467
Loss: 0.002347044413909316
Loss: 0.006212263833731413
Loss: 0.0041755978018045425
Loss: 0.026623353362083435
Loss: 0.017962154000997543
Loss: 0.01514350064098835
Loss: 0.0032095613423734903
Loss: 0.009689667262136936
Loss: 0.0028494042344391346
Loss: 0.02113751508295536
Loss: 0.039963915944099426
Loss: 0.013006595894694328
Loss: 0.025075649842619896
Loss: 0.004317540675401688
Loss: 0.0066177621483802795
Loss: 0.00658900523558259
Loss: 0.001350485603325069
Loss: 0.004857521504163742
Loss: 0.002057471312582493
Loss: 0.003983885049819946
Loss: 0.027994798496365547
Loss: 0.023378727957606316
Loss: 0.006486828904598951
Loss: 0.006742690224200487
Loss: 0.030931754037737846
Loss: 0.044812072068452835
Loss: 0.006548607721924782
Loss: 0.0011685180943459272
Loss: 0.03332970291376114
Loss: 0.02176150493323803
Loss: 0.008280830457806587
Loss: 0.08355184644460678
Loss: 0.062037836760282516
Loss: 0.03872883319854736
Loss: 0.0007364475750364363
Loss: 0.022602856159210205
Loss: 0.045625533908605576
Loss: 0.0023721337784081697
Loss: 0.05695454776287079
Loss: 0.0014372180448845029
Loss: 0.13063441216945648
Loss: 0.009234578348696232
Loss: 0.020129211246967316
Loss: 0.020967325195670128
Loss: 0.08180318027734756
Loss: 0.1701875627040863
Loss: 0.039635125547647476
Loss: 0.03900936245918274
Loss: 0.016868766397237778
Loss: 0.012630188837647438
Loss: 0.06573256850242615
Loss: 0.03068568743765354
Loss: 0.0015085614286363125
Loss: 0.002721775323152542
Loss: 0.010983622632920742
Loss: 0.0007776327547617257
Loss: 0.01293935626745224
Loss: 0.011762063950300217
Loss: 0.03760705888271332
Loss: 0.09243657439947128
Loss: 0.002936974400654435
Loss: 0.013951994478702545
Loss: 0.004685917869210243
Loss: 0.042341746389865875
Loss: 0.06572628021240234
Loss: 0.18228745460510254
Loss: 0.14815197885036469
Loss: 0.06175962835550308
Loss: 0.0013562210369855165
Loss: 0.11839351803064346
Loss: 0.00782308354973793
Loss: 0.0912921354174614
Loss: 0.04723547771573067
Loss: 0.01198908407241106
Loss: 0.010935088619589806
Loss: 0.08304984122514725
Loss: 0.0026910705491900444
Loss: 0.02687155455350876
[Train] Epoch 48, accuracy 1.0
[Eval] Epoch 48, loss 5.123299, accuracy 0.999306
Loss: 0.003442575689405203
Loss: 0.03641403093934059
Loss: 0.005315174348652363
Loss: 0.02219061553478241
Loss: 0.0631294772028923
Loss: 0.04414951056241989
Loss: 0.12334237992763519
Loss: 0.010806254111230373
Loss: 0.011391057632863522
Loss: 0.024244818836450577
Loss: 0.006569307297468185
Loss: 0.0029509412124753
Loss: 0.003196125850081444
Loss: 0.007959229871630669
Loss: 0.01658395119011402
Loss: 0.0408506765961647
Loss: 0.07220929116010666
Loss: 0.0013053551083430648
Loss: 0.005575287155807018
Loss: 0.023023169487714767
Loss: 0.08814004063606262
Loss: 0.011315934360027313
Loss: 0.03644954785704613
Loss: 0.0024304736871272326
Loss: 0.013335482217371464
Loss: 0.00911299604922533
Loss: 0.003926802426576614
Loss: 0.0025713921058923006
Loss: 0.04993540793657303
Loss: 0.009722340852022171
Loss: 0.008085358887910843
Loss: 0.029231300577521324
Loss: 0.00574138481169939
Loss: 0.025180675089359283
Loss: 0.008539319969713688
Loss: 0.08928880095481873
Loss: 0.06713970005512238
Loss: 0.007833140902221203
Loss: 0.01748189516365528
Loss: 0.004012232646346092
Loss: 0.04538571834564209
Loss: 0.02195614017546177
Loss: 0.02150772511959076
Loss: 0.03484176844358444
Loss: 0.006707849912345409
Loss: 0.026871105656027794
Loss: 0.0034071223344653845
Loss: 0.020823467522859573
Loss: 0.03646622225642204
Loss: 0.00602302048355341
Loss: 0.008757377043366432
Loss: 0.050665825605392456
Loss: 0.019641343504190445
Loss: 0.023386919870972633
Loss: 0.011947349645197392
Loss: 0.003541235812008381
Loss: 0.06785639375448227
Loss: 0.017328672111034393
Loss: 0.001986474497243762
Loss: 0.015074783936142921
Loss: 0.017109405249357224
Loss: 0.0155295729637146
Loss: 0.030540596693754196
Loss: 0.017024865373969078
Loss: 0.0024780635721981525
Loss: 0.014293664135038853
Loss: 0.008198287338018417
Loss: 0.006143974605947733
Loss: 0.052452150732278824
Loss: 0.005312675144523382
Loss: 0.0005180754233151674
Loss: 0.0017954573268070817
Loss: 0.0015868594637140632
Loss: 0.006052103359252214
Loss: 0.08637692034244537
Loss: 0.04851675406098366
Loss: 0.01873100735247135
Loss: 0.06910303980112076
Loss: 0.004153574351221323
Loss: 0.06024818494915962
Loss: 0.027731698006391525
Loss: 0.01056837011128664
Loss: 0.0054994127713143826
Loss: 0.0069620925933122635
Loss: 0.024534029886126518
Loss: 0.010172554291784763
Loss: 0.015462169423699379
Loss: 0.01470860280096531
Loss: 0.009611274115741253
Loss: 0.008246384561061859
[Train] Epoch 49, accuracy 1.0
[Eval] Epoch 49, loss 5.121571, accuracy 0.999306
Model saved as x_small_model_weights_best.pth
Loss: 0.03447234258055687
Loss: 0.02820800617337227
Loss: 0.004769834224134684
Loss: 0.007861838676035404
Loss: 0.00485380832105875
Loss: 0.005840983707457781
Loss: 0.0033339837100356817
Loss: 0.043163783848285675
Loss: 0.026502419263124466
Loss: 0.028823891654610634
Loss: 0.08306042104959488
Loss: 0.015910213813185692
Loss: 0.03292916715145111
Loss: 0.0020130975171923637
Loss: 0.01607273705303669
Loss: 0.009423680603504181
Loss: 0.040042608976364136
Loss: 0.00042206025682389736
Loss: 0.02561570331454277
Loss: 0.12554261088371277
Loss: 0.023480216041207314
Loss: 0.014050510711967945
Loss: 0.005344398319721222
Loss: 0.026424624025821686
Loss: 0.006124563980847597
Loss: 0.026653682813048363
Loss: 0.1789463758468628
Loss: 0.008378339000046253
Loss: 0.08561873435974121
Loss: 0.03433943912386894
Loss: 0.007126215845346451
Loss: 0.0029933471232652664
Loss: 0.0028356893453747034
Loss: 0.0017405180260539055
Loss: 0.015038294717669487
Loss: 0.0012931920355185866
Loss: 0.09942048788070679
Loss: 0.013195930980145931
Loss: 0.009897987358272076
Loss: 0.01196760032325983
Loss: 0.0018100938759744167
Loss: 0.03883516788482666
Loss: 0.020893145352602005
Loss: 0.1436769664287567
Loss: 0.012897462584078312
Loss: 0.009847663342952728
Loss: 0.08048851788043976
Loss: 0.006109393667429686
Loss: 0.04677904397249222
Loss: 0.0008500802796334028
Loss: 0.007513225544244051
Loss: 0.026901310309767723
Loss: 0.015344631858170033
Loss: 0.01717403158545494
Loss: 0.0025705599691718817
Loss: 0.0063145700842142105
Loss: 0.027698393911123276
Loss: 0.016598068177700043
Loss: 0.06619399040937424
Loss: 0.10122766345739365
Loss: 0.0017813161248341203
Loss: 0.008569366298615932
Loss: 0.019483456388115883
Loss: 0.10314448177814484
Loss: 0.015259822830557823
Loss: 0.011472535319626331
Loss: 0.00575594836845994
Loss: 0.01669442467391491
Loss: 0.002249121433123946
Loss: 0.019192436710000038
Loss: 0.009055298753082752
Loss: 0.008730598725378513
Loss: 0.005202479660511017
Loss: 0.016598472371697426
Loss: 0.013115613721311092
Loss: 0.017419643700122833
Loss: 0.018095597624778748
Loss: 0.006411097012460232
Loss: 0.006116092670708895
Loss: 0.08973216265439987
Loss: 0.001277178293094039
Loss: 0.0016189484158530831
Loss: 0.0034079973120242357
Loss: 0.007034779526293278
Loss: 0.03999277949333191
Loss: 0.00819929875433445
Loss: 0.03082902543246746
Loss: 0.00520829763263464
Loss: 0.07620216906070709
Loss: 0.0004154377384111285
[Train] Epoch 50, accuracy 1.0
[Eval] Epoch 50, loss 5.121142, accuracy 0.998611
Best accuracy: 0.999306
